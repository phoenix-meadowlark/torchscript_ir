graph(%self.1 : __torch__.transformers.modeling_longformer.___torch_mangle_8283.LongformerModel,
      %input_ids.1 : Long(17:13, 13:1),
      %input.1 : Long(17:13, 13:1)):
  %3 : __torch__.transformers.modeling_longformer.___torch_mangle_8282.LongformerPooler = prim::GetAttr[name="pooler"](%self.1)
  %4 : __torch__.transformers.modeling_longformer.___torch_mangle_8279.LongformerEncoder = prim::GetAttr[name="encoder"](%self.1)
  %5 : __torch__.transformers.modeling_longformer.___torch_mangle_8049.LongformerEmbeddings = prim::GetAttr[name="embeddings"](%self.1)
  %6 : int = prim::Constant[value=0]() # transformers/modeling_longformer.py:1228:0
  %7 : int = aten::size(%input_ids.1, %6) # transformers/modeling_longformer.py:1228:0
  %8 : Long() = prim::NumToTensor(%7)
  %9 : int = aten::Int(%8)
  %10 : int = prim::Constant[value=1]() # transformers/modeling_longformer.py:1228:0
  %11 : int = aten::size(%input_ids.1, %10) # transformers/modeling_longformer.py:1228:0
  %12 : Long() = prim::NumToTensor(%11)
  %13 : int = aten::Int(%12)
  %14 : int[] = prim::ListConstruct(%9, %13)
  %15 : int = prim::Constant[value=4]() # transformers/modeling_longformer.py:1239:0
  %16 : int = prim::Constant[value=0]() # transformers/modeling_longformer.py:1239:0
  %17 : Device = prim::Constant[value="cpu"]() # transformers/modeling_longformer.py:1239:0
  %18 : bool = prim::Constant[value=0]() # transformers/modeling_longformer.py:1239:0
  %input.2 : Long(17:13, 13:1) = aten::zeros(%14, %15, %16, %17, %18) # transformers/modeling_longformer.py:1239:0
  %20 : int = prim::Constant[value=1]() # transformers/modeling_longformer.py:1136:0
  %21 : int = aten::size(%input_ids.1, %20) # transformers/modeling_longformer.py:1136:0
  %seq_len.1 : Long() = prim::NumToTensor(%21)
  %23 : int = prim::Constant[value=512]() # transformers/modeling_longformer.py:1139:0
  %24 : Long() = aten::remainder(%seq_len.1, %23) # transformers/modeling_longformer.py:1139:0
  %25 : int = prim::Constant[value=512]() # torch/tensor.py:396:0
  %26 : int = prim::Constant[value=1]() # torch/tensor.py:396:0
  %27 : Long() = aten::rsub(%24, %25, %26) # torch/tensor.py:396:0
  %28 : int = prim::Constant[value=512]() # transformers/modeling_longformer.py:1139:0
  %padding_len : Long() = aten::remainder(%27, %28) # transformers/modeling_longformer.py:1139:0
  %30 : int = aten::Int(%padding_len)
  %31 : int = aten::Int(%padding_len)
  %32 : int = aten::Int(%padding_len)
  %33 : int = prim::Constant[value=0]() # torch/nn/functional.py:3552:0
  %34 : int[] = prim::ListConstruct(%33, %32)
  %35 : int = prim::Constant[value=1]() # torch/nn/functional.py:3552:0
  %input_ids : Long(17:512, 512:1) = aten::constant_pad_nd(%input_ids.1, %34, %35) # torch/nn/functional.py:3552:0
  %37 : int = prim::Constant[value=0]() # torch/nn/functional.py:3552:0
  %38 : int[] = prim::ListConstruct(%37, %31)
  %39 : int = prim::Constant[value=0]() # torch/nn/functional.py:3552:0
  %attention_mask.1 : Long(17:512, 512:1) = aten::constant_pad_nd(%input.1, %38, %39) # torch/nn/functional.py:3552:0
  %41 : int = prim::Constant[value=0]() # torch/nn/functional.py:3552:0
  %42 : int[] = prim::ListConstruct(%41, %30)
  %43 : int = prim::Constant[value=0]() # torch/nn/functional.py:3552:0
  %input.4 : Long(17:512, 512:1) = aten::constant_pad_nd(%input.2, %42, %43) # torch/nn/functional.py:3552:0
  %45 : int = prim::Constant[value=0]() # transformers/modeling_utils.py:244:0
  %46 : int = prim::Constant[value=0]() # transformers/modeling_utils.py:244:0
  %47 : int = prim::Constant[value=9223372036854775807]() # transformers/modeling_utils.py:244:0
  %48 : int = prim::Constant[value=1]() # transformers/modeling_utils.py:244:0
  %49 : Long(17:512, 512:1) = aten::slice(%attention_mask.1, %45, %46, %47, %48) # transformers/modeling_utils.py:244:0
  %50 : int = prim::Constant[value=1]() # transformers/modeling_utils.py:244:0
  %51 : Long(17:512, 1:512, 512:1) = aten::unsqueeze(%49, %50) # transformers/modeling_utils.py:244:0
  %52 : int = prim::Constant[value=2]() # transformers/modeling_utils.py:244:0
  %53 : Long(17:512, 1:512, 1:512, 512:1) = aten::unsqueeze(%51, %52) # transformers/modeling_utils.py:244:0
  %54 : int = prim::Constant[value=3]() # transformers/modeling_utils.py:244:0
  %55 : int = prim::Constant[value=0]() # transformers/modeling_utils.py:244:0
  %56 : int = prim::Constant[value=9223372036854775807]() # transformers/modeling_utils.py:244:0
  %57 : int = prim::Constant[value=1]() # transformers/modeling_utils.py:244:0
  %extended_attention_mask : Long(17:512, 1:512, 1:512, 512:1) = aten::slice(%53, %54, %55, %56, %57) # transformers/modeling_utils.py:244:0
  %59 : int = prim::Constant[value=6]() # transformers/modeling_utils.py:257:0
  %60 : bool = prim::Constant[value=0]() # transformers/modeling_utils.py:257:0
  %61 : bool = prim::Constant[value=0]() # transformers/modeling_utils.py:257:0
  %62 : None = prim::Constant()
  %63 : Float(17:512, 1:512, 1:512, 512:1) = aten::to(%extended_attention_mask, %59, %60, %61, %62) # transformers/modeling_utils.py:257:0
  %64 : float = prim::Constant[value=1.]() # torch/tensor.py:396:0
  %65 : int = prim::Constant[value=1]() # torch/tensor.py:396:0
  %66 : Float(17:512, 1:512, 1:512, 512:1) = aten::rsub(%63, %64, %65) # torch/tensor.py:396:0
  %67 : Double() = prim::Constant[value={-10000}]() # transformers/modeling_utils.py:258:0
  %attention_mask : Float(17:512, 1:512, 1:512, 512:1) = aten::mul(%66, %67) # transformers/modeling_utils.py:258:0
  %84 : float = prim::Constant[value=0.10000000000000001](), scope: __module.embeddings/__module.embeddings.dropout # torch/nn/functional.py:973:0
  %85 : int = prim::Constant[value=768](), scope: __module.embeddings/__module.embeddings.LayerNorm # torch/nn/functional.py:2048:0
  %86 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.embeddings/__module.embeddings.LayerNorm # torch/nn/functional.py:2048:0
  %87 : bool = prim::Constant[value=1](), scope: __module.embeddings/__module.embeddings.LayerNorm # torch/nn/functional.py:2048:0
  %88 : int = prim::Constant[value=-1](), scope: __module.embeddings/__module.embeddings.token_type_embeddings # torch/nn/functional.py:1814:0
  %89 : Device = prim::Constant[value="cpu"](), scope: __module.embeddings # transformers/modeling_longformer.py:147:0
  %90 : int = prim::Constant[value=0](), scope: __module.embeddings # transformers/modeling_longformer.py:147:0
  %91 : Long() = prim::Constant[value={1}](), scope: __module.embeddings # transformers/modeling_longformer.py:114:0
  %92 : int = prim::Constant[value=4](), scope: __module.embeddings # transformers/modeling_longformer.py:114:0
  %93 : None = prim::Constant(), scope: __module.embeddings
  %94 : bool = prim::Constant[value=0](), scope: __module.embeddings # transformers/modeling_longformer.py:112:0
  %95 : int = prim::Constant[value=3](), scope: __module.embeddings # transformers/modeling_longformer.py:112:0
  %96 : int = prim::Constant[value=1](), scope: __module.embeddings # transformers/modeling_longformer.py:112:0
  %97 : __torch__.torch.nn.modules.normalization.___torch_mangle_8047.LayerNorm = prim::GetAttr[name="LayerNorm"](%5)
  %98 : __torch__.torch.nn.modules.sparse.___torch_mangle_8046.Embedding = prim::GetAttr[name="token_type_embeddings"](%5)
  %99 : __torch__.torch.nn.modules.sparse.___torch_mangle_8045.Embedding = prim::GetAttr[name="position_embeddings"](%5)
  %100 : __torch__.torch.nn.modules.sparse.___torch_mangle_8044.Embedding = prim::GetAttr[name="word_embeddings"](%5)
  %101 : Bool(17:512, 512:1) = aten::ne(%input_ids, %96), scope: __module.embeddings # transformers/modeling_longformer.py:112:0
  %mask : Int(17:512, 512:1) = aten::to(%101, %95, %94, %94, %93), scope: __module.embeddings # transformers/modeling_longformer.py:112:0
  %103 : Long(17:512, 512:1) = aten::cumsum(%mask, %96, %93), scope: __module.embeddings # transformers/modeling_longformer.py:113:0
  %104 : Int(17:512, 512:1) = aten::type_as(%103, %mask), scope: __module.embeddings # transformers/modeling_longformer.py:113:0
  %incremental_indices : Int(17:512, 512:1) = aten::mul(%104, %mask), scope: __module.embeddings # transformers/modeling_longformer.py:113:0
  %106 : Long(17:512, 512:1) = aten::to(%incremental_indices, %92, %94, %94, %93), scope: __module.embeddings # transformers/modeling_longformer.py:114:0
  %107 : Long(17:512, 512:1) = aten::add(%106, %91, %96), scope: __module.embeddings # transformers/modeling_longformer.py:114:0
  %input.3 : Long(17:512, 512:1) = aten::to(%107, %92, %90, %89, %94, %94, %94, %93), scope: __module.embeddings # transformers/modeling_longformer.py:147:0
  %109 : Tensor = prim::GetAttr[name="weight"](%100)
  %inputs_embeds : Float(17:393216, 512:768, 768:1) = aten::embedding(%109, %input_ids, %96, %94, %94), scope: __module.embeddings/__module.embeddings.word_embeddings # torch/nn/functional.py:1814:0
  %111 : Tensor = prim::GetAttr[name="weight"](%99)
  %position_embeddings : Float(17:393216, 512:768, 768:1) = aten::embedding(%111, %input.3, %96, %94, %94), scope: __module.embeddings/__module.embeddings.position_embeddings # torch/nn/functional.py:1814:0
  %113 : Tensor = prim::GetAttr[name="weight"](%98)
  %token_type_embeddings : Float(17:393216, 512:768, 768:1) = aten::embedding(%113, %input.4, %88, %94, %94), scope: __module.embeddings/__module.embeddings.token_type_embeddings # torch/nn/functional.py:1814:0
  %115 : Float(17:393216, 512:768, 768:1) = aten::add(%inputs_embeds, %position_embeddings, %96), scope: __module.embeddings # transformers/modeling_longformer.py:170:0
  %input.5 : Float(17:393216, 512:768, 768:1) = aten::add(%115, %token_type_embeddings, %96), scope: __module.embeddings # transformers/modeling_longformer.py:170:0
  %117 : Tensor = prim::GetAttr[name="bias"](%97)
  %118 : Tensor = prim::GetAttr[name="weight"](%97)
  %119 : int[] = prim::ListConstruct(%85), scope: __module.embeddings/__module.embeddings.LayerNorm
  %input.6 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.5, %119, %118, %117, %86, %87), scope: __module.embeddings/__module.embeddings.LayerNorm # torch/nn/functional.py:2048:0
  %hidden_states.1 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.6, %84, %94), scope: __module.embeddings/__module.embeddings.dropout # torch/nn/functional.py:973:0
  %122 : bool = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %123 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %124 : int = prim::Constant[value=2](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:241:0
  %125 : int = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:241:0
  %126 : int = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:22:0
  %127 : Double() = prim::Constant[value={8}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:261:0
  %128 : int = prim::Constant[value=12](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:263:0
  %129 : int = prim::Constant[value=64](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:263:0
  %130 : int = prim::Constant[value=3](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:472:0
  %131 : Long() = prim::Constant[value={256}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:424:0
  %132 : Long() = prim::Constant[value={1}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:478:0
  %133 : Long() = prim::Constant[value={512}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:424:0
  %134 : int = prim::Constant[value=512](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:441:0
  %135 : Long() = prim::Constant[value={2}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:450:0
  %136 : int = prim::Constant[value=3342336](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:454:0
  %137 : int = prim::Constant[value=13056](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:454:0
  %138 : None = prim::Constant(), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %139 : str = prim::Constant[value="bcxd,bcyd->bcxy"](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/functional.py:327:0
  %140 : int = prim::Constant[value=-1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:401:0
  %141 : int = prim::Constant[value=-2](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:401:0
  %142 : int = prim::Constant[value=256](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:503:0
  %143 : int = prim::Constant[value=513](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:503:0
  %144 : int = prim::Constant[value=6](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:503:0
  %145 : Device = prim::Constant[value="cpu"](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:503:0
  %146 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:503:0
  %147 : int = prim::Constant[value=9223372036854775807](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %148 : int = prim::Constant[value=257](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %149 : int = prim::Constant[value=204](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %150 : int = prim::Constant[value=-257](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %151 : int = prim::Constant[value=255](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %152 : int = prim::Constant[value=-255](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %153 : float = prim::Constant[value=-inf](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:463:0
  %154 : int = prim::Constant[value=-256](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:464:0
  %155 : float = prim::Constant[value=-10000.](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:275:0
  %156 : int = prim::Constant[value=17](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %157 : float = prim::Constant[value=0.](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:326:0
  %158 : float = prim::Constant[value=0.10000000000000001](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/nn/functional.py:973:0
  %159 : int = prim::Constant[value=768](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:564:0
  %160 : int = prim::Constant[value=65536](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:564:0
  %161 : int = prim::Constant[value=16384](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:564:0
  %162 : str = prim::Constant[value="bcwd,bcdh->bcwh"](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/functional.py:327:0
  %163 : __torch__.torch.nn.modules.container.___torch_mangle_8278.ModuleList = prim::GetAttr[name="layer"](%4)
  %164 : __torch__.transformers.modeling_longformer.___torch_mangle_8277.LongformerLayer = prim::GetAttr[name="11"](%163)
  %165 : __torch__.torch.nn.modules.container.___torch_mangle_8278.ModuleList = prim::GetAttr[name="layer"](%4)
  %166 : __torch__.transformers.modeling_longformer.___torch_mangle_8258.LongformerLayer = prim::GetAttr[name="10"](%165)
  %167 : __torch__.torch.nn.modules.container.___torch_mangle_8278.ModuleList = prim::GetAttr[name="layer"](%4)
  %168 : __torch__.transformers.modeling_longformer.___torch_mangle_8239.LongformerLayer = prim::GetAttr[name="9"](%167)
  %169 : __torch__.torch.nn.modules.container.___torch_mangle_8278.ModuleList = prim::GetAttr[name="layer"](%4)
  %170 : __torch__.transformers.modeling_longformer.___torch_mangle_8220.LongformerLayer = prim::GetAttr[name="8"](%169)
  %171 : __torch__.torch.nn.modules.container.___torch_mangle_8278.ModuleList = prim::GetAttr[name="layer"](%4)
  %172 : __torch__.transformers.modeling_longformer.___torch_mangle_8201.LongformerLayer = prim::GetAttr[name="7"](%171)
  %173 : __torch__.torch.nn.modules.container.___torch_mangle_8278.ModuleList = prim::GetAttr[name="layer"](%4)
  %174 : __torch__.transformers.modeling_longformer.___torch_mangle_8182.LongformerLayer = prim::GetAttr[name="6"](%173)
  %175 : __torch__.torch.nn.modules.container.___torch_mangle_8278.ModuleList = prim::GetAttr[name="layer"](%4)
  %176 : __torch__.transformers.modeling_longformer.___torch_mangle_8163.LongformerLayer = prim::GetAttr[name="5"](%175)
  %177 : __torch__.torch.nn.modules.container.___torch_mangle_8278.ModuleList = prim::GetAttr[name="layer"](%4)
  %178 : __torch__.transformers.modeling_longformer.___torch_mangle_8144.LongformerLayer = prim::GetAttr[name="4"](%177)
  %179 : __torch__.torch.nn.modules.container.___torch_mangle_8278.ModuleList = prim::GetAttr[name="layer"](%4)
  %180 : __torch__.transformers.modeling_longformer.___torch_mangle_8125.LongformerLayer = prim::GetAttr[name="3"](%179)
  %181 : __torch__.torch.nn.modules.container.___torch_mangle_8278.ModuleList = prim::GetAttr[name="layer"](%4)
  %182 : __torch__.transformers.modeling_longformer.___torch_mangle_8106.LongformerLayer = prim::GetAttr[name="2"](%181)
  %183 : __torch__.torch.nn.modules.container.___torch_mangle_8278.ModuleList = prim::GetAttr[name="layer"](%4)
  %184 : __torch__.transformers.modeling_longformer.___torch_mangle_8087.LongformerLayer = prim::GetAttr[name="1"](%183)
  %185 : __torch__.torch.nn.modules.container.___torch_mangle_8278.ModuleList = prim::GetAttr[name="layer"](%4)
  %186 : __torch__.transformers.modeling_longformer.___torch_mangle_8068.LongformerLayer = prim::GetAttr[name="0"](%185)
  %187 : __torch__.transformers.modeling_longformer.___torch_mangle_8067.LongformerOutput = prim::GetAttr[name="output"](%186)
  %188 : __torch__.transformers.modeling_longformer.___torch_mangle_8063.LongformerIntermediate = prim::GetAttr[name="intermediate"](%186)
  %189 : __torch__.transformers.modeling_longformer.___torch_mangle_8061.LongformerAttention = prim::GetAttr[name="attention"](%186)
  %190 : __torch__.transformers.modeling_longformer.___torch_mangle_8060.LongformerSelfOutput = prim::GetAttr[name="output"](%189)
  %191 : __torch__.transformers.modeling_longformer.___torch_mangle_8056.LongformerSelfAttention = prim::GetAttr[name="self"](%189)
  %192 : __torch__.torch.nn.modules.linear.___torch_mangle_8052.Linear = prim::GetAttr[name="value"](%191)
  %193 : __torch__.torch.nn.modules.linear.___torch_mangle_8051.Linear = prim::GetAttr[name="key"](%191)
  %194 : __torch__.torch.nn.modules.linear.___torch_mangle_8050.Linear = prim::GetAttr[name="query"](%191)
  %195 : Float(17:512, 1:512, 512:1) = aten::squeeze(%attention_mask, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:241:0
  %196 : Float(17:512, 512:1) = aten::squeeze(%195, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:241:0
  %is_index_masked.1 : Bool(17:512, 512:1) = aten::lt(%196, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:22:0
  %input.7 : Float(512:768, 17:393216, 768:1) = aten::transpose(%hidden_states.1, %126, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:248:0
  %199 : Tensor = prim::GetAttr[name="bias"](%194)
  %200 : Tensor = prim::GetAttr[name="weight"](%194)
  %201 : Float(768:1, 768:768) = aten::t(%200), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %output.1 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.7, %201), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %query_vectors.1 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.1, %199, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # torch/nn/functional.py:1678:0
  %204 : Tensor = prim::GetAttr[name="bias"](%193)
  %205 : Tensor = prim::GetAttr[name="weight"](%193)
  %206 : Float(768:1, 768:768) = aten::t(%205), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %output.2 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.7, %206), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %key_vectors.1 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.2, %204, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # torch/nn/functional.py:1678:0
  %209 : Tensor = prim::GetAttr[name="bias"](%192)
  %210 : Tensor = prim::GetAttr[name="weight"](%192)
  %211 : Float(768:1, 768:768) = aten::t(%210), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %output.3 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.7, %211), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %value_vectors.1 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.3, %209, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # torch/nn/functional.py:1678:0
  %214 : int = aten::size(%input.7, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:255:0
  %215 : int = aten::size(%input.7, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:255:0
  %216 : int = aten::size(%input.7, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:255:0
  %query_vectors.2 : Float(512:13056, 17:768, 768:1) = aten::div_(%query_vectors.1, %127), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:261:0
  %218 : int[] = prim::ListConstruct(%214, %215, %128, %129), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %219 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%query_vectors.2, %218), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:263:0
  %query.1 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%219, %126, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:263:0
  %221 : int[] = prim::ListConstruct(%214, %215, %128, %129), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %222 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%key_vectors.1, %221), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:264:0
  %key.1 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%222, %126, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:264:0
  %224 : int = aten::size(%query.1, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.2 : Long() = prim::NumToTensor(%224), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %226 : int = aten::size(%query.1, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.3 : Long() = prim::NumToTensor(%226), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %228 : int = aten::size(%query.1, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.1 : Long() = prim::NumToTensor(%228), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %230 : int = aten::size(%query.1, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:472:0
  %231 : Long() = aten::floor_divide(%seq_len.3, %131), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:424:0
  %chunks_count.1 : Long() = aten::sub(%231, %132, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:478:0
  %233 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%query.1, %125, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:481:0
  %234 : Long() = aten::mul(%batch_size.2, %num_heads.1), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:481:0
  %235 : int = aten::Int(%234), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %236 : int[] = prim::ListConstruct(%235, %226, %230), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %hidden_states.2 : Float(204:64, 512:13056, 64:1) = aten::reshape(%233, %236), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:481:0
  %238 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%key.1, %125, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:482:0
  %239 : Long() = aten::mul(%batch_size.2, %num_heads.1), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:482:0
  %240 : int = aten::Int(%239), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %241 : int[] = prim::ListConstruct(%240, %226, %230), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %hidden_states.4 : Float(204:64, 512:13056, 64:1) = aten::reshape(%238, %241), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:482:0
  %243 : int = aten::size(%hidden_states.2, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:442:0
  %244 : int = aten::size(%hidden_states.2, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:443:0
  %245 : Long() = prim::NumToTensor(%244), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %246 : Long() = aten::floor_divide(%245, %133), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:424:0
  %247 : int = aten::Int(%246), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %248 : int = aten::size(%hidden_states.2, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:445:0
  %249 : int[] = prim::ListConstruct(%243, %247, %134, %248), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %hidden_states.3 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.2, %249), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:441:0
  %251 : int = aten::size(%hidden_states.3, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %252 : int = aten::size(%hidden_states.3, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %253 : Long() = prim::NumToTensor(%252), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %254 : int = aten::size(%hidden_states.3, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %255 : int = aten::size(%hidden_states.3, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %256 : Long() = aten::mul(%253, %135), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:450:0
  %257 : Long() = aten::sub(%256, %132, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:450:0
  %258 : int = aten::Int(%257), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %259 : int[] = prim::ListConstruct(%251, %258, %254, %255), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %260 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %261 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.3, %259, %260, %138), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:454:0
  %262 : int = aten::size(%hidden_states.4, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:442:0
  %263 : int = aten::size(%hidden_states.4, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:443:0
  %264 : Long() = prim::NumToTensor(%263), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %265 : Long() = aten::floor_divide(%264, %133), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:424:0
  %266 : int = aten::Int(%265), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %267 : int = aten::size(%hidden_states.4, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:445:0
  %268 : int[] = prim::ListConstruct(%262, %266, %134, %267), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %hidden_states.5 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.4, %268), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:441:0
  %270 : int = aten::size(%hidden_states.5, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %271 : int = aten::size(%hidden_states.5, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %272 : Long() = prim::NumToTensor(%271), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %273 : int = aten::size(%hidden_states.5, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %274 : int = aten::size(%hidden_states.5, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %275 : Long() = aten::mul(%272, %135), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:450:0
  %276 : Long() = aten::sub(%275, %132, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:450:0
  %277 : int = aten::Int(%276), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %278 : int[] = prim::ListConstruct(%270, %277, %273, %274), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %279 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %280 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.5, %278, %279, %138), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:454:0
  %281 : Tensor[] = prim::ListConstruct(%261, %280), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %input.8 : Float(204:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %281), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/functional.py:327:0
  %283 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %hidden_states_padded.1 : Float(204:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.8, %283, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/nn/functional.py:3552:0
  %285 : int = aten::size(%hidden_states_padded.1, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:401:0
  %286 : int = aten::size(%hidden_states_padded.1, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:401:0
  %287 : int = aten::size(%hidden_states_padded.1, %140), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:401:0
  %288 : int = aten::size(%hidden_states_padded.1, %141), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:401:0
  %289 : int[] = prim::ListConstruct(%285, %286, %287, %288), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %diagonal_chunked_attention_scores.1 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.1, %289), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:400:0
  %291 : Long() = aten::mul(%batch_size.2, %num_heads.1), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:504:0
  %292 : int = aten::Int(%291), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %293 : Long() = aten::add(%chunks_count.1, %132, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:504:0
  %294 : int = aten::Int(%293), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %295 : int[] = prim::ListConstruct(%292, %294, %142, %143), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %diagonal_attention_scores.1 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.1, %295, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:503:0
  %297 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.1, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %298 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%297, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %299 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%298, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %300 : Float(204:262656, 1:262656, 256:513, 257:1) = aten::slice(%299, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %301 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.1, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %302 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%301, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %303 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%302, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %304 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::slice(%303, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %305 : int[] = prim::ListConstruct(%149, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %306 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::view(%300, %305), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %307 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::copy_(%304, %306, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %308 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.1, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %309 : Float(204:262656, 512:513, 513:1) = aten::select(%308, %125, %140), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %310 : Float(204:262656, 256:513, 513:1) = aten::slice(%309, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %311 : Float(204:262656, 256:513, 257:1) = aten::slice(%310, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %312 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.1, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %313 : Float(204:262656, 256:513, 513:1) = aten::select(%312, %125, %140), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %314 : Float(204:262656, 256:513, 513:1) = aten::slice(%313, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %315 : Float(204:262656, 256:513, 257:1) = aten::slice(%314, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %316 : int[] = prim::ListConstruct(%149, %142, %148), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %317 : Float(204:262656, 256:513, 257:1) = aten::view(%311, %316), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %318 : Float(204:262656, 256:513, 257:1) = aten::copy_(%315, %317, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %319 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.1, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %320 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%319, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %321 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%320, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %322 : Float(204:262656, 1:262656, 256:513, 256:1) = aten::slice(%321, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %323 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.1, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %324 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%323, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %325 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%324, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %326 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::slice(%325, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %327 : int[] = prim::ListConstruct(%149, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %328 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::view(%322, %327), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %329 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::copy_(%326, %328, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %330 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.1, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %331 : Float(204:262656, 512:513, 513:1) = aten::select(%330, %125, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %332 : Float(204:262656, 255:513, 513:1) = aten::slice(%331, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %333 : Float(204:262656, 255:513, 255:1) = aten::slice(%332, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %334 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.1, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %335 : Float(204:262656, 256:513, 513:1) = aten::select(%334, %125, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %336 : Float(204:262656, 255:513, 513:1) = aten::slice(%335, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %337 : Float(204:262656, 255:513, 255:1) = aten::slice(%336, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %338 : int[] = prim::ListConstruct(%149, %151, %151), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %339 : Float(204:262656, 255:513, 255:1) = aten::view(%333, %338), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %340 : Float(204:262656, 255:513, 255:1) = aten::copy_(%337, %339, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %341 : int[] = prim::ListConstruct(%224, %228, %226, %143), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %342 : Float(17:3151872, 12:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.1, %341), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.1 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::transpose(%342, %124, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:525:0
  %344 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %345 : Float(256:257, 257:1) = aten::ones(%344, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:458:0
  %346 : Float(256:257, 257:1) = aten::tril(%345, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:458:0
  %347 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %beginning_mask_2d.1 : Float(256:257, 257:1) = aten::flip(%346, %347), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:458:0
  %349 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.1, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:459:0
  %350 : Float(1:65792, 256:257, 257:1) = aten::slice(%349, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:459:0
  %351 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%350, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.1 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%351, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:459:0
  %353 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %ending_mask.1 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.1, %353), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:460:0
  %355 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.1, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:461:0
  %356 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%355, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:461:0
  %357 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%356, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.1 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%357, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:461:0
  %359 : int = aten::size(%beginning_input.1, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:462:0
  %360 : int = aten::size(%beginning_input.1, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:462:0
  %361 : int = aten::size(%beginning_input.1, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:462:0
  %362 : int = aten::size(%beginning_input.1, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:462:0
  %363 : int[] = prim::ListConstruct(%359, %360, %361, %362), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %364 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%beginning_mask.1, %363, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:462:0
  %365 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%364, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:22:0
  %366 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%beginning_input.1, %365, %153), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:463:0
  %367 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.1, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:464:0
  %368 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%367, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:464:0
  %369 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%368, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.1 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%369, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:464:0
  %371 : int = aten::size(%ending_input.1, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:465:0
  %372 : int = aten::size(%ending_input.1, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:465:0
  %373 : int = aten::size(%ending_input.1, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:465:0
  %374 : int = aten::size(%ending_input.1, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:465:0
  %375 : int[] = prim::ListConstruct(%371, %372, %373, %374), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %376 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%ending_mask.1, %375, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:465:0
  %377 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%376, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:22:0
  %378 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%ending_input.1, %377, %153), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:466:0
  %379 : Bool(17:512, 512:1) = aten::ne(%196, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:22:0
  %380 : Bool(17:512, 512:1) = aten::slice(%379, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:272:0
  %381 : Bool(17:512, 512:1) = aten::slice(%380, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:272:0
  %382 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%381, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:272:0
  %remove_from_windowed_attention_mask.1 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%382, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:272:0
  %384 : Float(17:512, 512:1, 1:1, 1:1) = aten::type_as(%remove_from_windowed_attention_mask.1, %query.1), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:275:0
  %float_mask.1 : Float(17:512, 512:1, 1:1, 1:1) = aten::masked_fill(%384, %remove_from_windowed_attention_mask.1, %155), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:275:0
  %386 : int = aten::size(%float_mask.1, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:280:0
  %387 : int = aten::size(%float_mask.1, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:280:0
  %388 : int = aten::size(%float_mask.1, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:280:0
  %389 : int = aten::size(%float_mask.1, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:280:0
  %390 : int[] = prim::ListConstruct(%386, %387, %388, %389), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %query.2 : Float(17:512, 512:1, 1:1, 1:1) = aten::ones(%390, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:280:0
  %392 : int = aten::size(%query.2, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.3 : Long() = prim::NumToTensor(%392), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %394 : int = aten::size(%query.2, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.4 : Long() = prim::NumToTensor(%394), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %396 : int = aten::size(%query.2, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.2 : Long() = prim::NumToTensor(%396), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %398 : int = aten::size(%query.2, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:472:0
  %399 : Long() = aten::floor_divide(%seq_len.4, %131), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:424:0
  %chunks_count.2 : Long() = aten::sub(%399, %132, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:478:0
  %401 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%query.2, %125, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:481:0
  %402 : Long() = aten::mul(%batch_size.3, %num_heads.2), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:481:0
  %403 : int = aten::Int(%402), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %404 : int[] = prim::ListConstruct(%403, %394, %398), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %hidden_states.6 : Float(17:512, 512:1, 1:1) = aten::reshape(%401, %404), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:481:0
  %406 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%float_mask.1, %125, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:482:0
  %407 : Long() = aten::mul(%batch_size.3, %num_heads.2), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:482:0
  %408 : int = aten::Int(%407), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %409 : int[] = prim::ListConstruct(%408, %394, %398), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %hidden_states.8 : Float(17:512, 512:1, 1:1) = aten::reshape(%406, %409), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:482:0
  %411 : int = aten::size(%hidden_states.6, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:442:0
  %412 : int = aten::size(%hidden_states.6, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:443:0
  %413 : Long() = prim::NumToTensor(%412), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %414 : Long() = aten::floor_divide(%413, %133), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:424:0
  %415 : int = aten::Int(%414), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %416 : int = aten::size(%hidden_states.6, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:445:0
  %417 : int[] = prim::ListConstruct(%411, %415, %134, %416), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %hidden_states.7 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.6, %417), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:441:0
  %419 : int = aten::size(%hidden_states.7, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %420 : int = aten::size(%hidden_states.7, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %421 : Long() = prim::NumToTensor(%420), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %422 : int = aten::size(%hidden_states.7, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %423 : int = aten::size(%hidden_states.7, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %424 : Long() = aten::mul(%421, %135), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:450:0
  %425 : Long() = aten::sub(%424, %132, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:450:0
  %426 : int = aten::Int(%425), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %427 : int[] = prim::ListConstruct(%419, %426, %422, %423), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %428 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %429 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.7, %427, %428, %138), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:454:0
  %430 : int = aten::size(%hidden_states.8, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:442:0
  %431 : int = aten::size(%hidden_states.8, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:443:0
  %432 : Long() = prim::NumToTensor(%431), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %433 : Long() = aten::floor_divide(%432, %133), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:424:0
  %434 : int = aten::Int(%433), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %435 : int = aten::size(%hidden_states.8, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:445:0
  %436 : int[] = prim::ListConstruct(%430, %434, %134, %435), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %hidden_states.9 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.8, %436), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:441:0
  %438 : int = aten::size(%hidden_states.9, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %439 : int = aten::size(%hidden_states.9, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %440 : Long() = prim::NumToTensor(%439), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %441 : int = aten::size(%hidden_states.9, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %442 : int = aten::size(%hidden_states.9, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:449:0
  %443 : Long() = aten::mul(%440, %135), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:450:0
  %444 : Long() = aten::sub(%443, %132, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:450:0
  %445 : int = aten::Int(%444), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %446 : int[] = prim::ListConstruct(%438, %445, %441, %442), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %447 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %448 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.9, %446, %447, %138), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:454:0
  %449 : Tensor[] = prim::ListConstruct(%429, %448), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %input.9 : Float(17:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %449), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/functional.py:327:0
  %451 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %hidden_states_padded.2 : Float(17:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.9, %451, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/nn/functional.py:3552:0
  %453 : int = aten::size(%hidden_states_padded.2, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:401:0
  %454 : int = aten::size(%hidden_states_padded.2, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:401:0
  %455 : int = aten::size(%hidden_states_padded.2, %140), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:401:0
  %456 : int = aten::size(%hidden_states_padded.2, %141), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:401:0
  %457 : int[] = prim::ListConstruct(%453, %454, %455, %456), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %diagonal_chunked_attention_scores.2 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.2, %457), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:400:0
  %459 : Long() = aten::mul(%batch_size.3, %num_heads.2), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:504:0
  %460 : int = aten::Int(%459), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %461 : Long() = aten::add(%chunks_count.2, %132, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:504:0
  %462 : int = aten::Int(%461), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %463 : int[] = prim::ListConstruct(%460, %462, %142, %143), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %diagonal_attention_scores.2 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.2, %463, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:503:0
  %465 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.2, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %466 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%465, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %467 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%466, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %468 : Float(17:262656, 1:262656, 256:513, 257:1) = aten::slice(%467, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %469 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.2, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %470 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%469, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %471 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%470, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %472 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::slice(%471, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %473 : int[] = prim::ListConstruct(%156, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %474 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::view(%468, %473), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %475 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::copy_(%472, %474, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:509:0
  %476 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.2, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %477 : Float(17:262656, 512:513, 513:1) = aten::select(%476, %125, %140), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %478 : Float(17:262656, 256:513, 513:1) = aten::slice(%477, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %479 : Float(17:262656, 256:513, 257:1) = aten::slice(%478, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %480 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.2, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %481 : Float(17:262656, 256:513, 513:1) = aten::select(%480, %125, %140), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %482 : Float(17:262656, 256:513, 513:1) = aten::slice(%481, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %483 : Float(17:262656, 256:513, 257:1) = aten::slice(%482, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %484 : int[] = prim::ListConstruct(%156, %142, %148), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %485 : Float(17:262656, 256:513, 257:1) = aten::view(%479, %484), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %486 : Float(17:262656, 256:513, 257:1) = aten::copy_(%483, %485, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:512:0
  %487 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.2, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %488 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%487, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %489 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%488, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %490 : Float(17:262656, 1:262656, 256:513, 256:1) = aten::slice(%489, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %491 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.2, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %492 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%491, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %493 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%492, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %494 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::slice(%493, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %495 : int[] = prim::ListConstruct(%156, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %496 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::view(%490, %495), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %497 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::copy_(%494, %496, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:516:0
  %498 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.2, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %499 : Float(17:262656, 512:513, 513:1) = aten::select(%498, %125, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %500 : Float(17:262656, 255:513, 513:1) = aten::slice(%499, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %501 : Float(17:262656, 255:513, 255:1) = aten::slice(%500, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %502 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.2, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %503 : Float(17:262656, 256:513, 513:1) = aten::select(%502, %125, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %504 : Float(17:262656, 255:513, 513:1) = aten::slice(%503, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %505 : Float(17:262656, 255:513, 255:1) = aten::slice(%504, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %506 : int[] = prim::ListConstruct(%156, %151, %151), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %507 : Float(17:262656, 255:513, 255:1) = aten::view(%501, %506), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %508 : Float(17:262656, 255:513, 255:1) = aten::copy_(%505, %507, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:520:0
  %509 : int[] = prim::ListConstruct(%392, %396, %394, %143), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %510 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.2, %509), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.2 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::transpose(%510, %124, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:525:0
  %512 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %513 : Float(256:257, 257:1) = aten::ones(%512, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:458:0
  %514 : Float(256:257, 257:1) = aten::tril(%513, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:458:0
  %515 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %beginning_mask_2d.2 : Float(256:257, 257:1) = aten::flip(%514, %515), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:458:0
  %517 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.2, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:459:0
  %518 : Float(1:65792, 256:257, 257:1) = aten::slice(%517, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:459:0
  %519 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%518, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.2 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%519, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:459:0
  %521 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %ending_mask.2 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.2, %521), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:460:0
  %523 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.2, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:461:0
  %524 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%523, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:461:0
  %525 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%524, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.2 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%525, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:461:0
  %527 : int = aten::size(%beginning_input.2, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:462:0
  %528 : int = aten::size(%beginning_input.2, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:462:0
  %529 : int = aten::size(%beginning_input.2, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:462:0
  %530 : int = aten::size(%beginning_input.2, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:462:0
  %531 : int[] = prim::ListConstruct(%527, %528, %529, %530), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %532 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%beginning_mask.2, %531, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:462:0
  %533 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%532, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:22:0
  %534 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%beginning_input.2, %533, %153), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:463:0
  %535 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.2, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:464:0
  %536 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%535, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:464:0
  %537 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%536, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.2 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%537, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:464:0
  %539 : int = aten::size(%ending_input.2, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:465:0
  %540 : int = aten::size(%ending_input.2, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:465:0
  %541 : int = aten::size(%ending_input.2, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:465:0
  %542 : int = aten::size(%ending_input.2, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:465:0
  %543 : int[] = prim::ListConstruct(%539, %540, %541, %542), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %544 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%ending_mask.2, %543, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:465:0
  %545 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%544, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:22:0
  %546 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%ending_input.2, %545, %153), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:466:0
  %attn_scores.1 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::add_(%input_tensor.1, %input_tensor.2, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:284:0
  %attn_probs_fp32.1 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::softmax(%attn_scores.1, %140, %144), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/nn/functional.py:1500:0
  %549 : Bool(17:512, 512:1) = aten::slice(%is_index_masked.1, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:326:0
  %550 : Bool(17:512, 512:1) = aten::slice(%549, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:326:0
  %551 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%550, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:326:0
  %552 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%551, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:326:0
  %input.10 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::masked_fill(%attn_probs_fp32.1, %552, %157), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:326:0
  %attn_probs.2 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::dropout(%input.10, %158, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/nn/functional.py:973:0
  %555 : int[] = prim::ListConstruct(%214, %215, %128, %129), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %556 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%value_vectors.1, %555), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:331:0
  %value.1 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%556, %126, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:331:0
  %558 : int = aten::size(%value.1, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:537:0
  %batch_size.4 : Long() = prim::NumToTensor(%558), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %560 : int = aten::size(%value.1, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:537:0
  %seq_len.5 : Long() = prim::NumToTensor(%560), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %562 : int = aten::size(%value.1, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:537:0
  %num_heads.3 : Long() = prim::NumToTensor(%562), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %564 : int = aten::size(%value.1, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:537:0
  %565 : Long() = aten::floor_divide(%seq_len.5, %131), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:424:0
  %chunks_count.3 : Long() = aten::sub(%565, %132, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:542:0
  %567 : Float(17:3151872, 12:513, 512:6156, 513:1) = aten::transpose(%attn_probs.2, %125, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:545:0
  %568 : Long() = aten::mul(%batch_size.4, %num_heads.3), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:546:0
  %569 : int = aten::Int(%568), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %570 : Long() = aten::floor_divide(%seq_len.5, %131), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/tensor.py:424:0
  %571 : int = aten::Int(%570), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %572 : int[] = prim::ListConstruct(%569, %571, %142, %143), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %chunked_hidden_states.1 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::reshape(%567, %572), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:545:0
  %574 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%value.1, %125, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:550:0
  %575 : Long() = aten::mul(%batch_size.4, %num_heads.3), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:550:0
  %576 : int = aten::Int(%575), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %577 : int[] = prim::ListConstruct(%576, %560, %564), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %input.11 : Float(204:64, 512:13056, 64:1) = aten::reshape(%574, %577), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:550:0
  %579 : int[] = prim::ListConstruct(%126, %126, %142, %142), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %padded_value.1 : Float(204:65536, 1024:64, 64:1) = aten::constant_pad_nd(%input.11, %579, %140), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/nn/functional.py:3552:0
  %581 : Long() = aten::mul(%batch_size.4, %num_heads.3), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:556:0
  %582 : int = aten::Int(%581), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %583 : Long() = aten::add(%chunks_count.3, %132, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:556:0
  %584 : int = aten::Int(%583), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %585 : int[] = prim::ListConstruct(%582, %584, %159, %564), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %586 : int[] = prim::ListConstruct(%160, %161, %129, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %587 : Float(204:65536, 2:16384, 768:64, 64:1) = aten::as_strided(%padded_value.1, %585, %586, %138), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:564:0
  %588 : int = aten::size(%chunked_hidden_states.1, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:420:0
  %589 : int = aten::size(%chunked_hidden_states.1, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:420:0
  %590 : int = aten::size(%chunked_hidden_states.1, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:420:0
  %window_overlap.1 : Long() = prim::NumToTensor(%590), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %592 : int = aten::size(%chunked_hidden_states.1, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:420:0
  %hidden_dim.1 : Long() = prim::NumToTensor(%592), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %594 : Long() = aten::add(%window_overlap.1, %132, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:422:0
  %595 : int = aten::Int(%594), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %596 : int[] = prim::ListConstruct(%126, %595), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %chunked_hidden_states.2 : Float(204:394240, 2:197120, 256:770, 770:1) = aten::constant_pad_nd(%chunked_hidden_states.1, %596, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/nn/functional.py:3552:0
  %598 : int[] = prim::ListConstruct(%588, %589, %140), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %chunked_hidden_states.3 : Float(204:394240, 2:197120, 197120:1) = aten::view(%chunked_hidden_states.2, %598), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:424:0
  %600 : Long() = aten::neg(%window_overlap.1), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:428:0
  %601 : int = aten::Int(%600), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %602 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%chunked_hidden_states.3, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:427:0
  %603 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%602, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:427:0
  %chunked_hidden_states.4 : Float(204:394240, 2:197120, 196864:1) = aten::slice(%603, %124, %126, %601, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:427:0
  %605 : Long() = aten::add(%window_overlap.1, %hidden_dim.1, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:431:0
  %606 : int = aten::Int(%605), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %607 : int[] = prim::ListConstruct(%588, %589, %590, %606), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %chunked_hidden_states.5 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::view(%chunked_hidden_states.4, %607), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:430:0
  %609 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%chunked_hidden_states.5, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:433:0
  %610 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%609, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:433:0
  %611 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%610, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:433:0
  %612 : Float(204:394240, 2:197120, 256:769, 768:1) = aten::slice(%611, %130, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:433:0
  %613 : Tensor[] = prim::ListConstruct(%612, %587), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %context.1 : Float(204:32768, 2:16384, 256:64, 64:1) = aten::einsum(%162, %613), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/functional.py:327:0
  %615 : int[] = prim::ListConstruct(%558, %562, %560, %564), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %616 : Float(17:393216, 12:32768, 512:64, 64:1) = aten::view(%context.1, %615), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:569:0
  %attn_output.1 : Float(17:393216, 512:64, 12:32768, 64:1) = aten::transpose(%616, %125, %124), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:569:0
  %618 : Float(512:64, 17:393216, 12:32768, 64:1) = aten::transpose(%attn_output.1, %126, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:350:0
  %619 : int[] = prim::ListConstruct(%214, %215, %216), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %620 : Float(512:13056, 17:768, 768:1) = aten::reshape(%618, %619), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:350:0
  %attn_output.2 : Float(512:13056, 17:768, 768:1) = aten::contiguous(%620, %126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:350:0
  %input.12 : Float(17:768, 512:13056, 768:1) = aten::transpose(%attn_output.2, %126, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_longformer.py:374:0
  %623 : __torch__.torch.nn.modules.normalization.___torch_mangle_8058.LayerNorm = prim::GetAttr[name="LayerNorm"](%190)
  %624 : __torch__.torch.nn.modules.linear.___torch_mangle_8057.Linear = prim::GetAttr[name="dense"](%190)
  %625 : Tensor = prim::GetAttr[name="bias"](%624)
  %626 : Tensor = prim::GetAttr[name="weight"](%624)
  %627 : Float(768:1, 768:768) = aten::t(%626), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %output.4 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.12, %627), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %input.13 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.4, %625, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.10 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.13, %158, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dropout # torch/nn/functional.py:973:0
  %input.14 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.10, %hidden_states.1, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output # transformers/modeling_longformer.py:758:0
  %632 : Tensor = prim::GetAttr[name="bias"](%623)
  %633 : Tensor = prim::GetAttr[name="weight"](%623)
  %634 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm
  %input_tensor.3 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.14, %634, %633, %632, %123, %122), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %636 : __torch__.torch.nn.modules.linear.___torch_mangle_8062.Linear = prim::GetAttr[name="dense"](%188)
  %637 : Tensor = prim::GetAttr[name="bias"](%636)
  %638 : Tensor = prim::GetAttr[name="weight"](%636)
  %639 : Float(768:1, 3072:768) = aten::t(%638), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.5 : Float(17:1572864, 512:3072, 3072:1) = aten::matmul(%input_tensor.3, %639), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.15 : Float(17:1572864, 512:3072, 3072:1) = aten::add_(%output.5, %637, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.16 : Float(17:1572864, 512:3072, 3072:1) = aten::gelu(%input.15), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # torch/nn/functional.py:1369:0
  %643 : __torch__.torch.nn.modules.normalization.___torch_mangle_8065.LayerNorm = prim::GetAttr[name="LayerNorm"](%187)
  %644 : __torch__.torch.nn.modules.linear.___torch_mangle_8064.Linear = prim::GetAttr[name="dense"](%187)
  %645 : Tensor = prim::GetAttr[name="bias"](%644)
  %646 : Tensor = prim::GetAttr[name="weight"](%644)
  %647 : Float(3072:1, 768:3072) = aten::t(%646), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %output.6 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.16, %647), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %input.17 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.6, %645, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.11 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.17, %158, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dropout # torch/nn/functional.py:973:0
  %input.18 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.11, %input_tensor.3, %125), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output # transformers/modeling_longformer.py:830:0
  %652 : Tensor = prim::GetAttr[name="bias"](%643)
  %653 : Tensor = prim::GetAttr[name="weight"](%643)
  %654 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.LayerNorm
  %hidden_states.12 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.18, %654, %653, %652, %123, %122), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.LayerNorm # torch/nn/functional.py:2048:0
  %656 : __torch__.transformers.modeling_longformer.___torch_mangle_8086.LongformerOutput = prim::GetAttr[name="output"](%184)
  %657 : __torch__.transformers.modeling_longformer.___torch_mangle_8082.LongformerIntermediate = prim::GetAttr[name="intermediate"](%184)
  %658 : __torch__.transformers.modeling_longformer.___torch_mangle_8080.LongformerAttention = prim::GetAttr[name="attention"](%184)
  %659 : __torch__.transformers.modeling_longformer.___torch_mangle_8079.LongformerSelfOutput = prim::GetAttr[name="output"](%658)
  %660 : __torch__.transformers.modeling_longformer.___torch_mangle_8075.LongformerSelfAttention = prim::GetAttr[name="self"](%658)
  %661 : __torch__.torch.nn.modules.linear.___torch_mangle_8071.Linear = prim::GetAttr[name="value"](%660)
  %662 : __torch__.torch.nn.modules.linear.___torch_mangle_8070.Linear = prim::GetAttr[name="key"](%660)
  %663 : __torch__.torch.nn.modules.linear.___torch_mangle_8069.Linear = prim::GetAttr[name="query"](%660)
  %664 : Float(17:512, 1:512, 512:1) = aten::squeeze(%attention_mask, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:241:0
  %665 : Float(17:512, 512:1) = aten::squeeze(%664, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:241:0
  %is_index_masked.2 : Bool(17:512, 512:1) = aten::lt(%665, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/tensor.py:22:0
  %input.19 : Float(512:768, 17:393216, 768:1) = aten::transpose(%hidden_states.12, %126, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:248:0
  %668 : Tensor = prim::GetAttr[name="bias"](%663)
  %669 : Tensor = prim::GetAttr[name="weight"](%663)
  %670 : Float(768:1, 768:768) = aten::t(%669), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %output.7 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.19, %670), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %query_vectors.3 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.7, %668, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # torch/nn/functional.py:1678:0
  %673 : Tensor = prim::GetAttr[name="bias"](%662)
  %674 : Tensor = prim::GetAttr[name="weight"](%662)
  %675 : Float(768:1, 768:768) = aten::t(%674), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %output.8 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.19, %675), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %key_vectors.2 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.8, %673, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # torch/nn/functional.py:1678:0
  %678 : Tensor = prim::GetAttr[name="bias"](%661)
  %679 : Tensor = prim::GetAttr[name="weight"](%661)
  %680 : Float(768:1, 768:768) = aten::t(%679), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %output.9 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.19, %680), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %value_vectors.2 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.9, %678, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # torch/nn/functional.py:1678:0
  %683 : int = aten::size(%input.19, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:255:0
  %684 : int = aten::size(%input.19, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:255:0
  %685 : int = aten::size(%input.19, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:255:0
  %query_vectors.4 : Float(512:13056, 17:768, 768:1) = aten::div_(%query_vectors.3, %127), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:261:0
  %687 : int[] = prim::ListConstruct(%683, %684, %128, %129), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %688 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%query_vectors.4, %687), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:263:0
  %query.3 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%688, %126, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:263:0
  %690 : int[] = prim::ListConstruct(%683, %684, %128, %129), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %691 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%key_vectors.2, %690), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:264:0
  %key.2 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%691, %126, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:264:0
  %693 : int = aten::size(%query.3, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.6 : Long() = prim::NumToTensor(%693), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %695 : int = aten::size(%query.3, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.7 : Long() = prim::NumToTensor(%695), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %697 : int = aten::size(%query.3, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.4 : Long() = prim::NumToTensor(%697), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %699 : int = aten::size(%query.3, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:472:0
  %700 : Long() = aten::floor_divide(%seq_len.7, %131), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/tensor.py:424:0
  %chunks_count.4 : Long() = aten::sub(%700, %132, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:478:0
  %702 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%query.3, %125, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:481:0
  %703 : Long() = aten::mul(%batch_size.6, %num_heads.4), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:481:0
  %704 : int = aten::Int(%703), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %705 : int[] = prim::ListConstruct(%704, %695, %699), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %hidden_states.13 : Float(204:64, 512:13056, 64:1) = aten::reshape(%702, %705), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:481:0
  %707 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%key.2, %125, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:482:0
  %708 : Long() = aten::mul(%batch_size.6, %num_heads.4), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:482:0
  %709 : int = aten::Int(%708), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %710 : int[] = prim::ListConstruct(%709, %695, %699), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %hidden_states.15 : Float(204:64, 512:13056, 64:1) = aten::reshape(%707, %710), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:482:0
  %712 : int = aten::size(%hidden_states.13, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:442:0
  %713 : int = aten::size(%hidden_states.13, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:443:0
  %714 : Long() = prim::NumToTensor(%713), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %715 : Long() = aten::floor_divide(%714, %133), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/tensor.py:424:0
  %716 : int = aten::Int(%715), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %717 : int = aten::size(%hidden_states.13, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:445:0
  %718 : int[] = prim::ListConstruct(%712, %716, %134, %717), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %hidden_states.14 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.13, %718), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:441:0
  %720 : int = aten::size(%hidden_states.14, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %721 : int = aten::size(%hidden_states.14, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %722 : Long() = prim::NumToTensor(%721), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %723 : int = aten::size(%hidden_states.14, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %724 : int = aten::size(%hidden_states.14, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %725 : Long() = aten::mul(%722, %135), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:450:0
  %726 : Long() = aten::sub(%725, %132, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:450:0
  %727 : int = aten::Int(%726), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %728 : int[] = prim::ListConstruct(%720, %727, %723, %724), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %729 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %730 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.14, %728, %729, %138), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:454:0
  %731 : int = aten::size(%hidden_states.15, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:442:0
  %732 : int = aten::size(%hidden_states.15, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:443:0
  %733 : Long() = prim::NumToTensor(%732), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %734 : Long() = aten::floor_divide(%733, %133), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/tensor.py:424:0
  %735 : int = aten::Int(%734), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %736 : int = aten::size(%hidden_states.15, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:445:0
  %737 : int[] = prim::ListConstruct(%731, %735, %134, %736), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %hidden_states.16 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.15, %737), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:441:0
  %739 : int = aten::size(%hidden_states.16, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %740 : int = aten::size(%hidden_states.16, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %741 : Long() = prim::NumToTensor(%740), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %742 : int = aten::size(%hidden_states.16, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %743 : int = aten::size(%hidden_states.16, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %744 : Long() = aten::mul(%741, %135), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:450:0
  %745 : Long() = aten::sub(%744, %132, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:450:0
  %746 : int = aten::Int(%745), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %747 : int[] = prim::ListConstruct(%739, %746, %742, %743), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %748 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %749 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.16, %747, %748, %138), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:454:0
  %750 : Tensor[] = prim::ListConstruct(%730, %749), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %input.20 : Float(204:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %750), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/functional.py:327:0
  %752 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %hidden_states_padded.3 : Float(204:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.20, %752, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/nn/functional.py:3552:0
  %754 : int = aten::size(%hidden_states_padded.3, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:401:0
  %755 : int = aten::size(%hidden_states_padded.3, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:401:0
  %756 : int = aten::size(%hidden_states_padded.3, %140), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:401:0
  %757 : int = aten::size(%hidden_states_padded.3, %141), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:401:0
  %758 : int[] = prim::ListConstruct(%754, %755, %756, %757), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %diagonal_chunked_attention_scores.3 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.3, %758), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:400:0
  %760 : Long() = aten::mul(%batch_size.6, %num_heads.4), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:504:0
  %761 : int = aten::Int(%760), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %762 : Long() = aten::add(%chunks_count.4, %132, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:504:0
  %763 : int = aten::Int(%762), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %764 : int[] = prim::ListConstruct(%761, %763, %142, %143), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %diagonal_attention_scores.3 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.3, %764, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:503:0
  %766 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.3, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %767 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%766, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %768 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%767, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %769 : Float(204:262656, 1:262656, 256:513, 257:1) = aten::slice(%768, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %770 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.3, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %771 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%770, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %772 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%771, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %773 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::slice(%772, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %774 : int[] = prim::ListConstruct(%149, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %775 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::view(%769, %774), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %776 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::copy_(%773, %775, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %777 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.3, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %778 : Float(204:262656, 512:513, 513:1) = aten::select(%777, %125, %140), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %779 : Float(204:262656, 256:513, 513:1) = aten::slice(%778, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %780 : Float(204:262656, 256:513, 257:1) = aten::slice(%779, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %781 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.3, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %782 : Float(204:262656, 256:513, 513:1) = aten::select(%781, %125, %140), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %783 : Float(204:262656, 256:513, 513:1) = aten::slice(%782, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %784 : Float(204:262656, 256:513, 257:1) = aten::slice(%783, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %785 : int[] = prim::ListConstruct(%149, %142, %148), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %786 : Float(204:262656, 256:513, 257:1) = aten::view(%780, %785), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %787 : Float(204:262656, 256:513, 257:1) = aten::copy_(%784, %786, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %788 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.3, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %789 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%788, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %790 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%789, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %791 : Float(204:262656, 1:262656, 256:513, 256:1) = aten::slice(%790, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %792 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.3, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %793 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%792, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %794 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%793, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %795 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::slice(%794, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %796 : int[] = prim::ListConstruct(%149, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %797 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::view(%791, %796), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %798 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::copy_(%795, %797, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %799 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.3, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %800 : Float(204:262656, 512:513, 513:1) = aten::select(%799, %125, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %801 : Float(204:262656, 255:513, 513:1) = aten::slice(%800, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %802 : Float(204:262656, 255:513, 255:1) = aten::slice(%801, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %803 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.3, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %804 : Float(204:262656, 256:513, 513:1) = aten::select(%803, %125, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %805 : Float(204:262656, 255:513, 513:1) = aten::slice(%804, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %806 : Float(204:262656, 255:513, 255:1) = aten::slice(%805, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %807 : int[] = prim::ListConstruct(%149, %151, %151), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %808 : Float(204:262656, 255:513, 255:1) = aten::view(%802, %807), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %809 : Float(204:262656, 255:513, 255:1) = aten::copy_(%806, %808, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %810 : int[] = prim::ListConstruct(%693, %697, %695, %143), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %811 : Float(17:3151872, 12:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.3, %810), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.4 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::transpose(%811, %124, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:525:0
  %813 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %814 : Float(256:257, 257:1) = aten::ones(%813, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:458:0
  %815 : Float(256:257, 257:1) = aten::tril(%814, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:458:0
  %816 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %beginning_mask_2d.3 : Float(256:257, 257:1) = aten::flip(%815, %816), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:458:0
  %818 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.3, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:459:0
  %819 : Float(1:65792, 256:257, 257:1) = aten::slice(%818, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:459:0
  %820 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%819, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.3 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%820, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:459:0
  %822 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %ending_mask.3 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.3, %822), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:460:0
  %824 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.4, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:461:0
  %825 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%824, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:461:0
  %826 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%825, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.3 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%826, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:461:0
  %828 : int = aten::size(%beginning_input.3, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:462:0
  %829 : int = aten::size(%beginning_input.3, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:462:0
  %830 : int = aten::size(%beginning_input.3, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:462:0
  %831 : int = aten::size(%beginning_input.3, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:462:0
  %832 : int[] = prim::ListConstruct(%828, %829, %830, %831), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %833 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%beginning_mask.3, %832, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:462:0
  %834 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%833, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/tensor.py:22:0
  %835 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%beginning_input.3, %834, %153), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:463:0
  %836 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.4, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:464:0
  %837 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%836, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:464:0
  %838 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%837, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.3 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%838, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:464:0
  %840 : int = aten::size(%ending_input.3, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:465:0
  %841 : int = aten::size(%ending_input.3, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:465:0
  %842 : int = aten::size(%ending_input.3, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:465:0
  %843 : int = aten::size(%ending_input.3, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:465:0
  %844 : int[] = prim::ListConstruct(%840, %841, %842, %843), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %845 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%ending_mask.3, %844, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:465:0
  %846 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%845, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/tensor.py:22:0
  %847 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%ending_input.3, %846, %153), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:466:0
  %848 : Bool(17:512, 512:1) = aten::ne(%665, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/tensor.py:22:0
  %849 : Bool(17:512, 512:1) = aten::slice(%848, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:272:0
  %850 : Bool(17:512, 512:1) = aten::slice(%849, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:272:0
  %851 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%850, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:272:0
  %remove_from_windowed_attention_mask.2 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%851, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:272:0
  %853 : Float(17:512, 512:1, 1:1, 1:1) = aten::type_as(%remove_from_windowed_attention_mask.2, %query.3), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:275:0
  %float_mask.2 : Float(17:512, 512:1, 1:1, 1:1) = aten::masked_fill(%853, %remove_from_windowed_attention_mask.2, %155), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:275:0
  %855 : int = aten::size(%float_mask.2, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:280:0
  %856 : int = aten::size(%float_mask.2, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:280:0
  %857 : int = aten::size(%float_mask.2, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:280:0
  %858 : int = aten::size(%float_mask.2, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:280:0
  %859 : int[] = prim::ListConstruct(%855, %856, %857, %858), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %query.4 : Float(17:512, 512:1, 1:1, 1:1) = aten::ones(%859, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:280:0
  %861 : int = aten::size(%query.4, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.7 : Long() = prim::NumToTensor(%861), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %863 : int = aten::size(%query.4, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.8 : Long() = prim::NumToTensor(%863), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %865 : int = aten::size(%query.4, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.5 : Long() = prim::NumToTensor(%865), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %867 : int = aten::size(%query.4, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:472:0
  %868 : Long() = aten::floor_divide(%seq_len.8, %131), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/tensor.py:424:0
  %chunks_count.5 : Long() = aten::sub(%868, %132, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:478:0
  %870 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%query.4, %125, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:481:0
  %871 : Long() = aten::mul(%batch_size.7, %num_heads.5), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:481:0
  %872 : int = aten::Int(%871), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %873 : int[] = prim::ListConstruct(%872, %863, %867), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %hidden_states.17 : Float(17:512, 512:1, 1:1) = aten::reshape(%870, %873), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:481:0
  %875 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%float_mask.2, %125, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:482:0
  %876 : Long() = aten::mul(%batch_size.7, %num_heads.5), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:482:0
  %877 : int = aten::Int(%876), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %878 : int[] = prim::ListConstruct(%877, %863, %867), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %hidden_states.19 : Float(17:512, 512:1, 1:1) = aten::reshape(%875, %878), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:482:0
  %880 : int = aten::size(%hidden_states.17, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:442:0
  %881 : int = aten::size(%hidden_states.17, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:443:0
  %882 : Long() = prim::NumToTensor(%881), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %883 : Long() = aten::floor_divide(%882, %133), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/tensor.py:424:0
  %884 : int = aten::Int(%883), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %885 : int = aten::size(%hidden_states.17, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:445:0
  %886 : int[] = prim::ListConstruct(%880, %884, %134, %885), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %hidden_states.18 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.17, %886), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:441:0
  %888 : int = aten::size(%hidden_states.18, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %889 : int = aten::size(%hidden_states.18, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %890 : Long() = prim::NumToTensor(%889), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %891 : int = aten::size(%hidden_states.18, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %892 : int = aten::size(%hidden_states.18, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %893 : Long() = aten::mul(%890, %135), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:450:0
  %894 : Long() = aten::sub(%893, %132, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:450:0
  %895 : int = aten::Int(%894), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %896 : int[] = prim::ListConstruct(%888, %895, %891, %892), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %897 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %898 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.18, %896, %897, %138), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:454:0
  %899 : int = aten::size(%hidden_states.19, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:442:0
  %900 : int = aten::size(%hidden_states.19, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:443:0
  %901 : Long() = prim::NumToTensor(%900), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %902 : Long() = aten::floor_divide(%901, %133), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/tensor.py:424:0
  %903 : int = aten::Int(%902), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %904 : int = aten::size(%hidden_states.19, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:445:0
  %905 : int[] = prim::ListConstruct(%899, %903, %134, %904), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %hidden_states.20 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.19, %905), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:441:0
  %907 : int = aten::size(%hidden_states.20, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %908 : int = aten::size(%hidden_states.20, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %909 : Long() = prim::NumToTensor(%908), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %910 : int = aten::size(%hidden_states.20, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %911 : int = aten::size(%hidden_states.20, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:449:0
  %912 : Long() = aten::mul(%909, %135), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:450:0
  %913 : Long() = aten::sub(%912, %132, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:450:0
  %914 : int = aten::Int(%913), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %915 : int[] = prim::ListConstruct(%907, %914, %910, %911), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %916 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %917 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.20, %915, %916, %138), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:454:0
  %918 : Tensor[] = prim::ListConstruct(%898, %917), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %input.21 : Float(17:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %918), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/functional.py:327:0
  %920 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %hidden_states_padded.4 : Float(17:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.21, %920, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/nn/functional.py:3552:0
  %922 : int = aten::size(%hidden_states_padded.4, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:401:0
  %923 : int = aten::size(%hidden_states_padded.4, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:401:0
  %924 : int = aten::size(%hidden_states_padded.4, %140), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:401:0
  %925 : int = aten::size(%hidden_states_padded.4, %141), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:401:0
  %926 : int[] = prim::ListConstruct(%922, %923, %924, %925), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %diagonal_chunked_attention_scores.4 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.4, %926), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:400:0
  %928 : Long() = aten::mul(%batch_size.7, %num_heads.5), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:504:0
  %929 : int = aten::Int(%928), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %930 : Long() = aten::add(%chunks_count.5, %132, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:504:0
  %931 : int = aten::Int(%930), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %932 : int[] = prim::ListConstruct(%929, %931, %142, %143), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %diagonal_attention_scores.4 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.4, %932, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:503:0
  %934 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.4, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %935 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%934, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %936 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%935, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %937 : Float(17:262656, 1:262656, 256:513, 257:1) = aten::slice(%936, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %938 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.4, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %939 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%938, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %940 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%939, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %941 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::slice(%940, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %942 : int[] = prim::ListConstruct(%156, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %943 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::view(%937, %942), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %944 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::copy_(%941, %943, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:509:0
  %945 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.4, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %946 : Float(17:262656, 512:513, 513:1) = aten::select(%945, %125, %140), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %947 : Float(17:262656, 256:513, 513:1) = aten::slice(%946, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %948 : Float(17:262656, 256:513, 257:1) = aten::slice(%947, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %949 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.4, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %950 : Float(17:262656, 256:513, 513:1) = aten::select(%949, %125, %140), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %951 : Float(17:262656, 256:513, 513:1) = aten::slice(%950, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %952 : Float(17:262656, 256:513, 257:1) = aten::slice(%951, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %953 : int[] = prim::ListConstruct(%156, %142, %148), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %954 : Float(17:262656, 256:513, 257:1) = aten::view(%948, %953), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %955 : Float(17:262656, 256:513, 257:1) = aten::copy_(%952, %954, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:512:0
  %956 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.4, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %957 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%956, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %958 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%957, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %959 : Float(17:262656, 1:262656, 256:513, 256:1) = aten::slice(%958, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %960 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.4, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %961 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%960, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %962 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%961, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %963 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::slice(%962, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %964 : int[] = prim::ListConstruct(%156, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %965 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::view(%959, %964), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %966 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::copy_(%963, %965, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:516:0
  %967 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.4, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %968 : Float(17:262656, 512:513, 513:1) = aten::select(%967, %125, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %969 : Float(17:262656, 255:513, 513:1) = aten::slice(%968, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %970 : Float(17:262656, 255:513, 255:1) = aten::slice(%969, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %971 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.4, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %972 : Float(17:262656, 256:513, 513:1) = aten::select(%971, %125, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %973 : Float(17:262656, 255:513, 513:1) = aten::slice(%972, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %974 : Float(17:262656, 255:513, 255:1) = aten::slice(%973, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %975 : int[] = prim::ListConstruct(%156, %151, %151), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %976 : Float(17:262656, 255:513, 255:1) = aten::view(%970, %975), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %977 : Float(17:262656, 255:513, 255:1) = aten::copy_(%974, %976, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:520:0
  %978 : int[] = prim::ListConstruct(%861, %865, %863, %143), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %979 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.4, %978), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.5 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::transpose(%979, %124, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:525:0
  %981 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %982 : Float(256:257, 257:1) = aten::ones(%981, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:458:0
  %983 : Float(256:257, 257:1) = aten::tril(%982, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:458:0
  %984 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %beginning_mask_2d.4 : Float(256:257, 257:1) = aten::flip(%983, %984), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:458:0
  %986 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.4, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:459:0
  %987 : Float(1:65792, 256:257, 257:1) = aten::slice(%986, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:459:0
  %988 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%987, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.4 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%988, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:459:0
  %990 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %ending_mask.4 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.4, %990), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:460:0
  %992 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.5, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:461:0
  %993 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%992, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:461:0
  %994 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%993, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.4 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%994, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:461:0
  %996 : int = aten::size(%beginning_input.4, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:462:0
  %997 : int = aten::size(%beginning_input.4, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:462:0
  %998 : int = aten::size(%beginning_input.4, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:462:0
  %999 : int = aten::size(%beginning_input.4, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:462:0
  %1000 : int[] = prim::ListConstruct(%996, %997, %998, %999), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1001 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%beginning_mask.4, %1000, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:462:0
  %1002 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%1001, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/tensor.py:22:0
  %1003 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%beginning_input.4, %1002, %153), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:463:0
  %1004 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.5, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:464:0
  %1005 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%1004, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:464:0
  %1006 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%1005, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.4 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%1006, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:464:0
  %1008 : int = aten::size(%ending_input.4, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:465:0
  %1009 : int = aten::size(%ending_input.4, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:465:0
  %1010 : int = aten::size(%ending_input.4, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:465:0
  %1011 : int = aten::size(%ending_input.4, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:465:0
  %1012 : int[] = prim::ListConstruct(%1008, %1009, %1010, %1011), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1013 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%ending_mask.4, %1012, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:465:0
  %1014 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%1013, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/tensor.py:22:0
  %1015 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%ending_input.4, %1014, %153), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:466:0
  %attn_scores.2 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::add_(%input_tensor.4, %input_tensor.5, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:284:0
  %attn_probs_fp32.2 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::softmax(%attn_scores.2, %140, %144), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/nn/functional.py:1500:0
  %1018 : Bool(17:512, 512:1) = aten::slice(%is_index_masked.2, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:326:0
  %1019 : Bool(17:512, 512:1) = aten::slice(%1018, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:326:0
  %1020 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%1019, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:326:0
  %1021 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%1020, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:326:0
  %input.22 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::masked_fill(%attn_probs_fp32.2, %1021, %157), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:326:0
  %attn_probs.4 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::dropout(%input.22, %158, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/nn/functional.py:973:0
  %1024 : int[] = prim::ListConstruct(%683, %684, %128, %129), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1025 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%value_vectors.2, %1024), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:331:0
  %value.2 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%1025, %126, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:331:0
  %1027 : int = aten::size(%value.2, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:537:0
  %batch_size.8 : Long() = prim::NumToTensor(%1027), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1029 : int = aten::size(%value.2, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:537:0
  %seq_len.9 : Long() = prim::NumToTensor(%1029), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1031 : int = aten::size(%value.2, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:537:0
  %num_heads.6 : Long() = prim::NumToTensor(%1031), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1033 : int = aten::size(%value.2, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:537:0
  %1034 : Long() = aten::floor_divide(%seq_len.9, %131), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/tensor.py:424:0
  %chunks_count.6 : Long() = aten::sub(%1034, %132, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:542:0
  %1036 : Float(17:3151872, 12:513, 512:6156, 513:1) = aten::transpose(%attn_probs.4, %125, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:545:0
  %1037 : Long() = aten::mul(%batch_size.8, %num_heads.6), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:546:0
  %1038 : int = aten::Int(%1037), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1039 : Long() = aten::floor_divide(%seq_len.9, %131), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/tensor.py:424:0
  %1040 : int = aten::Int(%1039), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1041 : int[] = prim::ListConstruct(%1038, %1040, %142, %143), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %chunked_hidden_states.6 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::reshape(%1036, %1041), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:545:0
  %1043 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%value.2, %125, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:550:0
  %1044 : Long() = aten::mul(%batch_size.8, %num_heads.6), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:550:0
  %1045 : int = aten::Int(%1044), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1046 : int[] = prim::ListConstruct(%1045, %1029, %1033), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %input.23 : Float(204:64, 512:13056, 64:1) = aten::reshape(%1043, %1046), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:550:0
  %1048 : int[] = prim::ListConstruct(%126, %126, %142, %142), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %padded_value.2 : Float(204:65536, 1024:64, 64:1) = aten::constant_pad_nd(%input.23, %1048, %140), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/nn/functional.py:3552:0
  %1050 : Long() = aten::mul(%batch_size.8, %num_heads.6), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:556:0
  %1051 : int = aten::Int(%1050), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1052 : Long() = aten::add(%chunks_count.6, %132, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:556:0
  %1053 : int = aten::Int(%1052), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1054 : int[] = prim::ListConstruct(%1051, %1053, %159, %1033), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1055 : int[] = prim::ListConstruct(%160, %161, %129, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1056 : Float(204:65536, 2:16384, 768:64, 64:1) = aten::as_strided(%padded_value.2, %1054, %1055, %138), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:564:0
  %1057 : int = aten::size(%chunked_hidden_states.6, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:420:0
  %1058 : int = aten::size(%chunked_hidden_states.6, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:420:0
  %1059 : int = aten::size(%chunked_hidden_states.6, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:420:0
  %window_overlap.2 : Long() = prim::NumToTensor(%1059), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1061 : int = aten::size(%chunked_hidden_states.6, %130), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:420:0
  %hidden_dim.2 : Long() = prim::NumToTensor(%1061), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1063 : Long() = aten::add(%window_overlap.2, %132, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:422:0
  %1064 : int = aten::Int(%1063), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1065 : int[] = prim::ListConstruct(%126, %1064), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %chunked_hidden_states.7 : Float(204:394240, 2:197120, 256:770, 770:1) = aten::constant_pad_nd(%chunked_hidden_states.6, %1065, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/nn/functional.py:3552:0
  %1067 : int[] = prim::ListConstruct(%1057, %1058, %140), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %chunked_hidden_states.8 : Float(204:394240, 2:197120, 197120:1) = aten::view(%chunked_hidden_states.7, %1067), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:424:0
  %1069 : Long() = aten::neg(%window_overlap.2), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:428:0
  %1070 : int = aten::Int(%1069), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1071 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%chunked_hidden_states.8, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:427:0
  %1072 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%1071, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:427:0
  %chunked_hidden_states.9 : Float(204:394240, 2:197120, 196864:1) = aten::slice(%1072, %124, %126, %1070, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:427:0
  %1074 : Long() = aten::add(%window_overlap.2, %hidden_dim.2, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:431:0
  %1075 : int = aten::Int(%1074), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1076 : int[] = prim::ListConstruct(%1057, %1058, %1059, %1075), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %chunked_hidden_states.10 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::view(%chunked_hidden_states.9, %1076), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:430:0
  %1078 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%chunked_hidden_states.10, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:433:0
  %1079 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%1078, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:433:0
  %1080 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%1079, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:433:0
  %1081 : Float(204:394240, 2:197120, 256:769, 768:1) = aten::slice(%1080, %130, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:433:0
  %1082 : Tensor[] = prim::ListConstruct(%1081, %1056), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %context.2 : Float(204:32768, 2:16384, 256:64, 64:1) = aten::einsum(%162, %1082), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/functional.py:327:0
  %1084 : int[] = prim::ListConstruct(%1027, %1031, %1029, %1033), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1085 : Float(17:393216, 12:32768, 512:64, 64:1) = aten::view(%context.2, %1084), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:569:0
  %attn_output.3 : Float(17:393216, 512:64, 12:32768, 64:1) = aten::transpose(%1085, %125, %124), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:569:0
  %1087 : Float(512:64, 17:393216, 12:32768, 64:1) = aten::transpose(%attn_output.3, %126, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:350:0
  %1088 : int[] = prim::ListConstruct(%683, %684, %685), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %1089 : Float(512:13056, 17:768, 768:1) = aten::reshape(%1087, %1088), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:350:0
  %attn_output.4 : Float(512:13056, 17:768, 768:1) = aten::contiguous(%1089, %126), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:350:0
  %input.24 : Float(17:768, 512:13056, 768:1) = aten::transpose(%attn_output.4, %126, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_longformer.py:374:0
  %1092 : __torch__.torch.nn.modules.normalization.___torch_mangle_8077.LayerNorm = prim::GetAttr[name="LayerNorm"](%659)
  %1093 : __torch__.torch.nn.modules.linear.___torch_mangle_8076.Linear = prim::GetAttr[name="dense"](%659)
  %1094 : Tensor = prim::GetAttr[name="bias"](%1093)
  %1095 : Tensor = prim::GetAttr[name="weight"](%1093)
  %1096 : Float(768:1, 768:768) = aten::t(%1095), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %output.10 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.24, %1096), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %input.25 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.10, %1094, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.21 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.25, %158, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dropout # torch/nn/functional.py:973:0
  %input.26 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.21, %hidden_states.12, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output # transformers/modeling_longformer.py:758:0
  %1101 : Tensor = prim::GetAttr[name="bias"](%1092)
  %1102 : Tensor = prim::GetAttr[name="weight"](%1092)
  %1103 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.LayerNorm
  %input_tensor.6 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.26, %1103, %1102, %1101, %123, %122), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %1105 : __torch__.torch.nn.modules.linear.___torch_mangle_8081.Linear = prim::GetAttr[name="dense"](%657)
  %1106 : Tensor = prim::GetAttr[name="bias"](%1105)
  %1107 : Tensor = prim::GetAttr[name="weight"](%1105)
  %1108 : Float(768:1, 3072:768) = aten::t(%1107), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.11 : Float(17:1572864, 512:3072, 3072:1) = aten::matmul(%input_tensor.6, %1108), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.27 : Float(17:1572864, 512:3072, 3072:1) = aten::add_(%output.11, %1106, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.28 : Float(17:1572864, 512:3072, 3072:1) = aten::gelu(%input.27), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # torch/nn/functional.py:1369:0
  %1112 : __torch__.torch.nn.modules.normalization.___torch_mangle_8084.LayerNorm = prim::GetAttr[name="LayerNorm"](%656)
  %1113 : __torch__.torch.nn.modules.linear.___torch_mangle_8083.Linear = prim::GetAttr[name="dense"](%656)
  %1114 : Tensor = prim::GetAttr[name="bias"](%1113)
  %1115 : Tensor = prim::GetAttr[name="weight"](%1113)
  %1116 : Float(3072:1, 768:3072) = aten::t(%1115), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %output.12 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.28, %1116), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %input.29 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.12, %1114, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.22 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.29, %158, %146), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dropout # torch/nn/functional.py:973:0
  %input.30 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.22, %input_tensor.6, %125), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output # transformers/modeling_longformer.py:830:0
  %1121 : Tensor = prim::GetAttr[name="bias"](%1112)
  %1122 : Tensor = prim::GetAttr[name="weight"](%1112)
  %1123 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.LayerNorm
  %hidden_states.23 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.30, %1123, %1122, %1121, %123, %122), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.LayerNorm # torch/nn/functional.py:2048:0
  %1125 : __torch__.transformers.modeling_longformer.___torch_mangle_8105.LongformerOutput = prim::GetAttr[name="output"](%182)
  %1126 : __torch__.transformers.modeling_longformer.___torch_mangle_8101.LongformerIntermediate = prim::GetAttr[name="intermediate"](%182)
  %1127 : __torch__.transformers.modeling_longformer.___torch_mangle_8099.LongformerAttention = prim::GetAttr[name="attention"](%182)
  %1128 : __torch__.transformers.modeling_longformer.___torch_mangle_8098.LongformerSelfOutput = prim::GetAttr[name="output"](%1127)
  %1129 : __torch__.transformers.modeling_longformer.___torch_mangle_8094.LongformerSelfAttention = prim::GetAttr[name="self"](%1127)
  %1130 : __torch__.torch.nn.modules.linear.___torch_mangle_8090.Linear = prim::GetAttr[name="value"](%1129)
  %1131 : __torch__.torch.nn.modules.linear.___torch_mangle_8089.Linear = prim::GetAttr[name="key"](%1129)
  %1132 : __torch__.torch.nn.modules.linear.___torch_mangle_8088.Linear = prim::GetAttr[name="query"](%1129)
  %1133 : Float(17:512, 1:512, 512:1) = aten::squeeze(%attention_mask, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:241:0
  %1134 : Float(17:512, 512:1) = aten::squeeze(%1133, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:241:0
  %is_index_masked.3 : Bool(17:512, 512:1) = aten::lt(%1134, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/tensor.py:22:0
  %input.31 : Float(512:768, 17:393216, 768:1) = aten::transpose(%hidden_states.23, %126, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:248:0
  %1137 : Tensor = prim::GetAttr[name="bias"](%1132)
  %1138 : Tensor = prim::GetAttr[name="weight"](%1132)
  %1139 : Float(768:1, 768:768) = aten::t(%1138), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %output.13 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.31, %1139), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %query_vectors.5 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.13, %1137, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.query # torch/nn/functional.py:1678:0
  %1142 : Tensor = prim::GetAttr[name="bias"](%1131)
  %1143 : Tensor = prim::GetAttr[name="weight"](%1131)
  %1144 : Float(768:1, 768:768) = aten::t(%1143), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %output.14 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.31, %1144), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %key_vectors.3 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.14, %1142, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.key # torch/nn/functional.py:1678:0
  %1147 : Tensor = prim::GetAttr[name="bias"](%1130)
  %1148 : Tensor = prim::GetAttr[name="weight"](%1130)
  %1149 : Float(768:1, 768:768) = aten::t(%1148), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %output.15 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.31, %1149), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %value_vectors.3 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.15, %1147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.value # torch/nn/functional.py:1678:0
  %1152 : int = aten::size(%input.31, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:255:0
  %1153 : int = aten::size(%input.31, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:255:0
  %1154 : int = aten::size(%input.31, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:255:0
  %query_vectors.6 : Float(512:13056, 17:768, 768:1) = aten::div_(%query_vectors.5, %127), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:261:0
  %1156 : int[] = prim::ListConstruct(%1152, %1153, %128, %129), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1157 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%query_vectors.6, %1156), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:263:0
  %query.5 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%1157, %126, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:263:0
  %1159 : int[] = prim::ListConstruct(%1152, %1153, %128, %129), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1160 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%key_vectors.3, %1159), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:264:0
  %key.3 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%1160, %126, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:264:0
  %1162 : int = aten::size(%query.5, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.10 : Long() = prim::NumToTensor(%1162), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1164 : int = aten::size(%query.5, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.11 : Long() = prim::NumToTensor(%1164), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1166 : int = aten::size(%query.5, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.7 : Long() = prim::NumToTensor(%1166), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1168 : int = aten::size(%query.5, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:472:0
  %1169 : Long() = aten::floor_divide(%seq_len.11, %131), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/tensor.py:424:0
  %chunks_count.7 : Long() = aten::sub(%1169, %132, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:478:0
  %1171 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%query.5, %125, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:481:0
  %1172 : Long() = aten::mul(%batch_size.10, %num_heads.7), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:481:0
  %1173 : int = aten::Int(%1172), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1174 : int[] = prim::ListConstruct(%1173, %1164, %1168), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %hidden_states.24 : Float(204:64, 512:13056, 64:1) = aten::reshape(%1171, %1174), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:481:0
  %1176 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%key.3, %125, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:482:0
  %1177 : Long() = aten::mul(%batch_size.10, %num_heads.7), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:482:0
  %1178 : int = aten::Int(%1177), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1179 : int[] = prim::ListConstruct(%1178, %1164, %1168), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %hidden_states.26 : Float(204:64, 512:13056, 64:1) = aten::reshape(%1176, %1179), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:482:0
  %1181 : int = aten::size(%hidden_states.24, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:442:0
  %1182 : int = aten::size(%hidden_states.24, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:443:0
  %1183 : Long() = prim::NumToTensor(%1182), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1184 : Long() = aten::floor_divide(%1183, %133), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/tensor.py:424:0
  %1185 : int = aten::Int(%1184), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1186 : int = aten::size(%hidden_states.24, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:445:0
  %1187 : int[] = prim::ListConstruct(%1181, %1185, %134, %1186), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %hidden_states.25 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.24, %1187), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:441:0
  %1189 : int = aten::size(%hidden_states.25, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1190 : int = aten::size(%hidden_states.25, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1191 : Long() = prim::NumToTensor(%1190), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1192 : int = aten::size(%hidden_states.25, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1193 : int = aten::size(%hidden_states.25, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1194 : Long() = aten::mul(%1191, %135), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:450:0
  %1195 : Long() = aten::sub(%1194, %132, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:450:0
  %1196 : int = aten::Int(%1195), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1197 : int[] = prim::ListConstruct(%1189, %1196, %1192, %1193), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1198 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1199 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.25, %1197, %1198, %138), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:454:0
  %1200 : int = aten::size(%hidden_states.26, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:442:0
  %1201 : int = aten::size(%hidden_states.26, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:443:0
  %1202 : Long() = prim::NumToTensor(%1201), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1203 : Long() = aten::floor_divide(%1202, %133), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/tensor.py:424:0
  %1204 : int = aten::Int(%1203), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1205 : int = aten::size(%hidden_states.26, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:445:0
  %1206 : int[] = prim::ListConstruct(%1200, %1204, %134, %1205), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %hidden_states.27 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.26, %1206), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:441:0
  %1208 : int = aten::size(%hidden_states.27, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1209 : int = aten::size(%hidden_states.27, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1210 : Long() = prim::NumToTensor(%1209), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1211 : int = aten::size(%hidden_states.27, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1212 : int = aten::size(%hidden_states.27, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1213 : Long() = aten::mul(%1210, %135), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:450:0
  %1214 : Long() = aten::sub(%1213, %132, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:450:0
  %1215 : int = aten::Int(%1214), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1216 : int[] = prim::ListConstruct(%1208, %1215, %1211, %1212), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1217 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1218 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.27, %1216, %1217, %138), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:454:0
  %1219 : Tensor[] = prim::ListConstruct(%1199, %1218), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %input.32 : Float(204:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %1219), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/functional.py:327:0
  %1221 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %hidden_states_padded.5 : Float(204:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.32, %1221, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/nn/functional.py:3552:0
  %1223 : int = aten::size(%hidden_states_padded.5, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:401:0
  %1224 : int = aten::size(%hidden_states_padded.5, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:401:0
  %1225 : int = aten::size(%hidden_states_padded.5, %140), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:401:0
  %1226 : int = aten::size(%hidden_states_padded.5, %141), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:401:0
  %1227 : int[] = prim::ListConstruct(%1223, %1224, %1225, %1226), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %diagonal_chunked_attention_scores.5 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.5, %1227), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:400:0
  %1229 : Long() = aten::mul(%batch_size.10, %num_heads.7), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:504:0
  %1230 : int = aten::Int(%1229), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1231 : Long() = aten::add(%chunks_count.7, %132, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:504:0
  %1232 : int = aten::Int(%1231), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1233 : int[] = prim::ListConstruct(%1230, %1232, %142, %143), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %diagonal_attention_scores.5 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.5, %1233, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:503:0
  %1235 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.5, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1236 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%1235, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1237 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%1236, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1238 : Float(204:262656, 1:262656, 256:513, 257:1) = aten::slice(%1237, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1239 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.5, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1240 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%1239, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1241 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%1240, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1242 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::slice(%1241, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1243 : int[] = prim::ListConstruct(%149, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1244 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::view(%1238, %1243), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1245 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::copy_(%1242, %1244, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1246 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.5, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1247 : Float(204:262656, 512:513, 513:1) = aten::select(%1246, %125, %140), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1248 : Float(204:262656, 256:513, 513:1) = aten::slice(%1247, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1249 : Float(204:262656, 256:513, 257:1) = aten::slice(%1248, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1250 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.5, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1251 : Float(204:262656, 256:513, 513:1) = aten::select(%1250, %125, %140), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1252 : Float(204:262656, 256:513, 513:1) = aten::slice(%1251, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1253 : Float(204:262656, 256:513, 257:1) = aten::slice(%1252, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1254 : int[] = prim::ListConstruct(%149, %142, %148), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1255 : Float(204:262656, 256:513, 257:1) = aten::view(%1249, %1254), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1256 : Float(204:262656, 256:513, 257:1) = aten::copy_(%1253, %1255, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1257 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.5, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1258 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%1257, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1259 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%1258, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1260 : Float(204:262656, 1:262656, 256:513, 256:1) = aten::slice(%1259, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1261 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.5, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1262 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%1261, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1263 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%1262, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1264 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::slice(%1263, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1265 : int[] = prim::ListConstruct(%149, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1266 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::view(%1260, %1265), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1267 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::copy_(%1264, %1266, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1268 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.5, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1269 : Float(204:262656, 512:513, 513:1) = aten::select(%1268, %125, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1270 : Float(204:262656, 255:513, 513:1) = aten::slice(%1269, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1271 : Float(204:262656, 255:513, 255:1) = aten::slice(%1270, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1272 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.5, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1273 : Float(204:262656, 256:513, 513:1) = aten::select(%1272, %125, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1274 : Float(204:262656, 255:513, 513:1) = aten::slice(%1273, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1275 : Float(204:262656, 255:513, 255:1) = aten::slice(%1274, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1276 : int[] = prim::ListConstruct(%149, %151, %151), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1277 : Float(204:262656, 255:513, 255:1) = aten::view(%1271, %1276), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1278 : Float(204:262656, 255:513, 255:1) = aten::copy_(%1275, %1277, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1279 : int[] = prim::ListConstruct(%1162, %1166, %1164, %143), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1280 : Float(17:3151872, 12:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.5, %1279), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.7 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::transpose(%1280, %124, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:525:0
  %1282 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1283 : Float(256:257, 257:1) = aten::ones(%1282, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:458:0
  %1284 : Float(256:257, 257:1) = aten::tril(%1283, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:458:0
  %1285 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %beginning_mask_2d.5 : Float(256:257, 257:1) = aten::flip(%1284, %1285), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:458:0
  %1287 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.5, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:459:0
  %1288 : Float(1:65792, 256:257, 257:1) = aten::slice(%1287, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:459:0
  %1289 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%1288, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.5 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%1289, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:459:0
  %1291 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %ending_mask.5 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.5, %1291), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:460:0
  %1293 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.7, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:461:0
  %1294 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%1293, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:461:0
  %1295 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%1294, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.5 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%1295, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:461:0
  %1297 : int = aten::size(%beginning_input.5, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:462:0
  %1298 : int = aten::size(%beginning_input.5, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:462:0
  %1299 : int = aten::size(%beginning_input.5, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:462:0
  %1300 : int = aten::size(%beginning_input.5, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:462:0
  %1301 : int[] = prim::ListConstruct(%1297, %1298, %1299, %1300), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1302 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%beginning_mask.5, %1301, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:462:0
  %1303 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%1302, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/tensor.py:22:0
  %1304 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%beginning_input.5, %1303, %153), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:463:0
  %1305 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.7, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:464:0
  %1306 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%1305, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:464:0
  %1307 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%1306, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.5 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%1307, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:464:0
  %1309 : int = aten::size(%ending_input.5, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:465:0
  %1310 : int = aten::size(%ending_input.5, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:465:0
  %1311 : int = aten::size(%ending_input.5, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:465:0
  %1312 : int = aten::size(%ending_input.5, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:465:0
  %1313 : int[] = prim::ListConstruct(%1309, %1310, %1311, %1312), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1314 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%ending_mask.5, %1313, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:465:0
  %1315 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%1314, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/tensor.py:22:0
  %1316 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%ending_input.5, %1315, %153), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:466:0
  %1317 : Bool(17:512, 512:1) = aten::ne(%1134, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/tensor.py:22:0
  %1318 : Bool(17:512, 512:1) = aten::slice(%1317, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:272:0
  %1319 : Bool(17:512, 512:1) = aten::slice(%1318, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:272:0
  %1320 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%1319, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:272:0
  %remove_from_windowed_attention_mask.3 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%1320, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:272:0
  %1322 : Float(17:512, 512:1, 1:1, 1:1) = aten::type_as(%remove_from_windowed_attention_mask.3, %query.5), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:275:0
  %float_mask.3 : Float(17:512, 512:1, 1:1, 1:1) = aten::masked_fill(%1322, %remove_from_windowed_attention_mask.3, %155), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:275:0
  %1324 : int = aten::size(%float_mask.3, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:280:0
  %1325 : int = aten::size(%float_mask.3, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:280:0
  %1326 : int = aten::size(%float_mask.3, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:280:0
  %1327 : int = aten::size(%float_mask.3, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:280:0
  %1328 : int[] = prim::ListConstruct(%1324, %1325, %1326, %1327), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %query.6 : Float(17:512, 512:1, 1:1, 1:1) = aten::ones(%1328, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:280:0
  %1330 : int = aten::size(%query.6, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.11 : Long() = prim::NumToTensor(%1330), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1332 : int = aten::size(%query.6, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.12 : Long() = prim::NumToTensor(%1332), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1334 : int = aten::size(%query.6, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.8 : Long() = prim::NumToTensor(%1334), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1336 : int = aten::size(%query.6, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:472:0
  %1337 : Long() = aten::floor_divide(%seq_len.12, %131), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/tensor.py:424:0
  %chunks_count.8 : Long() = aten::sub(%1337, %132, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:478:0
  %1339 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%query.6, %125, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:481:0
  %1340 : Long() = aten::mul(%batch_size.11, %num_heads.8), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:481:0
  %1341 : int = aten::Int(%1340), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1342 : int[] = prim::ListConstruct(%1341, %1332, %1336), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %hidden_states.28 : Float(17:512, 512:1, 1:1) = aten::reshape(%1339, %1342), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:481:0
  %1344 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%float_mask.3, %125, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:482:0
  %1345 : Long() = aten::mul(%batch_size.11, %num_heads.8), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:482:0
  %1346 : int = aten::Int(%1345), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1347 : int[] = prim::ListConstruct(%1346, %1332, %1336), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %hidden_states.30 : Float(17:512, 512:1, 1:1) = aten::reshape(%1344, %1347), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:482:0
  %1349 : int = aten::size(%hidden_states.28, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:442:0
  %1350 : int = aten::size(%hidden_states.28, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:443:0
  %1351 : Long() = prim::NumToTensor(%1350), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1352 : Long() = aten::floor_divide(%1351, %133), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/tensor.py:424:0
  %1353 : int = aten::Int(%1352), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1354 : int = aten::size(%hidden_states.28, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:445:0
  %1355 : int[] = prim::ListConstruct(%1349, %1353, %134, %1354), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %hidden_states.29 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.28, %1355), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:441:0
  %1357 : int = aten::size(%hidden_states.29, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1358 : int = aten::size(%hidden_states.29, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1359 : Long() = prim::NumToTensor(%1358), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1360 : int = aten::size(%hidden_states.29, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1361 : int = aten::size(%hidden_states.29, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1362 : Long() = aten::mul(%1359, %135), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:450:0
  %1363 : Long() = aten::sub(%1362, %132, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:450:0
  %1364 : int = aten::Int(%1363), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1365 : int[] = prim::ListConstruct(%1357, %1364, %1360, %1361), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1366 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1367 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.29, %1365, %1366, %138), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:454:0
  %1368 : int = aten::size(%hidden_states.30, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:442:0
  %1369 : int = aten::size(%hidden_states.30, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:443:0
  %1370 : Long() = prim::NumToTensor(%1369), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1371 : Long() = aten::floor_divide(%1370, %133), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/tensor.py:424:0
  %1372 : int = aten::Int(%1371), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1373 : int = aten::size(%hidden_states.30, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:445:0
  %1374 : int[] = prim::ListConstruct(%1368, %1372, %134, %1373), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %hidden_states.31 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.30, %1374), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:441:0
  %1376 : int = aten::size(%hidden_states.31, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1377 : int = aten::size(%hidden_states.31, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1378 : Long() = prim::NumToTensor(%1377), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1379 : int = aten::size(%hidden_states.31, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1380 : int = aten::size(%hidden_states.31, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:449:0
  %1381 : Long() = aten::mul(%1378, %135), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:450:0
  %1382 : Long() = aten::sub(%1381, %132, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:450:0
  %1383 : int = aten::Int(%1382), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1384 : int[] = prim::ListConstruct(%1376, %1383, %1379, %1380), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1385 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1386 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.31, %1384, %1385, %138), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:454:0
  %1387 : Tensor[] = prim::ListConstruct(%1367, %1386), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %input.33 : Float(17:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %1387), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/functional.py:327:0
  %1389 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %hidden_states_padded.6 : Float(17:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.33, %1389, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/nn/functional.py:3552:0
  %1391 : int = aten::size(%hidden_states_padded.6, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:401:0
  %1392 : int = aten::size(%hidden_states_padded.6, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:401:0
  %1393 : int = aten::size(%hidden_states_padded.6, %140), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:401:0
  %1394 : int = aten::size(%hidden_states_padded.6, %141), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:401:0
  %1395 : int[] = prim::ListConstruct(%1391, %1392, %1393, %1394), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %diagonal_chunked_attention_scores.6 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.6, %1395), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:400:0
  %1397 : Long() = aten::mul(%batch_size.11, %num_heads.8), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:504:0
  %1398 : int = aten::Int(%1397), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1399 : Long() = aten::add(%chunks_count.8, %132, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:504:0
  %1400 : int = aten::Int(%1399), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1401 : int[] = prim::ListConstruct(%1398, %1400, %142, %143), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %diagonal_attention_scores.6 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.6, %1401, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:503:0
  %1403 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.6, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1404 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%1403, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1405 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%1404, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1406 : Float(17:262656, 1:262656, 256:513, 257:1) = aten::slice(%1405, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1407 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.6, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1408 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%1407, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1409 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%1408, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1410 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::slice(%1409, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1411 : int[] = prim::ListConstruct(%156, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1412 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::view(%1406, %1411), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1413 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::copy_(%1410, %1412, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:509:0
  %1414 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.6, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1415 : Float(17:262656, 512:513, 513:1) = aten::select(%1414, %125, %140), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1416 : Float(17:262656, 256:513, 513:1) = aten::slice(%1415, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1417 : Float(17:262656, 256:513, 257:1) = aten::slice(%1416, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1418 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.6, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1419 : Float(17:262656, 256:513, 513:1) = aten::select(%1418, %125, %140), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1420 : Float(17:262656, 256:513, 513:1) = aten::slice(%1419, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1421 : Float(17:262656, 256:513, 257:1) = aten::slice(%1420, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1422 : int[] = prim::ListConstruct(%156, %142, %148), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1423 : Float(17:262656, 256:513, 257:1) = aten::view(%1417, %1422), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1424 : Float(17:262656, 256:513, 257:1) = aten::copy_(%1421, %1423, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:512:0
  %1425 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.6, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1426 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%1425, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1427 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%1426, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1428 : Float(17:262656, 1:262656, 256:513, 256:1) = aten::slice(%1427, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1429 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.6, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1430 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%1429, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1431 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%1430, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1432 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::slice(%1431, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1433 : int[] = prim::ListConstruct(%156, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1434 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::view(%1428, %1433), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1435 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::copy_(%1432, %1434, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:516:0
  %1436 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.6, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1437 : Float(17:262656, 512:513, 513:1) = aten::select(%1436, %125, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1438 : Float(17:262656, 255:513, 513:1) = aten::slice(%1437, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1439 : Float(17:262656, 255:513, 255:1) = aten::slice(%1438, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1440 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.6, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1441 : Float(17:262656, 256:513, 513:1) = aten::select(%1440, %125, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1442 : Float(17:262656, 255:513, 513:1) = aten::slice(%1441, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1443 : Float(17:262656, 255:513, 255:1) = aten::slice(%1442, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1444 : int[] = prim::ListConstruct(%156, %151, %151), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1445 : Float(17:262656, 255:513, 255:1) = aten::view(%1439, %1444), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1446 : Float(17:262656, 255:513, 255:1) = aten::copy_(%1443, %1445, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:520:0
  %1447 : int[] = prim::ListConstruct(%1330, %1334, %1332, %143), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1448 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.6, %1447), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.8 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::transpose(%1448, %124, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:525:0
  %1450 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1451 : Float(256:257, 257:1) = aten::ones(%1450, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:458:0
  %1452 : Float(256:257, 257:1) = aten::tril(%1451, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:458:0
  %1453 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %beginning_mask_2d.6 : Float(256:257, 257:1) = aten::flip(%1452, %1453), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:458:0
  %1455 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.6, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:459:0
  %1456 : Float(1:65792, 256:257, 257:1) = aten::slice(%1455, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:459:0
  %1457 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%1456, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.6 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%1457, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:459:0
  %1459 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %ending_mask.6 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.6, %1459), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:460:0
  %1461 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.8, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:461:0
  %1462 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%1461, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:461:0
  %1463 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%1462, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.6 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%1463, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:461:0
  %1465 : int = aten::size(%beginning_input.6, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:462:0
  %1466 : int = aten::size(%beginning_input.6, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:462:0
  %1467 : int = aten::size(%beginning_input.6, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:462:0
  %1468 : int = aten::size(%beginning_input.6, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:462:0
  %1469 : int[] = prim::ListConstruct(%1465, %1466, %1467, %1468), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1470 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%beginning_mask.6, %1469, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:462:0
  %1471 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%1470, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/tensor.py:22:0
  %1472 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%beginning_input.6, %1471, %153), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:463:0
  %1473 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.8, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:464:0
  %1474 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%1473, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:464:0
  %1475 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%1474, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.6 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%1475, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:464:0
  %1477 : int = aten::size(%ending_input.6, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:465:0
  %1478 : int = aten::size(%ending_input.6, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:465:0
  %1479 : int = aten::size(%ending_input.6, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:465:0
  %1480 : int = aten::size(%ending_input.6, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:465:0
  %1481 : int[] = prim::ListConstruct(%1477, %1478, %1479, %1480), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1482 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%ending_mask.6, %1481, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:465:0
  %1483 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%1482, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/tensor.py:22:0
  %1484 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%ending_input.6, %1483, %153), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:466:0
  %attn_scores.3 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::add_(%input_tensor.7, %input_tensor.8, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:284:0
  %attn_probs_fp32.3 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::softmax(%attn_scores.3, %140, %144), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/nn/functional.py:1500:0
  %1487 : Bool(17:512, 512:1) = aten::slice(%is_index_masked.3, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:326:0
  %1488 : Bool(17:512, 512:1) = aten::slice(%1487, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:326:0
  %1489 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%1488, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:326:0
  %1490 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%1489, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:326:0
  %input.34 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::masked_fill(%attn_probs_fp32.3, %1490, %157), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:326:0
  %attn_probs.6 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::dropout(%input.34, %158, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/nn/functional.py:973:0
  %1493 : int[] = prim::ListConstruct(%1152, %1153, %128, %129), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1494 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%value_vectors.3, %1493), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:331:0
  %value.3 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%1494, %126, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:331:0
  %1496 : int = aten::size(%value.3, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:537:0
  %batch_size.12 : Long() = prim::NumToTensor(%1496), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1498 : int = aten::size(%value.3, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:537:0
  %seq_len.13 : Long() = prim::NumToTensor(%1498), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1500 : int = aten::size(%value.3, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:537:0
  %num_heads.9 : Long() = prim::NumToTensor(%1500), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1502 : int = aten::size(%value.3, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:537:0
  %1503 : Long() = aten::floor_divide(%seq_len.13, %131), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/tensor.py:424:0
  %chunks_count.9 : Long() = aten::sub(%1503, %132, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:542:0
  %1505 : Float(17:3151872, 12:513, 512:6156, 513:1) = aten::transpose(%attn_probs.6, %125, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:545:0
  %1506 : Long() = aten::mul(%batch_size.12, %num_heads.9), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:546:0
  %1507 : int = aten::Int(%1506), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1508 : Long() = aten::floor_divide(%seq_len.13, %131), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/tensor.py:424:0
  %1509 : int = aten::Int(%1508), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1510 : int[] = prim::ListConstruct(%1507, %1509, %142, %143), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %chunked_hidden_states.11 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::reshape(%1505, %1510), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:545:0
  %1512 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%value.3, %125, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:550:0
  %1513 : Long() = aten::mul(%batch_size.12, %num_heads.9), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:550:0
  %1514 : int = aten::Int(%1513), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1515 : int[] = prim::ListConstruct(%1514, %1498, %1502), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %input.35 : Float(204:64, 512:13056, 64:1) = aten::reshape(%1512, %1515), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:550:0
  %1517 : int[] = prim::ListConstruct(%126, %126, %142, %142), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %padded_value.3 : Float(204:65536, 1024:64, 64:1) = aten::constant_pad_nd(%input.35, %1517, %140), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/nn/functional.py:3552:0
  %1519 : Long() = aten::mul(%batch_size.12, %num_heads.9), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:556:0
  %1520 : int = aten::Int(%1519), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1521 : Long() = aten::add(%chunks_count.9, %132, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:556:0
  %1522 : int = aten::Int(%1521), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1523 : int[] = prim::ListConstruct(%1520, %1522, %159, %1502), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1524 : int[] = prim::ListConstruct(%160, %161, %129, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1525 : Float(204:65536, 2:16384, 768:64, 64:1) = aten::as_strided(%padded_value.3, %1523, %1524, %138), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:564:0
  %1526 : int = aten::size(%chunked_hidden_states.11, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:420:0
  %1527 : int = aten::size(%chunked_hidden_states.11, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:420:0
  %1528 : int = aten::size(%chunked_hidden_states.11, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:420:0
  %window_overlap.3 : Long() = prim::NumToTensor(%1528), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1530 : int = aten::size(%chunked_hidden_states.11, %130), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:420:0
  %hidden_dim.3 : Long() = prim::NumToTensor(%1530), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1532 : Long() = aten::add(%window_overlap.3, %132, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:422:0
  %1533 : int = aten::Int(%1532), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1534 : int[] = prim::ListConstruct(%126, %1533), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %chunked_hidden_states.12 : Float(204:394240, 2:197120, 256:770, 770:1) = aten::constant_pad_nd(%chunked_hidden_states.11, %1534, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/nn/functional.py:3552:0
  %1536 : int[] = prim::ListConstruct(%1526, %1527, %140), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %chunked_hidden_states.13 : Float(204:394240, 2:197120, 197120:1) = aten::view(%chunked_hidden_states.12, %1536), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:424:0
  %1538 : Long() = aten::neg(%window_overlap.3), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:428:0
  %1539 : int = aten::Int(%1538), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1540 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%chunked_hidden_states.13, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:427:0
  %1541 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%1540, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:427:0
  %chunked_hidden_states.14 : Float(204:394240, 2:197120, 196864:1) = aten::slice(%1541, %124, %126, %1539, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:427:0
  %1543 : Long() = aten::add(%window_overlap.3, %hidden_dim.3, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:431:0
  %1544 : int = aten::Int(%1543), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1545 : int[] = prim::ListConstruct(%1526, %1527, %1528, %1544), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %chunked_hidden_states.15 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::view(%chunked_hidden_states.14, %1545), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:430:0
  %1547 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%chunked_hidden_states.15, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:433:0
  %1548 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%1547, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:433:0
  %1549 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%1548, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:433:0
  %1550 : Float(204:394240, 2:197120, 256:769, 768:1) = aten::slice(%1549, %130, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:433:0
  %1551 : Tensor[] = prim::ListConstruct(%1550, %1525), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %context.3 : Float(204:32768, 2:16384, 256:64, 64:1) = aten::einsum(%162, %1551), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/functional.py:327:0
  %1553 : int[] = prim::ListConstruct(%1496, %1500, %1498, %1502), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1554 : Float(17:393216, 12:32768, 512:64, 64:1) = aten::view(%context.3, %1553), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:569:0
  %attn_output.5 : Float(17:393216, 512:64, 12:32768, 64:1) = aten::transpose(%1554, %125, %124), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:569:0
  %1556 : Float(512:64, 17:393216, 12:32768, 64:1) = aten::transpose(%attn_output.5, %126, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:350:0
  %1557 : int[] = prim::ListConstruct(%1152, %1153, %1154), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %1558 : Float(512:13056, 17:768, 768:1) = aten::reshape(%1556, %1557), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:350:0
  %attn_output.6 : Float(512:13056, 17:768, 768:1) = aten::contiguous(%1558, %126), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:350:0
  %input.36 : Float(17:768, 512:13056, 768:1) = aten::transpose(%attn_output.6, %126, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_longformer.py:374:0
  %1561 : __torch__.torch.nn.modules.normalization.___torch_mangle_8096.LayerNorm = prim::GetAttr[name="LayerNorm"](%1128)
  %1562 : __torch__.torch.nn.modules.linear.___torch_mangle_8095.Linear = prim::GetAttr[name="dense"](%1128)
  %1563 : Tensor = prim::GetAttr[name="bias"](%1562)
  %1564 : Tensor = prim::GetAttr[name="weight"](%1562)
  %1565 : Float(768:1, 768:768) = aten::t(%1564), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %output.16 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.36, %1565), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %input.37 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.16, %1563, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.32 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.37, %158, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.dropout # torch/nn/functional.py:973:0
  %input.38 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.32, %hidden_states.23, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output # transformers/modeling_longformer.py:758:0
  %1570 : Tensor = prim::GetAttr[name="bias"](%1561)
  %1571 : Tensor = prim::GetAttr[name="weight"](%1561)
  %1572 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.LayerNorm
  %input_tensor.9 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.38, %1572, %1571, %1570, %123, %122), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %1574 : __torch__.torch.nn.modules.linear.___torch_mangle_8100.Linear = prim::GetAttr[name="dense"](%1126)
  %1575 : Tensor = prim::GetAttr[name="bias"](%1574)
  %1576 : Tensor = prim::GetAttr[name="weight"](%1574)
  %1577 : Float(768:1, 3072:768) = aten::t(%1576), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.intermediate/__module.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.17 : Float(17:1572864, 512:3072, 3072:1) = aten::matmul(%input_tensor.9, %1577), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.intermediate/__module.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.39 : Float(17:1572864, 512:3072, 3072:1) = aten::add_(%output.17, %1575, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.intermediate/__module.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.40 : Float(17:1572864, 512:3072, 3072:1) = aten::gelu(%input.39), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.intermediate # torch/nn/functional.py:1369:0
  %1581 : __torch__.torch.nn.modules.normalization.___torch_mangle_8103.LayerNorm = prim::GetAttr[name="LayerNorm"](%1125)
  %1582 : __torch__.torch.nn.modules.linear.___torch_mangle_8102.Linear = prim::GetAttr[name="dense"](%1125)
  %1583 : Tensor = prim::GetAttr[name="bias"](%1582)
  %1584 : Tensor = prim::GetAttr[name="weight"](%1582)
  %1585 : Float(3072:1, 768:3072) = aten::t(%1584), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %output.18 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.40, %1585), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %input.41 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.18, %1583, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.33 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.41, %158, %146), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.dropout # torch/nn/functional.py:973:0
  %input.42 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.33, %input_tensor.9, %125), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output # transformers/modeling_longformer.py:830:0
  %1590 : Tensor = prim::GetAttr[name="bias"](%1581)
  %1591 : Tensor = prim::GetAttr[name="weight"](%1581)
  %1592 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.LayerNorm
  %hidden_states.34 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.42, %1592, %1591, %1590, %123, %122), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.LayerNorm # torch/nn/functional.py:2048:0
  %1594 : __torch__.transformers.modeling_longformer.___torch_mangle_8124.LongformerOutput = prim::GetAttr[name="output"](%180)
  %1595 : __torch__.transformers.modeling_longformer.___torch_mangle_8120.LongformerIntermediate = prim::GetAttr[name="intermediate"](%180)
  %1596 : __torch__.transformers.modeling_longformer.___torch_mangle_8118.LongformerAttention = prim::GetAttr[name="attention"](%180)
  %1597 : __torch__.transformers.modeling_longformer.___torch_mangle_8117.LongformerSelfOutput = prim::GetAttr[name="output"](%1596)
  %1598 : __torch__.transformers.modeling_longformer.___torch_mangle_8113.LongformerSelfAttention = prim::GetAttr[name="self"](%1596)
  %1599 : __torch__.torch.nn.modules.linear.___torch_mangle_8109.Linear = prim::GetAttr[name="value"](%1598)
  %1600 : __torch__.torch.nn.modules.linear.___torch_mangle_8108.Linear = prim::GetAttr[name="key"](%1598)
  %1601 : __torch__.torch.nn.modules.linear.___torch_mangle_8107.Linear = prim::GetAttr[name="query"](%1598)
  %1602 : Float(17:512, 1:512, 512:1) = aten::squeeze(%attention_mask, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:241:0
  %1603 : Float(17:512, 512:1) = aten::squeeze(%1602, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:241:0
  %is_index_masked.4 : Bool(17:512, 512:1) = aten::lt(%1603, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/tensor.py:22:0
  %input.43 : Float(512:768, 17:393216, 768:1) = aten::transpose(%hidden_states.34, %126, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:248:0
  %1606 : Tensor = prim::GetAttr[name="bias"](%1601)
  %1607 : Tensor = prim::GetAttr[name="weight"](%1601)
  %1608 : Float(768:1, 768:768) = aten::t(%1607), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %output.19 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.43, %1608), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %query_vectors.7 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.19, %1606, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.query # torch/nn/functional.py:1678:0
  %1611 : Tensor = prim::GetAttr[name="bias"](%1600)
  %1612 : Tensor = prim::GetAttr[name="weight"](%1600)
  %1613 : Float(768:1, 768:768) = aten::t(%1612), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %output.20 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.43, %1613), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %key_vectors.4 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.20, %1611, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.key # torch/nn/functional.py:1678:0
  %1616 : Tensor = prim::GetAttr[name="bias"](%1599)
  %1617 : Tensor = prim::GetAttr[name="weight"](%1599)
  %1618 : Float(768:1, 768:768) = aten::t(%1617), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %output.21 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.43, %1618), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %value_vectors.4 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.21, %1616, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.value # torch/nn/functional.py:1678:0
  %1621 : int = aten::size(%input.43, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:255:0
  %1622 : int = aten::size(%input.43, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:255:0
  %1623 : int = aten::size(%input.43, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:255:0
  %query_vectors.8 : Float(512:13056, 17:768, 768:1) = aten::div_(%query_vectors.7, %127), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:261:0
  %1625 : int[] = prim::ListConstruct(%1621, %1622, %128, %129), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1626 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%query_vectors.8, %1625), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:263:0
  %query.7 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%1626, %126, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:263:0
  %1628 : int[] = prim::ListConstruct(%1621, %1622, %128, %129), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1629 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%key_vectors.4, %1628), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:264:0
  %key.4 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%1629, %126, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:264:0
  %1631 : int = aten::size(%query.7, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.14 : Long() = prim::NumToTensor(%1631), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1633 : int = aten::size(%query.7, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.15 : Long() = prim::NumToTensor(%1633), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1635 : int = aten::size(%query.7, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.10 : Long() = prim::NumToTensor(%1635), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1637 : int = aten::size(%query.7, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:472:0
  %1638 : Long() = aten::floor_divide(%seq_len.15, %131), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/tensor.py:424:0
  %chunks_count.10 : Long() = aten::sub(%1638, %132, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:478:0
  %1640 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%query.7, %125, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:481:0
  %1641 : Long() = aten::mul(%batch_size.14, %num_heads.10), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:481:0
  %1642 : int = aten::Int(%1641), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1643 : int[] = prim::ListConstruct(%1642, %1633, %1637), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %hidden_states.35 : Float(204:64, 512:13056, 64:1) = aten::reshape(%1640, %1643), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:481:0
  %1645 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%key.4, %125, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:482:0
  %1646 : Long() = aten::mul(%batch_size.14, %num_heads.10), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:482:0
  %1647 : int = aten::Int(%1646), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1648 : int[] = prim::ListConstruct(%1647, %1633, %1637), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %hidden_states.37 : Float(204:64, 512:13056, 64:1) = aten::reshape(%1645, %1648), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:482:0
  %1650 : int = aten::size(%hidden_states.35, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:442:0
  %1651 : int = aten::size(%hidden_states.35, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:443:0
  %1652 : Long() = prim::NumToTensor(%1651), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1653 : Long() = aten::floor_divide(%1652, %133), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/tensor.py:424:0
  %1654 : int = aten::Int(%1653), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1655 : int = aten::size(%hidden_states.35, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:445:0
  %1656 : int[] = prim::ListConstruct(%1650, %1654, %134, %1655), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %hidden_states.36 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.35, %1656), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:441:0
  %1658 : int = aten::size(%hidden_states.36, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1659 : int = aten::size(%hidden_states.36, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1660 : Long() = prim::NumToTensor(%1659), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1661 : int = aten::size(%hidden_states.36, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1662 : int = aten::size(%hidden_states.36, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1663 : Long() = aten::mul(%1660, %135), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:450:0
  %1664 : Long() = aten::sub(%1663, %132, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:450:0
  %1665 : int = aten::Int(%1664), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1666 : int[] = prim::ListConstruct(%1658, %1665, %1661, %1662), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1667 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1668 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.36, %1666, %1667, %138), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:454:0
  %1669 : int = aten::size(%hidden_states.37, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:442:0
  %1670 : int = aten::size(%hidden_states.37, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:443:0
  %1671 : Long() = prim::NumToTensor(%1670), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1672 : Long() = aten::floor_divide(%1671, %133), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/tensor.py:424:0
  %1673 : int = aten::Int(%1672), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1674 : int = aten::size(%hidden_states.37, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:445:0
  %1675 : int[] = prim::ListConstruct(%1669, %1673, %134, %1674), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %hidden_states.38 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.37, %1675), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:441:0
  %1677 : int = aten::size(%hidden_states.38, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1678 : int = aten::size(%hidden_states.38, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1679 : Long() = prim::NumToTensor(%1678), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1680 : int = aten::size(%hidden_states.38, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1681 : int = aten::size(%hidden_states.38, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1682 : Long() = aten::mul(%1679, %135), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:450:0
  %1683 : Long() = aten::sub(%1682, %132, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:450:0
  %1684 : int = aten::Int(%1683), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1685 : int[] = prim::ListConstruct(%1677, %1684, %1680, %1681), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1686 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1687 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.38, %1685, %1686, %138), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:454:0
  %1688 : Tensor[] = prim::ListConstruct(%1668, %1687), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %input.44 : Float(204:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %1688), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/functional.py:327:0
  %1690 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %hidden_states_padded.7 : Float(204:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.44, %1690, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/nn/functional.py:3552:0
  %1692 : int = aten::size(%hidden_states_padded.7, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:401:0
  %1693 : int = aten::size(%hidden_states_padded.7, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:401:0
  %1694 : int = aten::size(%hidden_states_padded.7, %140), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:401:0
  %1695 : int = aten::size(%hidden_states_padded.7, %141), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:401:0
  %1696 : int[] = prim::ListConstruct(%1692, %1693, %1694, %1695), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %diagonal_chunked_attention_scores.7 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.7, %1696), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:400:0
  %1698 : Long() = aten::mul(%batch_size.14, %num_heads.10), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:504:0
  %1699 : int = aten::Int(%1698), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1700 : Long() = aten::add(%chunks_count.10, %132, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:504:0
  %1701 : int = aten::Int(%1700), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1702 : int[] = prim::ListConstruct(%1699, %1701, %142, %143), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %diagonal_attention_scores.7 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.7, %1702, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:503:0
  %1704 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.7, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1705 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%1704, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1706 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%1705, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1707 : Float(204:262656, 1:262656, 256:513, 257:1) = aten::slice(%1706, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1708 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.7, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1709 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%1708, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1710 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%1709, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1711 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::slice(%1710, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1712 : int[] = prim::ListConstruct(%149, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1713 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::view(%1707, %1712), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1714 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::copy_(%1711, %1713, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1715 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.7, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1716 : Float(204:262656, 512:513, 513:1) = aten::select(%1715, %125, %140), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1717 : Float(204:262656, 256:513, 513:1) = aten::slice(%1716, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1718 : Float(204:262656, 256:513, 257:1) = aten::slice(%1717, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1719 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.7, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1720 : Float(204:262656, 256:513, 513:1) = aten::select(%1719, %125, %140), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1721 : Float(204:262656, 256:513, 513:1) = aten::slice(%1720, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1722 : Float(204:262656, 256:513, 257:1) = aten::slice(%1721, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1723 : int[] = prim::ListConstruct(%149, %142, %148), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1724 : Float(204:262656, 256:513, 257:1) = aten::view(%1718, %1723), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1725 : Float(204:262656, 256:513, 257:1) = aten::copy_(%1722, %1724, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1726 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.7, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1727 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%1726, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1728 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%1727, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1729 : Float(204:262656, 1:262656, 256:513, 256:1) = aten::slice(%1728, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1730 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.7, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1731 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%1730, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1732 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%1731, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1733 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::slice(%1732, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1734 : int[] = prim::ListConstruct(%149, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1735 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::view(%1729, %1734), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1736 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::copy_(%1733, %1735, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1737 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.7, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1738 : Float(204:262656, 512:513, 513:1) = aten::select(%1737, %125, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1739 : Float(204:262656, 255:513, 513:1) = aten::slice(%1738, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1740 : Float(204:262656, 255:513, 255:1) = aten::slice(%1739, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1741 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.7, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1742 : Float(204:262656, 256:513, 513:1) = aten::select(%1741, %125, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1743 : Float(204:262656, 255:513, 513:1) = aten::slice(%1742, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1744 : Float(204:262656, 255:513, 255:1) = aten::slice(%1743, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1745 : int[] = prim::ListConstruct(%149, %151, %151), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1746 : Float(204:262656, 255:513, 255:1) = aten::view(%1740, %1745), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1747 : Float(204:262656, 255:513, 255:1) = aten::copy_(%1744, %1746, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1748 : int[] = prim::ListConstruct(%1631, %1635, %1633, %143), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1749 : Float(17:3151872, 12:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.7, %1748), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.10 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::transpose(%1749, %124, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:525:0
  %1751 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1752 : Float(256:257, 257:1) = aten::ones(%1751, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:458:0
  %1753 : Float(256:257, 257:1) = aten::tril(%1752, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:458:0
  %1754 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %beginning_mask_2d.7 : Float(256:257, 257:1) = aten::flip(%1753, %1754), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:458:0
  %1756 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.7, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:459:0
  %1757 : Float(1:65792, 256:257, 257:1) = aten::slice(%1756, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:459:0
  %1758 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%1757, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.7 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%1758, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:459:0
  %1760 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %ending_mask.7 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.7, %1760), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:460:0
  %1762 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.10, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:461:0
  %1763 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%1762, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:461:0
  %1764 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%1763, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.7 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%1764, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:461:0
  %1766 : int = aten::size(%beginning_input.7, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:462:0
  %1767 : int = aten::size(%beginning_input.7, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:462:0
  %1768 : int = aten::size(%beginning_input.7, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:462:0
  %1769 : int = aten::size(%beginning_input.7, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:462:0
  %1770 : int[] = prim::ListConstruct(%1766, %1767, %1768, %1769), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1771 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%beginning_mask.7, %1770, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:462:0
  %1772 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%1771, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/tensor.py:22:0
  %1773 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%beginning_input.7, %1772, %153), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:463:0
  %1774 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.10, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:464:0
  %1775 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%1774, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:464:0
  %1776 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%1775, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.7 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%1776, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:464:0
  %1778 : int = aten::size(%ending_input.7, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:465:0
  %1779 : int = aten::size(%ending_input.7, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:465:0
  %1780 : int = aten::size(%ending_input.7, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:465:0
  %1781 : int = aten::size(%ending_input.7, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:465:0
  %1782 : int[] = prim::ListConstruct(%1778, %1779, %1780, %1781), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1783 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%ending_mask.7, %1782, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:465:0
  %1784 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%1783, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/tensor.py:22:0
  %1785 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%ending_input.7, %1784, %153), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:466:0
  %1786 : Bool(17:512, 512:1) = aten::ne(%1603, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/tensor.py:22:0
  %1787 : Bool(17:512, 512:1) = aten::slice(%1786, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:272:0
  %1788 : Bool(17:512, 512:1) = aten::slice(%1787, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:272:0
  %1789 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%1788, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:272:0
  %remove_from_windowed_attention_mask.4 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%1789, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:272:0
  %1791 : Float(17:512, 512:1, 1:1, 1:1) = aten::type_as(%remove_from_windowed_attention_mask.4, %query.7), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:275:0
  %float_mask.4 : Float(17:512, 512:1, 1:1, 1:1) = aten::masked_fill(%1791, %remove_from_windowed_attention_mask.4, %155), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:275:0
  %1793 : int = aten::size(%float_mask.4, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:280:0
  %1794 : int = aten::size(%float_mask.4, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:280:0
  %1795 : int = aten::size(%float_mask.4, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:280:0
  %1796 : int = aten::size(%float_mask.4, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:280:0
  %1797 : int[] = prim::ListConstruct(%1793, %1794, %1795, %1796), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %query.8 : Float(17:512, 512:1, 1:1, 1:1) = aten::ones(%1797, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:280:0
  %1799 : int = aten::size(%query.8, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.15 : Long() = prim::NumToTensor(%1799), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1801 : int = aten::size(%query.8, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.16 : Long() = prim::NumToTensor(%1801), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1803 : int = aten::size(%query.8, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.11 : Long() = prim::NumToTensor(%1803), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1805 : int = aten::size(%query.8, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:472:0
  %1806 : Long() = aten::floor_divide(%seq_len.16, %131), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/tensor.py:424:0
  %chunks_count.11 : Long() = aten::sub(%1806, %132, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:478:0
  %1808 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%query.8, %125, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:481:0
  %1809 : Long() = aten::mul(%batch_size.15, %num_heads.11), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:481:0
  %1810 : int = aten::Int(%1809), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1811 : int[] = prim::ListConstruct(%1810, %1801, %1805), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %hidden_states.39 : Float(17:512, 512:1, 1:1) = aten::reshape(%1808, %1811), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:481:0
  %1813 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%float_mask.4, %125, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:482:0
  %1814 : Long() = aten::mul(%batch_size.15, %num_heads.11), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:482:0
  %1815 : int = aten::Int(%1814), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1816 : int[] = prim::ListConstruct(%1815, %1801, %1805), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %hidden_states.41 : Float(17:512, 512:1, 1:1) = aten::reshape(%1813, %1816), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:482:0
  %1818 : int = aten::size(%hidden_states.39, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:442:0
  %1819 : int = aten::size(%hidden_states.39, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:443:0
  %1820 : Long() = prim::NumToTensor(%1819), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1821 : Long() = aten::floor_divide(%1820, %133), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/tensor.py:424:0
  %1822 : int = aten::Int(%1821), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1823 : int = aten::size(%hidden_states.39, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:445:0
  %1824 : int[] = prim::ListConstruct(%1818, %1822, %134, %1823), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %hidden_states.40 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.39, %1824), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:441:0
  %1826 : int = aten::size(%hidden_states.40, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1827 : int = aten::size(%hidden_states.40, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1828 : Long() = prim::NumToTensor(%1827), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1829 : int = aten::size(%hidden_states.40, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1830 : int = aten::size(%hidden_states.40, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1831 : Long() = aten::mul(%1828, %135), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:450:0
  %1832 : Long() = aten::sub(%1831, %132, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:450:0
  %1833 : int = aten::Int(%1832), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1834 : int[] = prim::ListConstruct(%1826, %1833, %1829, %1830), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1835 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1836 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.40, %1834, %1835, %138), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:454:0
  %1837 : int = aten::size(%hidden_states.41, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:442:0
  %1838 : int = aten::size(%hidden_states.41, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:443:0
  %1839 : Long() = prim::NumToTensor(%1838), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1840 : Long() = aten::floor_divide(%1839, %133), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/tensor.py:424:0
  %1841 : int = aten::Int(%1840), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1842 : int = aten::size(%hidden_states.41, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:445:0
  %1843 : int[] = prim::ListConstruct(%1837, %1841, %134, %1842), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %hidden_states.42 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.41, %1843), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:441:0
  %1845 : int = aten::size(%hidden_states.42, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1846 : int = aten::size(%hidden_states.42, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1847 : Long() = prim::NumToTensor(%1846), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1848 : int = aten::size(%hidden_states.42, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1849 : int = aten::size(%hidden_states.42, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:449:0
  %1850 : Long() = aten::mul(%1847, %135), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:450:0
  %1851 : Long() = aten::sub(%1850, %132, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:450:0
  %1852 : int = aten::Int(%1851), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1853 : int[] = prim::ListConstruct(%1845, %1852, %1848, %1849), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1854 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1855 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.42, %1853, %1854, %138), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:454:0
  %1856 : Tensor[] = prim::ListConstruct(%1836, %1855), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %input.45 : Float(17:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %1856), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/functional.py:327:0
  %1858 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %hidden_states_padded.8 : Float(17:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.45, %1858, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/nn/functional.py:3552:0
  %1860 : int = aten::size(%hidden_states_padded.8, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:401:0
  %1861 : int = aten::size(%hidden_states_padded.8, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:401:0
  %1862 : int = aten::size(%hidden_states_padded.8, %140), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:401:0
  %1863 : int = aten::size(%hidden_states_padded.8, %141), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:401:0
  %1864 : int[] = prim::ListConstruct(%1860, %1861, %1862, %1863), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %diagonal_chunked_attention_scores.8 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.8, %1864), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:400:0
  %1866 : Long() = aten::mul(%batch_size.15, %num_heads.11), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:504:0
  %1867 : int = aten::Int(%1866), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1868 : Long() = aten::add(%chunks_count.11, %132, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:504:0
  %1869 : int = aten::Int(%1868), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1870 : int[] = prim::ListConstruct(%1867, %1869, %142, %143), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %diagonal_attention_scores.8 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.8, %1870, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:503:0
  %1872 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.8, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1873 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%1872, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1874 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%1873, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1875 : Float(17:262656, 1:262656, 256:513, 257:1) = aten::slice(%1874, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1876 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.8, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1877 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%1876, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1878 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%1877, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1879 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::slice(%1878, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1880 : int[] = prim::ListConstruct(%156, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1881 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::view(%1875, %1880), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1882 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::copy_(%1879, %1881, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:509:0
  %1883 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.8, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1884 : Float(17:262656, 512:513, 513:1) = aten::select(%1883, %125, %140), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1885 : Float(17:262656, 256:513, 513:1) = aten::slice(%1884, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1886 : Float(17:262656, 256:513, 257:1) = aten::slice(%1885, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1887 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.8, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1888 : Float(17:262656, 256:513, 513:1) = aten::select(%1887, %125, %140), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1889 : Float(17:262656, 256:513, 513:1) = aten::slice(%1888, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1890 : Float(17:262656, 256:513, 257:1) = aten::slice(%1889, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1891 : int[] = prim::ListConstruct(%156, %142, %148), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1892 : Float(17:262656, 256:513, 257:1) = aten::view(%1886, %1891), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1893 : Float(17:262656, 256:513, 257:1) = aten::copy_(%1890, %1892, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:512:0
  %1894 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.8, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1895 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%1894, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1896 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%1895, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1897 : Float(17:262656, 1:262656, 256:513, 256:1) = aten::slice(%1896, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1898 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.8, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1899 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%1898, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1900 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%1899, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1901 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::slice(%1900, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1902 : int[] = prim::ListConstruct(%156, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1903 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::view(%1897, %1902), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1904 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::copy_(%1901, %1903, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:516:0
  %1905 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.8, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1906 : Float(17:262656, 512:513, 513:1) = aten::select(%1905, %125, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1907 : Float(17:262656, 255:513, 513:1) = aten::slice(%1906, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1908 : Float(17:262656, 255:513, 255:1) = aten::slice(%1907, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1909 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.8, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1910 : Float(17:262656, 256:513, 513:1) = aten::select(%1909, %125, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1911 : Float(17:262656, 255:513, 513:1) = aten::slice(%1910, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1912 : Float(17:262656, 255:513, 255:1) = aten::slice(%1911, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1913 : int[] = prim::ListConstruct(%156, %151, %151), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1914 : Float(17:262656, 255:513, 255:1) = aten::view(%1908, %1913), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1915 : Float(17:262656, 255:513, 255:1) = aten::copy_(%1912, %1914, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:520:0
  %1916 : int[] = prim::ListConstruct(%1799, %1803, %1801, %143), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1917 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.8, %1916), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.11 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::transpose(%1917, %124, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:525:0
  %1919 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1920 : Float(256:257, 257:1) = aten::ones(%1919, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:458:0
  %1921 : Float(256:257, 257:1) = aten::tril(%1920, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:458:0
  %1922 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %beginning_mask_2d.8 : Float(256:257, 257:1) = aten::flip(%1921, %1922), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:458:0
  %1924 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.8, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:459:0
  %1925 : Float(1:65792, 256:257, 257:1) = aten::slice(%1924, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:459:0
  %1926 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%1925, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.8 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%1926, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:459:0
  %1928 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %ending_mask.8 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.8, %1928), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:460:0
  %1930 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.11, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:461:0
  %1931 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%1930, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:461:0
  %1932 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%1931, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.8 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%1932, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:461:0
  %1934 : int = aten::size(%beginning_input.8, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:462:0
  %1935 : int = aten::size(%beginning_input.8, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:462:0
  %1936 : int = aten::size(%beginning_input.8, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:462:0
  %1937 : int = aten::size(%beginning_input.8, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:462:0
  %1938 : int[] = prim::ListConstruct(%1934, %1935, %1936, %1937), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1939 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%beginning_mask.8, %1938, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:462:0
  %1940 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%1939, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/tensor.py:22:0
  %1941 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%beginning_input.8, %1940, %153), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:463:0
  %1942 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.11, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:464:0
  %1943 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%1942, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:464:0
  %1944 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%1943, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.8 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%1944, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:464:0
  %1946 : int = aten::size(%ending_input.8, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:465:0
  %1947 : int = aten::size(%ending_input.8, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:465:0
  %1948 : int = aten::size(%ending_input.8, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:465:0
  %1949 : int = aten::size(%ending_input.8, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:465:0
  %1950 : int[] = prim::ListConstruct(%1946, %1947, %1948, %1949), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1951 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%ending_mask.8, %1950, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:465:0
  %1952 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%1951, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/tensor.py:22:0
  %1953 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%ending_input.8, %1952, %153), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:466:0
  %attn_scores.4 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::add_(%input_tensor.10, %input_tensor.11, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:284:0
  %attn_probs_fp32.4 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::softmax(%attn_scores.4, %140, %144), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/nn/functional.py:1500:0
  %1956 : Bool(17:512, 512:1) = aten::slice(%is_index_masked.4, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:326:0
  %1957 : Bool(17:512, 512:1) = aten::slice(%1956, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:326:0
  %1958 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%1957, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:326:0
  %1959 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%1958, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:326:0
  %input.46 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::masked_fill(%attn_probs_fp32.4, %1959, %157), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:326:0
  %attn_probs.8 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::dropout(%input.46, %158, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/nn/functional.py:973:0
  %1962 : int[] = prim::ListConstruct(%1621, %1622, %128, %129), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1963 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%value_vectors.4, %1962), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:331:0
  %value.4 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%1963, %126, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:331:0
  %1965 : int = aten::size(%value.4, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:537:0
  %batch_size.16 : Long() = prim::NumToTensor(%1965), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1967 : int = aten::size(%value.4, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:537:0
  %seq_len.17 : Long() = prim::NumToTensor(%1967), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1969 : int = aten::size(%value.4, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:537:0
  %num_heads.12 : Long() = prim::NumToTensor(%1969), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1971 : int = aten::size(%value.4, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:537:0
  %1972 : Long() = aten::floor_divide(%seq_len.17, %131), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/tensor.py:424:0
  %chunks_count.12 : Long() = aten::sub(%1972, %132, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:542:0
  %1974 : Float(17:3151872, 12:513, 512:6156, 513:1) = aten::transpose(%attn_probs.8, %125, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:545:0
  %1975 : Long() = aten::mul(%batch_size.16, %num_heads.12), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:546:0
  %1976 : int = aten::Int(%1975), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1977 : Long() = aten::floor_divide(%seq_len.17, %131), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/tensor.py:424:0
  %1978 : int = aten::Int(%1977), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1979 : int[] = prim::ListConstruct(%1976, %1978, %142, %143), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %chunked_hidden_states.16 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::reshape(%1974, %1979), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:545:0
  %1981 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%value.4, %125, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:550:0
  %1982 : Long() = aten::mul(%batch_size.16, %num_heads.12), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:550:0
  %1983 : int = aten::Int(%1982), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1984 : int[] = prim::ListConstruct(%1983, %1967, %1971), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %input.47 : Float(204:64, 512:13056, 64:1) = aten::reshape(%1981, %1984), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:550:0
  %1986 : int[] = prim::ListConstruct(%126, %126, %142, %142), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %padded_value.4 : Float(204:65536, 1024:64, 64:1) = aten::constant_pad_nd(%input.47, %1986, %140), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/nn/functional.py:3552:0
  %1988 : Long() = aten::mul(%batch_size.16, %num_heads.12), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:556:0
  %1989 : int = aten::Int(%1988), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1990 : Long() = aten::add(%chunks_count.12, %132, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:556:0
  %1991 : int = aten::Int(%1990), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1992 : int[] = prim::ListConstruct(%1989, %1991, %159, %1971), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1993 : int[] = prim::ListConstruct(%160, %161, %129, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1994 : Float(204:65536, 2:16384, 768:64, 64:1) = aten::as_strided(%padded_value.4, %1992, %1993, %138), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:564:0
  %1995 : int = aten::size(%chunked_hidden_states.16, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:420:0
  %1996 : int = aten::size(%chunked_hidden_states.16, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:420:0
  %1997 : int = aten::size(%chunked_hidden_states.16, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:420:0
  %window_overlap.4 : Long() = prim::NumToTensor(%1997), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %1999 : int = aten::size(%chunked_hidden_states.16, %130), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:420:0
  %hidden_dim.4 : Long() = prim::NumToTensor(%1999), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %2001 : Long() = aten::add(%window_overlap.4, %132, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:422:0
  %2002 : int = aten::Int(%2001), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %2003 : int[] = prim::ListConstruct(%126, %2002), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %chunked_hidden_states.17 : Float(204:394240, 2:197120, 256:770, 770:1) = aten::constant_pad_nd(%chunked_hidden_states.16, %2003, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/nn/functional.py:3552:0
  %2005 : int[] = prim::ListConstruct(%1995, %1996, %140), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %chunked_hidden_states.18 : Float(204:394240, 2:197120, 197120:1) = aten::view(%chunked_hidden_states.17, %2005), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:424:0
  %2007 : Long() = aten::neg(%window_overlap.4), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:428:0
  %2008 : int = aten::Int(%2007), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %2009 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%chunked_hidden_states.18, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:427:0
  %2010 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%2009, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:427:0
  %chunked_hidden_states.19 : Float(204:394240, 2:197120, 196864:1) = aten::slice(%2010, %124, %126, %2008, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:427:0
  %2012 : Long() = aten::add(%window_overlap.4, %hidden_dim.4, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:431:0
  %2013 : int = aten::Int(%2012), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %2014 : int[] = prim::ListConstruct(%1995, %1996, %1997, %2013), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %chunked_hidden_states.20 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::view(%chunked_hidden_states.19, %2014), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:430:0
  %2016 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%chunked_hidden_states.20, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:433:0
  %2017 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%2016, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:433:0
  %2018 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%2017, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:433:0
  %2019 : Float(204:394240, 2:197120, 256:769, 768:1) = aten::slice(%2018, %130, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:433:0
  %2020 : Tensor[] = prim::ListConstruct(%2019, %1994), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %context.4 : Float(204:32768, 2:16384, 256:64, 64:1) = aten::einsum(%162, %2020), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/functional.py:327:0
  %2022 : int[] = prim::ListConstruct(%1965, %1969, %1967, %1971), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %2023 : Float(17:393216, 12:32768, 512:64, 64:1) = aten::view(%context.4, %2022), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:569:0
  %attn_output.7 : Float(17:393216, 512:64, 12:32768, 64:1) = aten::transpose(%2023, %125, %124), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:569:0
  %2025 : Float(512:64, 17:393216, 12:32768, 64:1) = aten::transpose(%attn_output.7, %126, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:350:0
  %2026 : int[] = prim::ListConstruct(%1621, %1622, %1623), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %2027 : Float(512:13056, 17:768, 768:1) = aten::reshape(%2025, %2026), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:350:0
  %attn_output.8 : Float(512:13056, 17:768, 768:1) = aten::contiguous(%2027, %126), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:350:0
  %input.48 : Float(17:768, 512:13056, 768:1) = aten::transpose(%attn_output.8, %126, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_longformer.py:374:0
  %2030 : __torch__.torch.nn.modules.normalization.___torch_mangle_8115.LayerNorm = prim::GetAttr[name="LayerNorm"](%1597)
  %2031 : __torch__.torch.nn.modules.linear.___torch_mangle_8114.Linear = prim::GetAttr[name="dense"](%1597)
  %2032 : Tensor = prim::GetAttr[name="bias"](%2031)
  %2033 : Tensor = prim::GetAttr[name="weight"](%2031)
  %2034 : Float(768:1, 768:768) = aten::t(%2033), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %output.22 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.48, %2034), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %input.49 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.22, %2032, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.43 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.49, %158, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.dropout # torch/nn/functional.py:973:0
  %input.50 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.43, %hidden_states.34, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output # transformers/modeling_longformer.py:758:0
  %2039 : Tensor = prim::GetAttr[name="bias"](%2030)
  %2040 : Tensor = prim::GetAttr[name="weight"](%2030)
  %2041 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.LayerNorm
  %input_tensor.12 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.50, %2041, %2040, %2039, %123, %122), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %2043 : __torch__.torch.nn.modules.linear.___torch_mangle_8119.Linear = prim::GetAttr[name="dense"](%1595)
  %2044 : Tensor = prim::GetAttr[name="bias"](%2043)
  %2045 : Tensor = prim::GetAttr[name="weight"](%2043)
  %2046 : Float(768:1, 3072:768) = aten::t(%2045), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.intermediate/__module.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %output.23 : Float(17:1572864, 512:3072, 3072:1) = aten::matmul(%input_tensor.12, %2046), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.intermediate/__module.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %input.51 : Float(17:1572864, 512:3072, 3072:1) = aten::add_(%output.23, %2044, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.intermediate/__module.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1678:0
  %input.52 : Float(17:1572864, 512:3072, 3072:1) = aten::gelu(%input.51), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.intermediate # torch/nn/functional.py:1369:0
  %2050 : __torch__.torch.nn.modules.normalization.___torch_mangle_8122.LayerNorm = prim::GetAttr[name="LayerNorm"](%1594)
  %2051 : __torch__.torch.nn.modules.linear.___torch_mangle_8121.Linear = prim::GetAttr[name="dense"](%1594)
  %2052 : Tensor = prim::GetAttr[name="bias"](%2051)
  %2053 : Tensor = prim::GetAttr[name="weight"](%2051)
  %2054 : Float(3072:1, 768:3072) = aten::t(%2053), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %output.24 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.52, %2054), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %input.53 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.24, %2052, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.44 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.53, %158, %146), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.dropout # torch/nn/functional.py:973:0
  %input.54 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.44, %input_tensor.12, %125), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output # transformers/modeling_longformer.py:830:0
  %2059 : Tensor = prim::GetAttr[name="bias"](%2050)
  %2060 : Tensor = prim::GetAttr[name="weight"](%2050)
  %2061 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.LayerNorm
  %hidden_states.45 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.54, %2061, %2060, %2059, %123, %122), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.LayerNorm # torch/nn/functional.py:2048:0
  %2063 : __torch__.transformers.modeling_longformer.___torch_mangle_8143.LongformerOutput = prim::GetAttr[name="output"](%178)
  %2064 : __torch__.transformers.modeling_longformer.___torch_mangle_8139.LongformerIntermediate = prim::GetAttr[name="intermediate"](%178)
  %2065 : __torch__.transformers.modeling_longformer.___torch_mangle_8137.LongformerAttention = prim::GetAttr[name="attention"](%178)
  %2066 : __torch__.transformers.modeling_longformer.___torch_mangle_8136.LongformerSelfOutput = prim::GetAttr[name="output"](%2065)
  %2067 : __torch__.transformers.modeling_longformer.___torch_mangle_8132.LongformerSelfAttention = prim::GetAttr[name="self"](%2065)
  %2068 : __torch__.torch.nn.modules.linear.___torch_mangle_8128.Linear = prim::GetAttr[name="value"](%2067)
  %2069 : __torch__.torch.nn.modules.linear.___torch_mangle_8127.Linear = prim::GetAttr[name="key"](%2067)
  %2070 : __torch__.torch.nn.modules.linear.___torch_mangle_8126.Linear = prim::GetAttr[name="query"](%2067)
  %2071 : Float(17:512, 1:512, 512:1) = aten::squeeze(%attention_mask, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:241:0
  %2072 : Float(17:512, 512:1) = aten::squeeze(%2071, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:241:0
  %is_index_masked.5 : Bool(17:512, 512:1) = aten::lt(%2072, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/tensor.py:22:0
  %input.55 : Float(512:768, 17:393216, 768:1) = aten::transpose(%hidden_states.45, %126, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:248:0
  %2075 : Tensor = prim::GetAttr[name="bias"](%2070)
  %2076 : Tensor = prim::GetAttr[name="weight"](%2070)
  %2077 : Float(768:1, 768:768) = aten::t(%2076), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %output.25 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.55, %2077), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %query_vectors.9 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.25, %2075, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.query # torch/nn/functional.py:1678:0
  %2080 : Tensor = prim::GetAttr[name="bias"](%2069)
  %2081 : Tensor = prim::GetAttr[name="weight"](%2069)
  %2082 : Float(768:1, 768:768) = aten::t(%2081), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %output.26 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.55, %2082), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %key_vectors.5 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.26, %2080, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.key # torch/nn/functional.py:1678:0
  %2085 : Tensor = prim::GetAttr[name="bias"](%2068)
  %2086 : Tensor = prim::GetAttr[name="weight"](%2068)
  %2087 : Float(768:1, 768:768) = aten::t(%2086), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %output.27 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.55, %2087), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %value_vectors.5 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.27, %2085, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.value # torch/nn/functional.py:1678:0
  %2090 : int = aten::size(%input.55, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:255:0
  %2091 : int = aten::size(%input.55, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:255:0
  %2092 : int = aten::size(%input.55, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:255:0
  %query_vectors.10 : Float(512:13056, 17:768, 768:1) = aten::div_(%query_vectors.9, %127), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:261:0
  %2094 : int[] = prim::ListConstruct(%2090, %2091, %128, %129), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2095 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%query_vectors.10, %2094), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:263:0
  %query.9 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%2095, %126, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:263:0
  %2097 : int[] = prim::ListConstruct(%2090, %2091, %128, %129), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2098 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%key_vectors.5, %2097), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:264:0
  %key.5 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%2098, %126, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:264:0
  %2100 : int = aten::size(%query.9, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.18 : Long() = prim::NumToTensor(%2100), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2102 : int = aten::size(%query.9, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.19 : Long() = prim::NumToTensor(%2102), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2104 : int = aten::size(%query.9, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.13 : Long() = prim::NumToTensor(%2104), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2106 : int = aten::size(%query.9, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:472:0
  %2107 : Long() = aten::floor_divide(%seq_len.19, %131), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/tensor.py:424:0
  %chunks_count.13 : Long() = aten::sub(%2107, %132, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:478:0
  %2109 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%query.9, %125, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:481:0
  %2110 : Long() = aten::mul(%batch_size.18, %num_heads.13), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:481:0
  %2111 : int = aten::Int(%2110), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2112 : int[] = prim::ListConstruct(%2111, %2102, %2106), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %hidden_states.46 : Float(204:64, 512:13056, 64:1) = aten::reshape(%2109, %2112), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:481:0
  %2114 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%key.5, %125, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:482:0
  %2115 : Long() = aten::mul(%batch_size.18, %num_heads.13), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:482:0
  %2116 : int = aten::Int(%2115), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2117 : int[] = prim::ListConstruct(%2116, %2102, %2106), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %hidden_states.48 : Float(204:64, 512:13056, 64:1) = aten::reshape(%2114, %2117), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:482:0
  %2119 : int = aten::size(%hidden_states.46, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:442:0
  %2120 : int = aten::size(%hidden_states.46, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:443:0
  %2121 : Long() = prim::NumToTensor(%2120), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2122 : Long() = aten::floor_divide(%2121, %133), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/tensor.py:424:0
  %2123 : int = aten::Int(%2122), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2124 : int = aten::size(%hidden_states.46, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:445:0
  %2125 : int[] = prim::ListConstruct(%2119, %2123, %134, %2124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %hidden_states.47 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.46, %2125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:441:0
  %2127 : int = aten::size(%hidden_states.47, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2128 : int = aten::size(%hidden_states.47, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2129 : Long() = prim::NumToTensor(%2128), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2130 : int = aten::size(%hidden_states.47, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2131 : int = aten::size(%hidden_states.47, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2132 : Long() = aten::mul(%2129, %135), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:450:0
  %2133 : Long() = aten::sub(%2132, %132, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:450:0
  %2134 : int = aten::Int(%2133), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2135 : int[] = prim::ListConstruct(%2127, %2134, %2130, %2131), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2136 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2137 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.47, %2135, %2136, %138), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:454:0
  %2138 : int = aten::size(%hidden_states.48, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:442:0
  %2139 : int = aten::size(%hidden_states.48, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:443:0
  %2140 : Long() = prim::NumToTensor(%2139), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2141 : Long() = aten::floor_divide(%2140, %133), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/tensor.py:424:0
  %2142 : int = aten::Int(%2141), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2143 : int = aten::size(%hidden_states.48, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:445:0
  %2144 : int[] = prim::ListConstruct(%2138, %2142, %134, %2143), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %hidden_states.49 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.48, %2144), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:441:0
  %2146 : int = aten::size(%hidden_states.49, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2147 : int = aten::size(%hidden_states.49, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2148 : Long() = prim::NumToTensor(%2147), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2149 : int = aten::size(%hidden_states.49, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2150 : int = aten::size(%hidden_states.49, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2151 : Long() = aten::mul(%2148, %135), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:450:0
  %2152 : Long() = aten::sub(%2151, %132, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:450:0
  %2153 : int = aten::Int(%2152), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2154 : int[] = prim::ListConstruct(%2146, %2153, %2149, %2150), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2155 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2156 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.49, %2154, %2155, %138), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:454:0
  %2157 : Tensor[] = prim::ListConstruct(%2137, %2156), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %input.56 : Float(204:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %2157), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/functional.py:327:0
  %2159 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %hidden_states_padded.9 : Float(204:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.56, %2159, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/nn/functional.py:3552:0
  %2161 : int = aten::size(%hidden_states_padded.9, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:401:0
  %2162 : int = aten::size(%hidden_states_padded.9, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:401:0
  %2163 : int = aten::size(%hidden_states_padded.9, %140), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:401:0
  %2164 : int = aten::size(%hidden_states_padded.9, %141), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:401:0
  %2165 : int[] = prim::ListConstruct(%2161, %2162, %2163, %2164), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %diagonal_chunked_attention_scores.9 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.9, %2165), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:400:0
  %2167 : Long() = aten::mul(%batch_size.18, %num_heads.13), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:504:0
  %2168 : int = aten::Int(%2167), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2169 : Long() = aten::add(%chunks_count.13, %132, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:504:0
  %2170 : int = aten::Int(%2169), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2171 : int[] = prim::ListConstruct(%2168, %2170, %142, %143), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %diagonal_attention_scores.9 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.9, %2171, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:503:0
  %2173 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.9, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2174 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%2173, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2175 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%2174, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2176 : Float(204:262656, 1:262656, 256:513, 257:1) = aten::slice(%2175, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2177 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.9, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2178 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%2177, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2179 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%2178, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2180 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::slice(%2179, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2181 : int[] = prim::ListConstruct(%149, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2182 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::view(%2176, %2181), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2183 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::copy_(%2180, %2182, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2184 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.9, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2185 : Float(204:262656, 512:513, 513:1) = aten::select(%2184, %125, %140), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2186 : Float(204:262656, 256:513, 513:1) = aten::slice(%2185, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2187 : Float(204:262656, 256:513, 257:1) = aten::slice(%2186, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2188 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.9, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2189 : Float(204:262656, 256:513, 513:1) = aten::select(%2188, %125, %140), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2190 : Float(204:262656, 256:513, 513:1) = aten::slice(%2189, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2191 : Float(204:262656, 256:513, 257:1) = aten::slice(%2190, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2192 : int[] = prim::ListConstruct(%149, %142, %148), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2193 : Float(204:262656, 256:513, 257:1) = aten::view(%2187, %2192), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2194 : Float(204:262656, 256:513, 257:1) = aten::copy_(%2191, %2193, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2195 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.9, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2196 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%2195, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2197 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%2196, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2198 : Float(204:262656, 1:262656, 256:513, 256:1) = aten::slice(%2197, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2199 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.9, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2200 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%2199, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2201 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%2200, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2202 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::slice(%2201, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2203 : int[] = prim::ListConstruct(%149, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2204 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::view(%2198, %2203), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2205 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::copy_(%2202, %2204, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2206 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.9, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2207 : Float(204:262656, 512:513, 513:1) = aten::select(%2206, %125, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2208 : Float(204:262656, 255:513, 513:1) = aten::slice(%2207, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2209 : Float(204:262656, 255:513, 255:1) = aten::slice(%2208, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2210 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.9, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2211 : Float(204:262656, 256:513, 513:1) = aten::select(%2210, %125, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2212 : Float(204:262656, 255:513, 513:1) = aten::slice(%2211, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2213 : Float(204:262656, 255:513, 255:1) = aten::slice(%2212, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2214 : int[] = prim::ListConstruct(%149, %151, %151), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2215 : Float(204:262656, 255:513, 255:1) = aten::view(%2209, %2214), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2216 : Float(204:262656, 255:513, 255:1) = aten::copy_(%2213, %2215, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2217 : int[] = prim::ListConstruct(%2100, %2104, %2102, %143), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2218 : Float(17:3151872, 12:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.9, %2217), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.13 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::transpose(%2218, %124, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:525:0
  %2220 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2221 : Float(256:257, 257:1) = aten::ones(%2220, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:458:0
  %2222 : Float(256:257, 257:1) = aten::tril(%2221, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:458:0
  %2223 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %beginning_mask_2d.9 : Float(256:257, 257:1) = aten::flip(%2222, %2223), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:458:0
  %2225 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.9, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:459:0
  %2226 : Float(1:65792, 256:257, 257:1) = aten::slice(%2225, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:459:0
  %2227 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%2226, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.9 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%2227, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:459:0
  %2229 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %ending_mask.9 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.9, %2229), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:460:0
  %2231 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.13, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:461:0
  %2232 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%2231, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:461:0
  %2233 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%2232, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.9 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%2233, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:461:0
  %2235 : int = aten::size(%beginning_input.9, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:462:0
  %2236 : int = aten::size(%beginning_input.9, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:462:0
  %2237 : int = aten::size(%beginning_input.9, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:462:0
  %2238 : int = aten::size(%beginning_input.9, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:462:0
  %2239 : int[] = prim::ListConstruct(%2235, %2236, %2237, %2238), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2240 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%beginning_mask.9, %2239, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:462:0
  %2241 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%2240, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/tensor.py:22:0
  %2242 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%beginning_input.9, %2241, %153), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:463:0
  %2243 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.13, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:464:0
  %2244 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%2243, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:464:0
  %2245 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%2244, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.9 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%2245, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:464:0
  %2247 : int = aten::size(%ending_input.9, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:465:0
  %2248 : int = aten::size(%ending_input.9, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:465:0
  %2249 : int = aten::size(%ending_input.9, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:465:0
  %2250 : int = aten::size(%ending_input.9, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:465:0
  %2251 : int[] = prim::ListConstruct(%2247, %2248, %2249, %2250), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2252 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%ending_mask.9, %2251, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:465:0
  %2253 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%2252, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/tensor.py:22:0
  %2254 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%ending_input.9, %2253, %153), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:466:0
  %2255 : Bool(17:512, 512:1) = aten::ne(%2072, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/tensor.py:22:0
  %2256 : Bool(17:512, 512:1) = aten::slice(%2255, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:272:0
  %2257 : Bool(17:512, 512:1) = aten::slice(%2256, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:272:0
  %2258 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%2257, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:272:0
  %remove_from_windowed_attention_mask.5 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%2258, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:272:0
  %2260 : Float(17:512, 512:1, 1:1, 1:1) = aten::type_as(%remove_from_windowed_attention_mask.5, %query.9), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:275:0
  %float_mask.5 : Float(17:512, 512:1, 1:1, 1:1) = aten::masked_fill(%2260, %remove_from_windowed_attention_mask.5, %155), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:275:0
  %2262 : int = aten::size(%float_mask.5, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:280:0
  %2263 : int = aten::size(%float_mask.5, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:280:0
  %2264 : int = aten::size(%float_mask.5, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:280:0
  %2265 : int = aten::size(%float_mask.5, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:280:0
  %2266 : int[] = prim::ListConstruct(%2262, %2263, %2264, %2265), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %query.10 : Float(17:512, 512:1, 1:1, 1:1) = aten::ones(%2266, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:280:0
  %2268 : int = aten::size(%query.10, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.19 : Long() = prim::NumToTensor(%2268), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2270 : int = aten::size(%query.10, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.20 : Long() = prim::NumToTensor(%2270), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2272 : int = aten::size(%query.10, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.14 : Long() = prim::NumToTensor(%2272), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2274 : int = aten::size(%query.10, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:472:0
  %2275 : Long() = aten::floor_divide(%seq_len.20, %131), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/tensor.py:424:0
  %chunks_count.14 : Long() = aten::sub(%2275, %132, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:478:0
  %2277 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%query.10, %125, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:481:0
  %2278 : Long() = aten::mul(%batch_size.19, %num_heads.14), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:481:0
  %2279 : int = aten::Int(%2278), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2280 : int[] = prim::ListConstruct(%2279, %2270, %2274), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %hidden_states.50 : Float(17:512, 512:1, 1:1) = aten::reshape(%2277, %2280), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:481:0
  %2282 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%float_mask.5, %125, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:482:0
  %2283 : Long() = aten::mul(%batch_size.19, %num_heads.14), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:482:0
  %2284 : int = aten::Int(%2283), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2285 : int[] = prim::ListConstruct(%2284, %2270, %2274), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %hidden_states.52 : Float(17:512, 512:1, 1:1) = aten::reshape(%2282, %2285), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:482:0
  %2287 : int = aten::size(%hidden_states.50, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:442:0
  %2288 : int = aten::size(%hidden_states.50, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:443:0
  %2289 : Long() = prim::NumToTensor(%2288), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2290 : Long() = aten::floor_divide(%2289, %133), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/tensor.py:424:0
  %2291 : int = aten::Int(%2290), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2292 : int = aten::size(%hidden_states.50, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:445:0
  %2293 : int[] = prim::ListConstruct(%2287, %2291, %134, %2292), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %hidden_states.51 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.50, %2293), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:441:0
  %2295 : int = aten::size(%hidden_states.51, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2296 : int = aten::size(%hidden_states.51, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2297 : Long() = prim::NumToTensor(%2296), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2298 : int = aten::size(%hidden_states.51, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2299 : int = aten::size(%hidden_states.51, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2300 : Long() = aten::mul(%2297, %135), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:450:0
  %2301 : Long() = aten::sub(%2300, %132, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:450:0
  %2302 : int = aten::Int(%2301), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2303 : int[] = prim::ListConstruct(%2295, %2302, %2298, %2299), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2304 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2305 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.51, %2303, %2304, %138), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:454:0
  %2306 : int = aten::size(%hidden_states.52, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:442:0
  %2307 : int = aten::size(%hidden_states.52, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:443:0
  %2308 : Long() = prim::NumToTensor(%2307), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2309 : Long() = aten::floor_divide(%2308, %133), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/tensor.py:424:0
  %2310 : int = aten::Int(%2309), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2311 : int = aten::size(%hidden_states.52, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:445:0
  %2312 : int[] = prim::ListConstruct(%2306, %2310, %134, %2311), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %hidden_states.53 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.52, %2312), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:441:0
  %2314 : int = aten::size(%hidden_states.53, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2315 : int = aten::size(%hidden_states.53, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2316 : Long() = prim::NumToTensor(%2315), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2317 : int = aten::size(%hidden_states.53, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2318 : int = aten::size(%hidden_states.53, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:449:0
  %2319 : Long() = aten::mul(%2316, %135), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:450:0
  %2320 : Long() = aten::sub(%2319, %132, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:450:0
  %2321 : int = aten::Int(%2320), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2322 : int[] = prim::ListConstruct(%2314, %2321, %2317, %2318), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2323 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2324 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.53, %2322, %2323, %138), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:454:0
  %2325 : Tensor[] = prim::ListConstruct(%2305, %2324), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %input.57 : Float(17:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %2325), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/functional.py:327:0
  %2327 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %hidden_states_padded.10 : Float(17:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.57, %2327, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/nn/functional.py:3552:0
  %2329 : int = aten::size(%hidden_states_padded.10, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:401:0
  %2330 : int = aten::size(%hidden_states_padded.10, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:401:0
  %2331 : int = aten::size(%hidden_states_padded.10, %140), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:401:0
  %2332 : int = aten::size(%hidden_states_padded.10, %141), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:401:0
  %2333 : int[] = prim::ListConstruct(%2329, %2330, %2331, %2332), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %diagonal_chunked_attention_scores.10 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.10, %2333), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:400:0
  %2335 : Long() = aten::mul(%batch_size.19, %num_heads.14), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:504:0
  %2336 : int = aten::Int(%2335), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2337 : Long() = aten::add(%chunks_count.14, %132, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:504:0
  %2338 : int = aten::Int(%2337), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2339 : int[] = prim::ListConstruct(%2336, %2338, %142, %143), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %diagonal_attention_scores.10 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.10, %2339, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:503:0
  %2341 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.10, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2342 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%2341, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2343 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%2342, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2344 : Float(17:262656, 1:262656, 256:513, 257:1) = aten::slice(%2343, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2345 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.10, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2346 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%2345, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2347 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%2346, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2348 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::slice(%2347, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2349 : int[] = prim::ListConstruct(%156, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2350 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::view(%2344, %2349), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2351 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::copy_(%2348, %2350, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:509:0
  %2352 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.10, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2353 : Float(17:262656, 512:513, 513:1) = aten::select(%2352, %125, %140), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2354 : Float(17:262656, 256:513, 513:1) = aten::slice(%2353, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2355 : Float(17:262656, 256:513, 257:1) = aten::slice(%2354, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2356 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.10, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2357 : Float(17:262656, 256:513, 513:1) = aten::select(%2356, %125, %140), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2358 : Float(17:262656, 256:513, 513:1) = aten::slice(%2357, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2359 : Float(17:262656, 256:513, 257:1) = aten::slice(%2358, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2360 : int[] = prim::ListConstruct(%156, %142, %148), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2361 : Float(17:262656, 256:513, 257:1) = aten::view(%2355, %2360), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2362 : Float(17:262656, 256:513, 257:1) = aten::copy_(%2359, %2361, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:512:0
  %2363 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.10, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2364 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%2363, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2365 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%2364, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2366 : Float(17:262656, 1:262656, 256:513, 256:1) = aten::slice(%2365, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2367 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.10, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2368 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%2367, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2369 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%2368, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2370 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::slice(%2369, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2371 : int[] = prim::ListConstruct(%156, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2372 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::view(%2366, %2371), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2373 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::copy_(%2370, %2372, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:516:0
  %2374 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.10, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2375 : Float(17:262656, 512:513, 513:1) = aten::select(%2374, %125, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2376 : Float(17:262656, 255:513, 513:1) = aten::slice(%2375, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2377 : Float(17:262656, 255:513, 255:1) = aten::slice(%2376, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2378 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.10, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2379 : Float(17:262656, 256:513, 513:1) = aten::select(%2378, %125, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2380 : Float(17:262656, 255:513, 513:1) = aten::slice(%2379, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2381 : Float(17:262656, 255:513, 255:1) = aten::slice(%2380, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2382 : int[] = prim::ListConstruct(%156, %151, %151), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2383 : Float(17:262656, 255:513, 255:1) = aten::view(%2377, %2382), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2384 : Float(17:262656, 255:513, 255:1) = aten::copy_(%2381, %2383, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:520:0
  %2385 : int[] = prim::ListConstruct(%2268, %2272, %2270, %143), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2386 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.10, %2385), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.14 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::transpose(%2386, %124, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:525:0
  %2388 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2389 : Float(256:257, 257:1) = aten::ones(%2388, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:458:0
  %2390 : Float(256:257, 257:1) = aten::tril(%2389, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:458:0
  %2391 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %beginning_mask_2d.10 : Float(256:257, 257:1) = aten::flip(%2390, %2391), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:458:0
  %2393 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.10, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:459:0
  %2394 : Float(1:65792, 256:257, 257:1) = aten::slice(%2393, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:459:0
  %2395 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%2394, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.10 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%2395, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:459:0
  %2397 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %ending_mask.10 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.10, %2397), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:460:0
  %2399 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.14, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:461:0
  %2400 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%2399, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:461:0
  %2401 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%2400, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.10 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%2401, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:461:0
  %2403 : int = aten::size(%beginning_input.10, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:462:0
  %2404 : int = aten::size(%beginning_input.10, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:462:0
  %2405 : int = aten::size(%beginning_input.10, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:462:0
  %2406 : int = aten::size(%beginning_input.10, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:462:0
  %2407 : int[] = prim::ListConstruct(%2403, %2404, %2405, %2406), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2408 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%beginning_mask.10, %2407, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:462:0
  %2409 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%2408, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/tensor.py:22:0
  %2410 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%beginning_input.10, %2409, %153), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:463:0
  %2411 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.14, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:464:0
  %2412 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%2411, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:464:0
  %2413 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%2412, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.10 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%2413, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:464:0
  %2415 : int = aten::size(%ending_input.10, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:465:0
  %2416 : int = aten::size(%ending_input.10, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:465:0
  %2417 : int = aten::size(%ending_input.10, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:465:0
  %2418 : int = aten::size(%ending_input.10, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:465:0
  %2419 : int[] = prim::ListConstruct(%2415, %2416, %2417, %2418), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2420 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%ending_mask.10, %2419, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:465:0
  %2421 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%2420, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/tensor.py:22:0
  %2422 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%ending_input.10, %2421, %153), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:466:0
  %attn_scores.5 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::add_(%input_tensor.13, %input_tensor.14, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:284:0
  %attn_probs_fp32.5 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::softmax(%attn_scores.5, %140, %144), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/nn/functional.py:1500:0
  %2425 : Bool(17:512, 512:1) = aten::slice(%is_index_masked.5, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:326:0
  %2426 : Bool(17:512, 512:1) = aten::slice(%2425, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:326:0
  %2427 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%2426, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:326:0
  %2428 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%2427, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:326:0
  %input.58 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::masked_fill(%attn_probs_fp32.5, %2428, %157), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:326:0
  %attn_probs.10 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::dropout(%input.58, %158, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/nn/functional.py:973:0
  %2431 : int[] = prim::ListConstruct(%2090, %2091, %128, %129), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2432 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%value_vectors.5, %2431), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:331:0
  %value.5 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%2432, %126, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:331:0
  %2434 : int = aten::size(%value.5, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:537:0
  %batch_size.20 : Long() = prim::NumToTensor(%2434), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2436 : int = aten::size(%value.5, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:537:0
  %seq_len.21 : Long() = prim::NumToTensor(%2436), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2438 : int = aten::size(%value.5, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:537:0
  %num_heads.15 : Long() = prim::NumToTensor(%2438), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2440 : int = aten::size(%value.5, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:537:0
  %2441 : Long() = aten::floor_divide(%seq_len.21, %131), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/tensor.py:424:0
  %chunks_count.15 : Long() = aten::sub(%2441, %132, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:542:0
  %2443 : Float(17:3151872, 12:513, 512:6156, 513:1) = aten::transpose(%attn_probs.10, %125, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:545:0
  %2444 : Long() = aten::mul(%batch_size.20, %num_heads.15), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:546:0
  %2445 : int = aten::Int(%2444), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2446 : Long() = aten::floor_divide(%seq_len.21, %131), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/tensor.py:424:0
  %2447 : int = aten::Int(%2446), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2448 : int[] = prim::ListConstruct(%2445, %2447, %142, %143), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %chunked_hidden_states.21 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::reshape(%2443, %2448), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:545:0
  %2450 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%value.5, %125, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:550:0
  %2451 : Long() = aten::mul(%batch_size.20, %num_heads.15), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:550:0
  %2452 : int = aten::Int(%2451), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2453 : int[] = prim::ListConstruct(%2452, %2436, %2440), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %input.59 : Float(204:64, 512:13056, 64:1) = aten::reshape(%2450, %2453), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:550:0
  %2455 : int[] = prim::ListConstruct(%126, %126, %142, %142), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %padded_value.5 : Float(204:65536, 1024:64, 64:1) = aten::constant_pad_nd(%input.59, %2455, %140), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/nn/functional.py:3552:0
  %2457 : Long() = aten::mul(%batch_size.20, %num_heads.15), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:556:0
  %2458 : int = aten::Int(%2457), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2459 : Long() = aten::add(%chunks_count.15, %132, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:556:0
  %2460 : int = aten::Int(%2459), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2461 : int[] = prim::ListConstruct(%2458, %2460, %159, %2440), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2462 : int[] = prim::ListConstruct(%160, %161, %129, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2463 : Float(204:65536, 2:16384, 768:64, 64:1) = aten::as_strided(%padded_value.5, %2461, %2462, %138), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:564:0
  %2464 : int = aten::size(%chunked_hidden_states.21, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:420:0
  %2465 : int = aten::size(%chunked_hidden_states.21, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:420:0
  %2466 : int = aten::size(%chunked_hidden_states.21, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:420:0
  %window_overlap.5 : Long() = prim::NumToTensor(%2466), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2468 : int = aten::size(%chunked_hidden_states.21, %130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:420:0
  %hidden_dim.5 : Long() = prim::NumToTensor(%2468), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2470 : Long() = aten::add(%window_overlap.5, %132, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:422:0
  %2471 : int = aten::Int(%2470), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2472 : int[] = prim::ListConstruct(%126, %2471), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %chunked_hidden_states.22 : Float(204:394240, 2:197120, 256:770, 770:1) = aten::constant_pad_nd(%chunked_hidden_states.21, %2472, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/nn/functional.py:3552:0
  %2474 : int[] = prim::ListConstruct(%2464, %2465, %140), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %chunked_hidden_states.23 : Float(204:394240, 2:197120, 197120:1) = aten::view(%chunked_hidden_states.22, %2474), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:424:0
  %2476 : Long() = aten::neg(%window_overlap.5), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:428:0
  %2477 : int = aten::Int(%2476), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2478 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%chunked_hidden_states.23, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:427:0
  %2479 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%2478, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:427:0
  %chunked_hidden_states.24 : Float(204:394240, 2:197120, 196864:1) = aten::slice(%2479, %124, %126, %2477, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:427:0
  %2481 : Long() = aten::add(%window_overlap.5, %hidden_dim.5, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:431:0
  %2482 : int = aten::Int(%2481), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2483 : int[] = prim::ListConstruct(%2464, %2465, %2466, %2482), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %chunked_hidden_states.25 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::view(%chunked_hidden_states.24, %2483), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:430:0
  %2485 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%chunked_hidden_states.25, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:433:0
  %2486 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%2485, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:433:0
  %2487 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%2486, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:433:0
  %2488 : Float(204:394240, 2:197120, 256:769, 768:1) = aten::slice(%2487, %130, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:433:0
  %2489 : Tensor[] = prim::ListConstruct(%2488, %2463), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %context.5 : Float(204:32768, 2:16384, 256:64, 64:1) = aten::einsum(%162, %2489), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/functional.py:327:0
  %2491 : int[] = prim::ListConstruct(%2434, %2438, %2436, %2440), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2492 : Float(17:393216, 12:32768, 512:64, 64:1) = aten::view(%context.5, %2491), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:569:0
  %attn_output.9 : Float(17:393216, 512:64, 12:32768, 64:1) = aten::transpose(%2492, %125, %124), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:569:0
  %2494 : Float(512:64, 17:393216, 12:32768, 64:1) = aten::transpose(%attn_output.9, %126, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:350:0
  %2495 : int[] = prim::ListConstruct(%2090, %2091, %2092), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %2496 : Float(512:13056, 17:768, 768:1) = aten::reshape(%2494, %2495), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:350:0
  %attn_output.10 : Float(512:13056, 17:768, 768:1) = aten::contiguous(%2496, %126), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:350:0
  %input.60 : Float(17:768, 512:13056, 768:1) = aten::transpose(%attn_output.10, %126, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_longformer.py:374:0
  %2499 : __torch__.torch.nn.modules.normalization.___torch_mangle_8134.LayerNorm = prim::GetAttr[name="LayerNorm"](%2066)
  %2500 : __torch__.torch.nn.modules.linear.___torch_mangle_8133.Linear = prim::GetAttr[name="dense"](%2066)
  %2501 : Tensor = prim::GetAttr[name="bias"](%2500)
  %2502 : Tensor = prim::GetAttr[name="weight"](%2500)
  %2503 : Float(768:1, 768:768) = aten::t(%2502), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %output.28 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.60, %2503), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %input.61 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.28, %2501, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.54 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.61, %158, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.dropout # torch/nn/functional.py:973:0
  %input.62 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.54, %hidden_states.45, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output # transformers/modeling_longformer.py:758:0
  %2508 : Tensor = prim::GetAttr[name="bias"](%2499)
  %2509 : Tensor = prim::GetAttr[name="weight"](%2499)
  %2510 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.LayerNorm
  %input_tensor.15 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.62, %2510, %2509, %2508, %123, %122), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %2512 : __torch__.torch.nn.modules.linear.___torch_mangle_8138.Linear = prim::GetAttr[name="dense"](%2064)
  %2513 : Tensor = prim::GetAttr[name="bias"](%2512)
  %2514 : Tensor = prim::GetAttr[name="weight"](%2512)
  %2515 : Float(768:1, 3072:768) = aten::t(%2514), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.intermediate/__module.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %output.29 : Float(17:1572864, 512:3072, 3072:1) = aten::matmul(%input_tensor.15, %2515), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.intermediate/__module.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %input.63 : Float(17:1572864, 512:3072, 3072:1) = aten::add_(%output.29, %2513, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.intermediate/__module.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1678:0
  %input.64 : Float(17:1572864, 512:3072, 3072:1) = aten::gelu(%input.63), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.intermediate # torch/nn/functional.py:1369:0
  %2519 : __torch__.torch.nn.modules.normalization.___torch_mangle_8141.LayerNorm = prim::GetAttr[name="LayerNorm"](%2063)
  %2520 : __torch__.torch.nn.modules.linear.___torch_mangle_8140.Linear = prim::GetAttr[name="dense"](%2063)
  %2521 : Tensor = prim::GetAttr[name="bias"](%2520)
  %2522 : Tensor = prim::GetAttr[name="weight"](%2520)
  %2523 : Float(3072:1, 768:3072) = aten::t(%2522), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %output.30 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.64, %2523), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %input.65 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.30, %2521, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.55 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.65, %158, %146), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.dropout # torch/nn/functional.py:973:0
  %input.66 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.55, %input_tensor.15, %125), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output # transformers/modeling_longformer.py:830:0
  %2528 : Tensor = prim::GetAttr[name="bias"](%2519)
  %2529 : Tensor = prim::GetAttr[name="weight"](%2519)
  %2530 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.LayerNorm
  %hidden_states.56 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.66, %2530, %2529, %2528, %123, %122), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.LayerNorm # torch/nn/functional.py:2048:0
  %2532 : __torch__.transformers.modeling_longformer.___torch_mangle_8162.LongformerOutput = prim::GetAttr[name="output"](%176)
  %2533 : __torch__.transformers.modeling_longformer.___torch_mangle_8158.LongformerIntermediate = prim::GetAttr[name="intermediate"](%176)
  %2534 : __torch__.transformers.modeling_longformer.___torch_mangle_8156.LongformerAttention = prim::GetAttr[name="attention"](%176)
  %2535 : __torch__.transformers.modeling_longformer.___torch_mangle_8155.LongformerSelfOutput = prim::GetAttr[name="output"](%2534)
  %2536 : __torch__.transformers.modeling_longformer.___torch_mangle_8151.LongformerSelfAttention = prim::GetAttr[name="self"](%2534)
  %2537 : __torch__.torch.nn.modules.linear.___torch_mangle_8147.Linear = prim::GetAttr[name="value"](%2536)
  %2538 : __torch__.torch.nn.modules.linear.___torch_mangle_8146.Linear = prim::GetAttr[name="key"](%2536)
  %2539 : __torch__.torch.nn.modules.linear.___torch_mangle_8145.Linear = prim::GetAttr[name="query"](%2536)
  %2540 : Float(17:512, 1:512, 512:1) = aten::squeeze(%attention_mask, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:241:0
  %2541 : Float(17:512, 512:1) = aten::squeeze(%2540, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:241:0
  %is_index_masked.6 : Bool(17:512, 512:1) = aten::lt(%2541, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/tensor.py:22:0
  %input.67 : Float(512:768, 17:393216, 768:1) = aten::transpose(%hidden_states.56, %126, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:248:0
  %2544 : Tensor = prim::GetAttr[name="bias"](%2539)
  %2545 : Tensor = prim::GetAttr[name="weight"](%2539)
  %2546 : Float(768:1, 768:768) = aten::t(%2545), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %output.31 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.67, %2546), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %query_vectors.11 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.31, %2544, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.query # torch/nn/functional.py:1678:0
  %2549 : Tensor = prim::GetAttr[name="bias"](%2538)
  %2550 : Tensor = prim::GetAttr[name="weight"](%2538)
  %2551 : Float(768:1, 768:768) = aten::t(%2550), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %output.32 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.67, %2551), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %key_vectors.6 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.32, %2549, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.key # torch/nn/functional.py:1678:0
  %2554 : Tensor = prim::GetAttr[name="bias"](%2537)
  %2555 : Tensor = prim::GetAttr[name="weight"](%2537)
  %2556 : Float(768:1, 768:768) = aten::t(%2555), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %output.33 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.67, %2556), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %value_vectors.6 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.33, %2554, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.value # torch/nn/functional.py:1678:0
  %2559 : int = aten::size(%input.67, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:255:0
  %2560 : int = aten::size(%input.67, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:255:0
  %2561 : int = aten::size(%input.67, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:255:0
  %query_vectors.12 : Float(512:13056, 17:768, 768:1) = aten::div_(%query_vectors.11, %127), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:261:0
  %2563 : int[] = prim::ListConstruct(%2559, %2560, %128, %129), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2564 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%query_vectors.12, %2563), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:263:0
  %query.11 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%2564, %126, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:263:0
  %2566 : int[] = prim::ListConstruct(%2559, %2560, %128, %129), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2567 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%key_vectors.6, %2566), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:264:0
  %key.6 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%2567, %126, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:264:0
  %2569 : int = aten::size(%query.11, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.22 : Long() = prim::NumToTensor(%2569), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2571 : int = aten::size(%query.11, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.23 : Long() = prim::NumToTensor(%2571), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2573 : int = aten::size(%query.11, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.16 : Long() = prim::NumToTensor(%2573), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2575 : int = aten::size(%query.11, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:472:0
  %2576 : Long() = aten::floor_divide(%seq_len.23, %131), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/tensor.py:424:0
  %chunks_count.16 : Long() = aten::sub(%2576, %132, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:478:0
  %2578 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%query.11, %125, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:481:0
  %2579 : Long() = aten::mul(%batch_size.22, %num_heads.16), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:481:0
  %2580 : int = aten::Int(%2579), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2581 : int[] = prim::ListConstruct(%2580, %2571, %2575), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %hidden_states.57 : Float(204:64, 512:13056, 64:1) = aten::reshape(%2578, %2581), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:481:0
  %2583 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%key.6, %125, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:482:0
  %2584 : Long() = aten::mul(%batch_size.22, %num_heads.16), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:482:0
  %2585 : int = aten::Int(%2584), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2586 : int[] = prim::ListConstruct(%2585, %2571, %2575), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %hidden_states.59 : Float(204:64, 512:13056, 64:1) = aten::reshape(%2583, %2586), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:482:0
  %2588 : int = aten::size(%hidden_states.57, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:442:0
  %2589 : int = aten::size(%hidden_states.57, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:443:0
  %2590 : Long() = prim::NumToTensor(%2589), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2591 : Long() = aten::floor_divide(%2590, %133), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/tensor.py:424:0
  %2592 : int = aten::Int(%2591), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2593 : int = aten::size(%hidden_states.57, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:445:0
  %2594 : int[] = prim::ListConstruct(%2588, %2592, %134, %2593), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %hidden_states.58 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.57, %2594), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:441:0
  %2596 : int = aten::size(%hidden_states.58, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2597 : int = aten::size(%hidden_states.58, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2598 : Long() = prim::NumToTensor(%2597), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2599 : int = aten::size(%hidden_states.58, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2600 : int = aten::size(%hidden_states.58, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2601 : Long() = aten::mul(%2598, %135), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:450:0
  %2602 : Long() = aten::sub(%2601, %132, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:450:0
  %2603 : int = aten::Int(%2602), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2604 : int[] = prim::ListConstruct(%2596, %2603, %2599, %2600), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2605 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2606 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.58, %2604, %2605, %138), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:454:0
  %2607 : int = aten::size(%hidden_states.59, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:442:0
  %2608 : int = aten::size(%hidden_states.59, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:443:0
  %2609 : Long() = prim::NumToTensor(%2608), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2610 : Long() = aten::floor_divide(%2609, %133), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/tensor.py:424:0
  %2611 : int = aten::Int(%2610), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2612 : int = aten::size(%hidden_states.59, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:445:0
  %2613 : int[] = prim::ListConstruct(%2607, %2611, %134, %2612), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %hidden_states.60 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.59, %2613), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:441:0
  %2615 : int = aten::size(%hidden_states.60, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2616 : int = aten::size(%hidden_states.60, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2617 : Long() = prim::NumToTensor(%2616), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2618 : int = aten::size(%hidden_states.60, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2619 : int = aten::size(%hidden_states.60, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2620 : Long() = aten::mul(%2617, %135), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:450:0
  %2621 : Long() = aten::sub(%2620, %132, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:450:0
  %2622 : int = aten::Int(%2621), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2623 : int[] = prim::ListConstruct(%2615, %2622, %2618, %2619), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2624 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2625 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.60, %2623, %2624, %138), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:454:0
  %2626 : Tensor[] = prim::ListConstruct(%2606, %2625), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %input.68 : Float(204:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %2626), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/functional.py:327:0
  %2628 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %hidden_states_padded.11 : Float(204:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.68, %2628, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/nn/functional.py:3552:0
  %2630 : int = aten::size(%hidden_states_padded.11, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:401:0
  %2631 : int = aten::size(%hidden_states_padded.11, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:401:0
  %2632 : int = aten::size(%hidden_states_padded.11, %140), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:401:0
  %2633 : int = aten::size(%hidden_states_padded.11, %141), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:401:0
  %2634 : int[] = prim::ListConstruct(%2630, %2631, %2632, %2633), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %diagonal_chunked_attention_scores.11 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.11, %2634), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:400:0
  %2636 : Long() = aten::mul(%batch_size.22, %num_heads.16), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:504:0
  %2637 : int = aten::Int(%2636), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2638 : Long() = aten::add(%chunks_count.16, %132, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:504:0
  %2639 : int = aten::Int(%2638), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2640 : int[] = prim::ListConstruct(%2637, %2639, %142, %143), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %diagonal_attention_scores.11 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.11, %2640, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:503:0
  %2642 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.11, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2643 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%2642, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2644 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%2643, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2645 : Float(204:262656, 1:262656, 256:513, 257:1) = aten::slice(%2644, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2646 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.11, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2647 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%2646, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2648 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%2647, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2649 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::slice(%2648, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2650 : int[] = prim::ListConstruct(%149, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2651 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::view(%2645, %2650), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2652 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::copy_(%2649, %2651, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2653 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.11, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2654 : Float(204:262656, 512:513, 513:1) = aten::select(%2653, %125, %140), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2655 : Float(204:262656, 256:513, 513:1) = aten::slice(%2654, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2656 : Float(204:262656, 256:513, 257:1) = aten::slice(%2655, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2657 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.11, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2658 : Float(204:262656, 256:513, 513:1) = aten::select(%2657, %125, %140), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2659 : Float(204:262656, 256:513, 513:1) = aten::slice(%2658, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2660 : Float(204:262656, 256:513, 257:1) = aten::slice(%2659, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2661 : int[] = prim::ListConstruct(%149, %142, %148), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2662 : Float(204:262656, 256:513, 257:1) = aten::view(%2656, %2661), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2663 : Float(204:262656, 256:513, 257:1) = aten::copy_(%2660, %2662, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2664 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.11, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2665 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%2664, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2666 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%2665, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2667 : Float(204:262656, 1:262656, 256:513, 256:1) = aten::slice(%2666, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2668 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.11, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2669 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%2668, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2670 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%2669, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2671 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::slice(%2670, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2672 : int[] = prim::ListConstruct(%149, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2673 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::view(%2667, %2672), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2674 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::copy_(%2671, %2673, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2675 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.11, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2676 : Float(204:262656, 512:513, 513:1) = aten::select(%2675, %125, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2677 : Float(204:262656, 255:513, 513:1) = aten::slice(%2676, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2678 : Float(204:262656, 255:513, 255:1) = aten::slice(%2677, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2679 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.11, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2680 : Float(204:262656, 256:513, 513:1) = aten::select(%2679, %125, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2681 : Float(204:262656, 255:513, 513:1) = aten::slice(%2680, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2682 : Float(204:262656, 255:513, 255:1) = aten::slice(%2681, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2683 : int[] = prim::ListConstruct(%149, %151, %151), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2684 : Float(204:262656, 255:513, 255:1) = aten::view(%2678, %2683), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2685 : Float(204:262656, 255:513, 255:1) = aten::copy_(%2682, %2684, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2686 : int[] = prim::ListConstruct(%2569, %2573, %2571, %143), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2687 : Float(17:3151872, 12:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.11, %2686), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.16 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::transpose(%2687, %124, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:525:0
  %2689 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2690 : Float(256:257, 257:1) = aten::ones(%2689, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:458:0
  %2691 : Float(256:257, 257:1) = aten::tril(%2690, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:458:0
  %2692 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %beginning_mask_2d.11 : Float(256:257, 257:1) = aten::flip(%2691, %2692), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:458:0
  %2694 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.11, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:459:0
  %2695 : Float(1:65792, 256:257, 257:1) = aten::slice(%2694, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:459:0
  %2696 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%2695, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.11 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%2696, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:459:0
  %2698 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %ending_mask.11 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.11, %2698), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:460:0
  %2700 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.16, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:461:0
  %2701 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%2700, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:461:0
  %2702 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%2701, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.11 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%2702, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:461:0
  %2704 : int = aten::size(%beginning_input.11, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:462:0
  %2705 : int = aten::size(%beginning_input.11, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:462:0
  %2706 : int = aten::size(%beginning_input.11, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:462:0
  %2707 : int = aten::size(%beginning_input.11, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:462:0
  %2708 : int[] = prim::ListConstruct(%2704, %2705, %2706, %2707), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2709 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%beginning_mask.11, %2708, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:462:0
  %2710 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%2709, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/tensor.py:22:0
  %2711 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%beginning_input.11, %2710, %153), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:463:0
  %2712 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.16, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:464:0
  %2713 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%2712, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:464:0
  %2714 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%2713, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.11 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%2714, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:464:0
  %2716 : int = aten::size(%ending_input.11, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:465:0
  %2717 : int = aten::size(%ending_input.11, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:465:0
  %2718 : int = aten::size(%ending_input.11, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:465:0
  %2719 : int = aten::size(%ending_input.11, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:465:0
  %2720 : int[] = prim::ListConstruct(%2716, %2717, %2718, %2719), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2721 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%ending_mask.11, %2720, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:465:0
  %2722 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%2721, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/tensor.py:22:0
  %2723 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%ending_input.11, %2722, %153), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:466:0
  %2724 : Bool(17:512, 512:1) = aten::ne(%2541, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/tensor.py:22:0
  %2725 : Bool(17:512, 512:1) = aten::slice(%2724, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:272:0
  %2726 : Bool(17:512, 512:1) = aten::slice(%2725, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:272:0
  %2727 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%2726, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:272:0
  %remove_from_windowed_attention_mask.6 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%2727, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:272:0
  %2729 : Float(17:512, 512:1, 1:1, 1:1) = aten::type_as(%remove_from_windowed_attention_mask.6, %query.11), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:275:0
  %float_mask.6 : Float(17:512, 512:1, 1:1, 1:1) = aten::masked_fill(%2729, %remove_from_windowed_attention_mask.6, %155), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:275:0
  %2731 : int = aten::size(%float_mask.6, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:280:0
  %2732 : int = aten::size(%float_mask.6, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:280:0
  %2733 : int = aten::size(%float_mask.6, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:280:0
  %2734 : int = aten::size(%float_mask.6, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:280:0
  %2735 : int[] = prim::ListConstruct(%2731, %2732, %2733, %2734), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %query.12 : Float(17:512, 512:1, 1:1, 1:1) = aten::ones(%2735, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:280:0
  %2737 : int = aten::size(%query.12, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.23 : Long() = prim::NumToTensor(%2737), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2739 : int = aten::size(%query.12, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.24 : Long() = prim::NumToTensor(%2739), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2741 : int = aten::size(%query.12, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.17 : Long() = prim::NumToTensor(%2741), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2743 : int = aten::size(%query.12, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:472:0
  %2744 : Long() = aten::floor_divide(%seq_len.24, %131), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/tensor.py:424:0
  %chunks_count.17 : Long() = aten::sub(%2744, %132, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:478:0
  %2746 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%query.12, %125, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:481:0
  %2747 : Long() = aten::mul(%batch_size.23, %num_heads.17), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:481:0
  %2748 : int = aten::Int(%2747), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2749 : int[] = prim::ListConstruct(%2748, %2739, %2743), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %hidden_states.61 : Float(17:512, 512:1, 1:1) = aten::reshape(%2746, %2749), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:481:0
  %2751 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%float_mask.6, %125, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:482:0
  %2752 : Long() = aten::mul(%batch_size.23, %num_heads.17), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:482:0
  %2753 : int = aten::Int(%2752), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2754 : int[] = prim::ListConstruct(%2753, %2739, %2743), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %hidden_states.63 : Float(17:512, 512:1, 1:1) = aten::reshape(%2751, %2754), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:482:0
  %2756 : int = aten::size(%hidden_states.61, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:442:0
  %2757 : int = aten::size(%hidden_states.61, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:443:0
  %2758 : Long() = prim::NumToTensor(%2757), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2759 : Long() = aten::floor_divide(%2758, %133), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/tensor.py:424:0
  %2760 : int = aten::Int(%2759), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2761 : int = aten::size(%hidden_states.61, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:445:0
  %2762 : int[] = prim::ListConstruct(%2756, %2760, %134, %2761), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %hidden_states.62 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.61, %2762), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:441:0
  %2764 : int = aten::size(%hidden_states.62, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2765 : int = aten::size(%hidden_states.62, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2766 : Long() = prim::NumToTensor(%2765), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2767 : int = aten::size(%hidden_states.62, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2768 : int = aten::size(%hidden_states.62, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2769 : Long() = aten::mul(%2766, %135), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:450:0
  %2770 : Long() = aten::sub(%2769, %132, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:450:0
  %2771 : int = aten::Int(%2770), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2772 : int[] = prim::ListConstruct(%2764, %2771, %2767, %2768), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2773 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2774 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.62, %2772, %2773, %138), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:454:0
  %2775 : int = aten::size(%hidden_states.63, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:442:0
  %2776 : int = aten::size(%hidden_states.63, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:443:0
  %2777 : Long() = prim::NumToTensor(%2776), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2778 : Long() = aten::floor_divide(%2777, %133), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/tensor.py:424:0
  %2779 : int = aten::Int(%2778), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2780 : int = aten::size(%hidden_states.63, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:445:0
  %2781 : int[] = prim::ListConstruct(%2775, %2779, %134, %2780), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %hidden_states.64 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.63, %2781), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:441:0
  %2783 : int = aten::size(%hidden_states.64, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2784 : int = aten::size(%hidden_states.64, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2785 : Long() = prim::NumToTensor(%2784), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2786 : int = aten::size(%hidden_states.64, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2787 : int = aten::size(%hidden_states.64, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:449:0
  %2788 : Long() = aten::mul(%2785, %135), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:450:0
  %2789 : Long() = aten::sub(%2788, %132, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:450:0
  %2790 : int = aten::Int(%2789), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2791 : int[] = prim::ListConstruct(%2783, %2790, %2786, %2787), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2792 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2793 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.64, %2791, %2792, %138), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:454:0
  %2794 : Tensor[] = prim::ListConstruct(%2774, %2793), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %input.69 : Float(17:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %2794), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/functional.py:327:0
  %2796 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %hidden_states_padded.12 : Float(17:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.69, %2796, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/nn/functional.py:3552:0
  %2798 : int = aten::size(%hidden_states_padded.12, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:401:0
  %2799 : int = aten::size(%hidden_states_padded.12, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:401:0
  %2800 : int = aten::size(%hidden_states_padded.12, %140), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:401:0
  %2801 : int = aten::size(%hidden_states_padded.12, %141), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:401:0
  %2802 : int[] = prim::ListConstruct(%2798, %2799, %2800, %2801), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %diagonal_chunked_attention_scores.12 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.12, %2802), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:400:0
  %2804 : Long() = aten::mul(%batch_size.23, %num_heads.17), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:504:0
  %2805 : int = aten::Int(%2804), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2806 : Long() = aten::add(%chunks_count.17, %132, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:504:0
  %2807 : int = aten::Int(%2806), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2808 : int[] = prim::ListConstruct(%2805, %2807, %142, %143), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %diagonal_attention_scores.12 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.12, %2808, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:503:0
  %2810 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.12, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2811 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%2810, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2812 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%2811, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2813 : Float(17:262656, 1:262656, 256:513, 257:1) = aten::slice(%2812, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2814 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.12, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2815 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%2814, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2816 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%2815, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2817 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::slice(%2816, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2818 : int[] = prim::ListConstruct(%156, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2819 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::view(%2813, %2818), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2820 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::copy_(%2817, %2819, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:509:0
  %2821 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.12, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2822 : Float(17:262656, 512:513, 513:1) = aten::select(%2821, %125, %140), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2823 : Float(17:262656, 256:513, 513:1) = aten::slice(%2822, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2824 : Float(17:262656, 256:513, 257:1) = aten::slice(%2823, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2825 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.12, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2826 : Float(17:262656, 256:513, 513:1) = aten::select(%2825, %125, %140), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2827 : Float(17:262656, 256:513, 513:1) = aten::slice(%2826, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2828 : Float(17:262656, 256:513, 257:1) = aten::slice(%2827, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2829 : int[] = prim::ListConstruct(%156, %142, %148), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2830 : Float(17:262656, 256:513, 257:1) = aten::view(%2824, %2829), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2831 : Float(17:262656, 256:513, 257:1) = aten::copy_(%2828, %2830, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:512:0
  %2832 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.12, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2833 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%2832, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2834 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%2833, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2835 : Float(17:262656, 1:262656, 256:513, 256:1) = aten::slice(%2834, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2836 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.12, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2837 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%2836, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2838 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%2837, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2839 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::slice(%2838, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2840 : int[] = prim::ListConstruct(%156, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2841 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::view(%2835, %2840), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2842 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::copy_(%2839, %2841, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:516:0
  %2843 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.12, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2844 : Float(17:262656, 512:513, 513:1) = aten::select(%2843, %125, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2845 : Float(17:262656, 255:513, 513:1) = aten::slice(%2844, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2846 : Float(17:262656, 255:513, 255:1) = aten::slice(%2845, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2847 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.12, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2848 : Float(17:262656, 256:513, 513:1) = aten::select(%2847, %125, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2849 : Float(17:262656, 255:513, 513:1) = aten::slice(%2848, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2850 : Float(17:262656, 255:513, 255:1) = aten::slice(%2849, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2851 : int[] = prim::ListConstruct(%156, %151, %151), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2852 : Float(17:262656, 255:513, 255:1) = aten::view(%2846, %2851), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2853 : Float(17:262656, 255:513, 255:1) = aten::copy_(%2850, %2852, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:520:0
  %2854 : int[] = prim::ListConstruct(%2737, %2741, %2739, %143), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2855 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.12, %2854), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.17 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::transpose(%2855, %124, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:525:0
  %2857 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2858 : Float(256:257, 257:1) = aten::ones(%2857, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:458:0
  %2859 : Float(256:257, 257:1) = aten::tril(%2858, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:458:0
  %2860 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %beginning_mask_2d.12 : Float(256:257, 257:1) = aten::flip(%2859, %2860), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:458:0
  %2862 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.12, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:459:0
  %2863 : Float(1:65792, 256:257, 257:1) = aten::slice(%2862, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:459:0
  %2864 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%2863, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.12 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%2864, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:459:0
  %2866 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %ending_mask.12 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.12, %2866), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:460:0
  %2868 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.17, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:461:0
  %2869 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%2868, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:461:0
  %2870 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%2869, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.12 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%2870, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:461:0
  %2872 : int = aten::size(%beginning_input.12, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:462:0
  %2873 : int = aten::size(%beginning_input.12, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:462:0
  %2874 : int = aten::size(%beginning_input.12, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:462:0
  %2875 : int = aten::size(%beginning_input.12, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:462:0
  %2876 : int[] = prim::ListConstruct(%2872, %2873, %2874, %2875), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2877 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%beginning_mask.12, %2876, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:462:0
  %2878 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%2877, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/tensor.py:22:0
  %2879 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%beginning_input.12, %2878, %153), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:463:0
  %2880 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.17, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:464:0
  %2881 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%2880, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:464:0
  %2882 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%2881, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.12 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%2882, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:464:0
  %2884 : int = aten::size(%ending_input.12, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:465:0
  %2885 : int = aten::size(%ending_input.12, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:465:0
  %2886 : int = aten::size(%ending_input.12, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:465:0
  %2887 : int = aten::size(%ending_input.12, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:465:0
  %2888 : int[] = prim::ListConstruct(%2884, %2885, %2886, %2887), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2889 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%ending_mask.12, %2888, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:465:0
  %2890 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%2889, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/tensor.py:22:0
  %2891 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%ending_input.12, %2890, %153), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:466:0
  %attn_scores.6 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::add_(%input_tensor.16, %input_tensor.17, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:284:0
  %attn_probs_fp32.6 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::softmax(%attn_scores.6, %140, %144), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/nn/functional.py:1500:0
  %2894 : Bool(17:512, 512:1) = aten::slice(%is_index_masked.6, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:326:0
  %2895 : Bool(17:512, 512:1) = aten::slice(%2894, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:326:0
  %2896 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%2895, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:326:0
  %2897 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%2896, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:326:0
  %input.70 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::masked_fill(%attn_probs_fp32.6, %2897, %157), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:326:0
  %attn_probs.12 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::dropout(%input.70, %158, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/nn/functional.py:973:0
  %2900 : int[] = prim::ListConstruct(%2559, %2560, %128, %129), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2901 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%value_vectors.6, %2900), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:331:0
  %value.6 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%2901, %126, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:331:0
  %2903 : int = aten::size(%value.6, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:537:0
  %batch_size.24 : Long() = prim::NumToTensor(%2903), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2905 : int = aten::size(%value.6, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:537:0
  %seq_len.25 : Long() = prim::NumToTensor(%2905), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2907 : int = aten::size(%value.6, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:537:0
  %num_heads.18 : Long() = prim::NumToTensor(%2907), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2909 : int = aten::size(%value.6, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:537:0
  %2910 : Long() = aten::floor_divide(%seq_len.25, %131), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/tensor.py:424:0
  %chunks_count.18 : Long() = aten::sub(%2910, %132, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:542:0
  %2912 : Float(17:3151872, 12:513, 512:6156, 513:1) = aten::transpose(%attn_probs.12, %125, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:545:0
  %2913 : Long() = aten::mul(%batch_size.24, %num_heads.18), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:546:0
  %2914 : int = aten::Int(%2913), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2915 : Long() = aten::floor_divide(%seq_len.25, %131), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/tensor.py:424:0
  %2916 : int = aten::Int(%2915), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2917 : int[] = prim::ListConstruct(%2914, %2916, %142, %143), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %chunked_hidden_states.26 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::reshape(%2912, %2917), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:545:0
  %2919 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%value.6, %125, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:550:0
  %2920 : Long() = aten::mul(%batch_size.24, %num_heads.18), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:550:0
  %2921 : int = aten::Int(%2920), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2922 : int[] = prim::ListConstruct(%2921, %2905, %2909), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %input.71 : Float(204:64, 512:13056, 64:1) = aten::reshape(%2919, %2922), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:550:0
  %2924 : int[] = prim::ListConstruct(%126, %126, %142, %142), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %padded_value.6 : Float(204:65536, 1024:64, 64:1) = aten::constant_pad_nd(%input.71, %2924, %140), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/nn/functional.py:3552:0
  %2926 : Long() = aten::mul(%batch_size.24, %num_heads.18), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:556:0
  %2927 : int = aten::Int(%2926), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2928 : Long() = aten::add(%chunks_count.18, %132, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:556:0
  %2929 : int = aten::Int(%2928), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2930 : int[] = prim::ListConstruct(%2927, %2929, %159, %2909), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2931 : int[] = prim::ListConstruct(%160, %161, %129, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2932 : Float(204:65536, 2:16384, 768:64, 64:1) = aten::as_strided(%padded_value.6, %2930, %2931, %138), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:564:0
  %2933 : int = aten::size(%chunked_hidden_states.26, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:420:0
  %2934 : int = aten::size(%chunked_hidden_states.26, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:420:0
  %2935 : int = aten::size(%chunked_hidden_states.26, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:420:0
  %window_overlap.6 : Long() = prim::NumToTensor(%2935), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2937 : int = aten::size(%chunked_hidden_states.26, %130), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:420:0
  %hidden_dim.6 : Long() = prim::NumToTensor(%2937), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2939 : Long() = aten::add(%window_overlap.6, %132, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:422:0
  %2940 : int = aten::Int(%2939), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2941 : int[] = prim::ListConstruct(%126, %2940), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %chunked_hidden_states.27 : Float(204:394240, 2:197120, 256:770, 770:1) = aten::constant_pad_nd(%chunked_hidden_states.26, %2941, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/nn/functional.py:3552:0
  %2943 : int[] = prim::ListConstruct(%2933, %2934, %140), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %chunked_hidden_states.28 : Float(204:394240, 2:197120, 197120:1) = aten::view(%chunked_hidden_states.27, %2943), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:424:0
  %2945 : Long() = aten::neg(%window_overlap.6), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:428:0
  %2946 : int = aten::Int(%2945), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2947 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%chunked_hidden_states.28, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:427:0
  %2948 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%2947, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:427:0
  %chunked_hidden_states.29 : Float(204:394240, 2:197120, 196864:1) = aten::slice(%2948, %124, %126, %2946, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:427:0
  %2950 : Long() = aten::add(%window_overlap.6, %hidden_dim.6, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:431:0
  %2951 : int = aten::Int(%2950), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2952 : int[] = prim::ListConstruct(%2933, %2934, %2935, %2951), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %chunked_hidden_states.30 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::view(%chunked_hidden_states.29, %2952), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:430:0
  %2954 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%chunked_hidden_states.30, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:433:0
  %2955 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%2954, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:433:0
  %2956 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%2955, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:433:0
  %2957 : Float(204:394240, 2:197120, 256:769, 768:1) = aten::slice(%2956, %130, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:433:0
  %2958 : Tensor[] = prim::ListConstruct(%2957, %2932), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %context.6 : Float(204:32768, 2:16384, 256:64, 64:1) = aten::einsum(%162, %2958), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/functional.py:327:0
  %2960 : int[] = prim::ListConstruct(%2903, %2907, %2905, %2909), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2961 : Float(17:393216, 12:32768, 512:64, 64:1) = aten::view(%context.6, %2960), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:569:0
  %attn_output.11 : Float(17:393216, 512:64, 12:32768, 64:1) = aten::transpose(%2961, %125, %124), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:569:0
  %2963 : Float(512:64, 17:393216, 12:32768, 64:1) = aten::transpose(%attn_output.11, %126, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:350:0
  %2964 : int[] = prim::ListConstruct(%2559, %2560, %2561), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %2965 : Float(512:13056, 17:768, 768:1) = aten::reshape(%2963, %2964), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:350:0
  %attn_output.12 : Float(512:13056, 17:768, 768:1) = aten::contiguous(%2965, %126), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:350:0
  %input.72 : Float(17:768, 512:13056, 768:1) = aten::transpose(%attn_output.12, %126, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_longformer.py:374:0
  %2968 : __torch__.torch.nn.modules.normalization.___torch_mangle_8153.LayerNorm = prim::GetAttr[name="LayerNorm"](%2535)
  %2969 : __torch__.torch.nn.modules.linear.___torch_mangle_8152.Linear = prim::GetAttr[name="dense"](%2535)
  %2970 : Tensor = prim::GetAttr[name="bias"](%2969)
  %2971 : Tensor = prim::GetAttr[name="weight"](%2969)
  %2972 : Float(768:1, 768:768) = aten::t(%2971), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %output.34 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.72, %2972), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %input.73 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.34, %2970, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.65 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.73, %158, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.dropout # torch/nn/functional.py:973:0
  %input.74 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.65, %hidden_states.56, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output # transformers/modeling_longformer.py:758:0
  %2977 : Tensor = prim::GetAttr[name="bias"](%2968)
  %2978 : Tensor = prim::GetAttr[name="weight"](%2968)
  %2979 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.LayerNorm
  %input_tensor.18 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.74, %2979, %2978, %2977, %123, %122), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %2981 : __torch__.torch.nn.modules.linear.___torch_mangle_8157.Linear = prim::GetAttr[name="dense"](%2533)
  %2982 : Tensor = prim::GetAttr[name="bias"](%2981)
  %2983 : Tensor = prim::GetAttr[name="weight"](%2981)
  %2984 : Float(768:1, 3072:768) = aten::t(%2983), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.intermediate/__module.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %output.35 : Float(17:1572864, 512:3072, 3072:1) = aten::matmul(%input_tensor.18, %2984), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.intermediate/__module.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %input.75 : Float(17:1572864, 512:3072, 3072:1) = aten::add_(%output.35, %2982, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.intermediate/__module.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1678:0
  %input.76 : Float(17:1572864, 512:3072, 3072:1) = aten::gelu(%input.75), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.intermediate # torch/nn/functional.py:1369:0
  %2988 : __torch__.torch.nn.modules.normalization.___torch_mangle_8160.LayerNorm = prim::GetAttr[name="LayerNorm"](%2532)
  %2989 : __torch__.torch.nn.modules.linear.___torch_mangle_8159.Linear = prim::GetAttr[name="dense"](%2532)
  %2990 : Tensor = prim::GetAttr[name="bias"](%2989)
  %2991 : Tensor = prim::GetAttr[name="weight"](%2989)
  %2992 : Float(3072:1, 768:3072) = aten::t(%2991), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %output.36 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.76, %2992), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %input.77 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.36, %2990, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.66 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.77, %158, %146), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.dropout # torch/nn/functional.py:973:0
  %input.78 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.66, %input_tensor.18, %125), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output # transformers/modeling_longformer.py:830:0
  %2997 : Tensor = prim::GetAttr[name="bias"](%2988)
  %2998 : Tensor = prim::GetAttr[name="weight"](%2988)
  %2999 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.LayerNorm
  %hidden_states.67 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.78, %2999, %2998, %2997, %123, %122), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.LayerNorm # torch/nn/functional.py:2048:0
  %3001 : __torch__.transformers.modeling_longformer.___torch_mangle_8181.LongformerOutput = prim::GetAttr[name="output"](%174)
  %3002 : __torch__.transformers.modeling_longformer.___torch_mangle_8177.LongformerIntermediate = prim::GetAttr[name="intermediate"](%174)
  %3003 : __torch__.transformers.modeling_longformer.___torch_mangle_8175.LongformerAttention = prim::GetAttr[name="attention"](%174)
  %3004 : __torch__.transformers.modeling_longformer.___torch_mangle_8174.LongformerSelfOutput = prim::GetAttr[name="output"](%3003)
  %3005 : __torch__.transformers.modeling_longformer.___torch_mangle_8170.LongformerSelfAttention = prim::GetAttr[name="self"](%3003)
  %3006 : __torch__.torch.nn.modules.linear.___torch_mangle_8166.Linear = prim::GetAttr[name="value"](%3005)
  %3007 : __torch__.torch.nn.modules.linear.___torch_mangle_8165.Linear = prim::GetAttr[name="key"](%3005)
  %3008 : __torch__.torch.nn.modules.linear.___torch_mangle_8164.Linear = prim::GetAttr[name="query"](%3005)
  %3009 : Float(17:512, 1:512, 512:1) = aten::squeeze(%attention_mask, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:241:0
  %3010 : Float(17:512, 512:1) = aten::squeeze(%3009, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:241:0
  %is_index_masked.7 : Bool(17:512, 512:1) = aten::lt(%3010, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/tensor.py:22:0
  %input.79 : Float(512:768, 17:393216, 768:1) = aten::transpose(%hidden_states.67, %126, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:248:0
  %3013 : Tensor = prim::GetAttr[name="bias"](%3008)
  %3014 : Tensor = prim::GetAttr[name="weight"](%3008)
  %3015 : Float(768:1, 768:768) = aten::t(%3014), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %output.37 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.79, %3015), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %query_vectors.13 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.37, %3013, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.query # torch/nn/functional.py:1678:0
  %3018 : Tensor = prim::GetAttr[name="bias"](%3007)
  %3019 : Tensor = prim::GetAttr[name="weight"](%3007)
  %3020 : Float(768:1, 768:768) = aten::t(%3019), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %output.38 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.79, %3020), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %key_vectors.7 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.38, %3018, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.key # torch/nn/functional.py:1678:0
  %3023 : Tensor = prim::GetAttr[name="bias"](%3006)
  %3024 : Tensor = prim::GetAttr[name="weight"](%3006)
  %3025 : Float(768:1, 768:768) = aten::t(%3024), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %output.39 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.79, %3025), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %value_vectors.7 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.39, %3023, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.value # torch/nn/functional.py:1678:0
  %3028 : int = aten::size(%input.79, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:255:0
  %3029 : int = aten::size(%input.79, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:255:0
  %3030 : int = aten::size(%input.79, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:255:0
  %query_vectors.14 : Float(512:13056, 17:768, 768:1) = aten::div_(%query_vectors.13, %127), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:261:0
  %3032 : int[] = prim::ListConstruct(%3028, %3029, %128, %129), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3033 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%query_vectors.14, %3032), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:263:0
  %query.13 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%3033, %126, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:263:0
  %3035 : int[] = prim::ListConstruct(%3028, %3029, %128, %129), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3036 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%key_vectors.7, %3035), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:264:0
  %key.7 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%3036, %126, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:264:0
  %3038 : int = aten::size(%query.13, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.26 : Long() = prim::NumToTensor(%3038), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3040 : int = aten::size(%query.13, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.27 : Long() = prim::NumToTensor(%3040), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3042 : int = aten::size(%query.13, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.19 : Long() = prim::NumToTensor(%3042), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3044 : int = aten::size(%query.13, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:472:0
  %3045 : Long() = aten::floor_divide(%seq_len.27, %131), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/tensor.py:424:0
  %chunks_count.19 : Long() = aten::sub(%3045, %132, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:478:0
  %3047 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%query.13, %125, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:481:0
  %3048 : Long() = aten::mul(%batch_size.26, %num_heads.19), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:481:0
  %3049 : int = aten::Int(%3048), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3050 : int[] = prim::ListConstruct(%3049, %3040, %3044), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %hidden_states.68 : Float(204:64, 512:13056, 64:1) = aten::reshape(%3047, %3050), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:481:0
  %3052 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%key.7, %125, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:482:0
  %3053 : Long() = aten::mul(%batch_size.26, %num_heads.19), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:482:0
  %3054 : int = aten::Int(%3053), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3055 : int[] = prim::ListConstruct(%3054, %3040, %3044), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %hidden_states.70 : Float(204:64, 512:13056, 64:1) = aten::reshape(%3052, %3055), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:482:0
  %3057 : int = aten::size(%hidden_states.68, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:442:0
  %3058 : int = aten::size(%hidden_states.68, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:443:0
  %3059 : Long() = prim::NumToTensor(%3058), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3060 : Long() = aten::floor_divide(%3059, %133), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/tensor.py:424:0
  %3061 : int = aten::Int(%3060), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3062 : int = aten::size(%hidden_states.68, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:445:0
  %3063 : int[] = prim::ListConstruct(%3057, %3061, %134, %3062), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %hidden_states.69 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.68, %3063), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:441:0
  %3065 : int = aten::size(%hidden_states.69, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3066 : int = aten::size(%hidden_states.69, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3067 : Long() = prim::NumToTensor(%3066), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3068 : int = aten::size(%hidden_states.69, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3069 : int = aten::size(%hidden_states.69, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3070 : Long() = aten::mul(%3067, %135), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:450:0
  %3071 : Long() = aten::sub(%3070, %132, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:450:0
  %3072 : int = aten::Int(%3071), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3073 : int[] = prim::ListConstruct(%3065, %3072, %3068, %3069), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3074 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3075 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.69, %3073, %3074, %138), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:454:0
  %3076 : int = aten::size(%hidden_states.70, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:442:0
  %3077 : int = aten::size(%hidden_states.70, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:443:0
  %3078 : Long() = prim::NumToTensor(%3077), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3079 : Long() = aten::floor_divide(%3078, %133), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/tensor.py:424:0
  %3080 : int = aten::Int(%3079), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3081 : int = aten::size(%hidden_states.70, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:445:0
  %3082 : int[] = prim::ListConstruct(%3076, %3080, %134, %3081), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %hidden_states.71 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.70, %3082), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:441:0
  %3084 : int = aten::size(%hidden_states.71, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3085 : int = aten::size(%hidden_states.71, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3086 : Long() = prim::NumToTensor(%3085), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3087 : int = aten::size(%hidden_states.71, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3088 : int = aten::size(%hidden_states.71, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3089 : Long() = aten::mul(%3086, %135), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:450:0
  %3090 : Long() = aten::sub(%3089, %132, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:450:0
  %3091 : int = aten::Int(%3090), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3092 : int[] = prim::ListConstruct(%3084, %3091, %3087, %3088), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3093 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3094 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.71, %3092, %3093, %138), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:454:0
  %3095 : Tensor[] = prim::ListConstruct(%3075, %3094), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %input.80 : Float(204:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %3095), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/functional.py:327:0
  %3097 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %hidden_states_padded.13 : Float(204:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.80, %3097, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/nn/functional.py:3552:0
  %3099 : int = aten::size(%hidden_states_padded.13, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:401:0
  %3100 : int = aten::size(%hidden_states_padded.13, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:401:0
  %3101 : int = aten::size(%hidden_states_padded.13, %140), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:401:0
  %3102 : int = aten::size(%hidden_states_padded.13, %141), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:401:0
  %3103 : int[] = prim::ListConstruct(%3099, %3100, %3101, %3102), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %diagonal_chunked_attention_scores.13 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.13, %3103), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:400:0
  %3105 : Long() = aten::mul(%batch_size.26, %num_heads.19), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:504:0
  %3106 : int = aten::Int(%3105), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3107 : Long() = aten::add(%chunks_count.19, %132, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:504:0
  %3108 : int = aten::Int(%3107), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3109 : int[] = prim::ListConstruct(%3106, %3108, %142, %143), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %diagonal_attention_scores.13 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.13, %3109, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:503:0
  %3111 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.13, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3112 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%3111, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3113 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%3112, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3114 : Float(204:262656, 1:262656, 256:513, 257:1) = aten::slice(%3113, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3115 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.13, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3116 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%3115, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3117 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%3116, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3118 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::slice(%3117, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3119 : int[] = prim::ListConstruct(%149, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3120 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::view(%3114, %3119), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3121 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::copy_(%3118, %3120, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3122 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.13, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3123 : Float(204:262656, 512:513, 513:1) = aten::select(%3122, %125, %140), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3124 : Float(204:262656, 256:513, 513:1) = aten::slice(%3123, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3125 : Float(204:262656, 256:513, 257:1) = aten::slice(%3124, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3126 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.13, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3127 : Float(204:262656, 256:513, 513:1) = aten::select(%3126, %125, %140), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3128 : Float(204:262656, 256:513, 513:1) = aten::slice(%3127, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3129 : Float(204:262656, 256:513, 257:1) = aten::slice(%3128, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3130 : int[] = prim::ListConstruct(%149, %142, %148), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3131 : Float(204:262656, 256:513, 257:1) = aten::view(%3125, %3130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3132 : Float(204:262656, 256:513, 257:1) = aten::copy_(%3129, %3131, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3133 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.13, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3134 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%3133, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3135 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%3134, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3136 : Float(204:262656, 1:262656, 256:513, 256:1) = aten::slice(%3135, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3137 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.13, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3138 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%3137, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3139 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%3138, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3140 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::slice(%3139, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3141 : int[] = prim::ListConstruct(%149, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3142 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::view(%3136, %3141), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3143 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::copy_(%3140, %3142, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3144 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.13, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3145 : Float(204:262656, 512:513, 513:1) = aten::select(%3144, %125, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3146 : Float(204:262656, 255:513, 513:1) = aten::slice(%3145, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3147 : Float(204:262656, 255:513, 255:1) = aten::slice(%3146, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3148 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.13, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3149 : Float(204:262656, 256:513, 513:1) = aten::select(%3148, %125, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3150 : Float(204:262656, 255:513, 513:1) = aten::slice(%3149, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3151 : Float(204:262656, 255:513, 255:1) = aten::slice(%3150, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3152 : int[] = prim::ListConstruct(%149, %151, %151), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3153 : Float(204:262656, 255:513, 255:1) = aten::view(%3147, %3152), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3154 : Float(204:262656, 255:513, 255:1) = aten::copy_(%3151, %3153, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3155 : int[] = prim::ListConstruct(%3038, %3042, %3040, %143), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3156 : Float(17:3151872, 12:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.13, %3155), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.19 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::transpose(%3156, %124, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:525:0
  %3158 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3159 : Float(256:257, 257:1) = aten::ones(%3158, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:458:0
  %3160 : Float(256:257, 257:1) = aten::tril(%3159, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:458:0
  %3161 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %beginning_mask_2d.13 : Float(256:257, 257:1) = aten::flip(%3160, %3161), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:458:0
  %3163 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.13, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:459:0
  %3164 : Float(1:65792, 256:257, 257:1) = aten::slice(%3163, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:459:0
  %3165 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%3164, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.13 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%3165, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:459:0
  %3167 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %ending_mask.13 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.13, %3167), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:460:0
  %3169 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.19, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:461:0
  %3170 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%3169, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:461:0
  %3171 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%3170, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.13 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%3171, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:461:0
  %3173 : int = aten::size(%beginning_input.13, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:462:0
  %3174 : int = aten::size(%beginning_input.13, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:462:0
  %3175 : int = aten::size(%beginning_input.13, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:462:0
  %3176 : int = aten::size(%beginning_input.13, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:462:0
  %3177 : int[] = prim::ListConstruct(%3173, %3174, %3175, %3176), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3178 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%beginning_mask.13, %3177, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:462:0
  %3179 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%3178, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/tensor.py:22:0
  %3180 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%beginning_input.13, %3179, %153), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:463:0
  %3181 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.19, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:464:0
  %3182 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%3181, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:464:0
  %3183 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%3182, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.13 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%3183, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:464:0
  %3185 : int = aten::size(%ending_input.13, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:465:0
  %3186 : int = aten::size(%ending_input.13, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:465:0
  %3187 : int = aten::size(%ending_input.13, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:465:0
  %3188 : int = aten::size(%ending_input.13, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:465:0
  %3189 : int[] = prim::ListConstruct(%3185, %3186, %3187, %3188), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3190 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%ending_mask.13, %3189, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:465:0
  %3191 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%3190, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/tensor.py:22:0
  %3192 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%ending_input.13, %3191, %153), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:466:0
  %3193 : Bool(17:512, 512:1) = aten::ne(%3010, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/tensor.py:22:0
  %3194 : Bool(17:512, 512:1) = aten::slice(%3193, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:272:0
  %3195 : Bool(17:512, 512:1) = aten::slice(%3194, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:272:0
  %3196 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%3195, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:272:0
  %remove_from_windowed_attention_mask.7 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%3196, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:272:0
  %3198 : Float(17:512, 512:1, 1:1, 1:1) = aten::type_as(%remove_from_windowed_attention_mask.7, %query.13), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:275:0
  %float_mask.7 : Float(17:512, 512:1, 1:1, 1:1) = aten::masked_fill(%3198, %remove_from_windowed_attention_mask.7, %155), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:275:0
  %3200 : int = aten::size(%float_mask.7, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:280:0
  %3201 : int = aten::size(%float_mask.7, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:280:0
  %3202 : int = aten::size(%float_mask.7, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:280:0
  %3203 : int = aten::size(%float_mask.7, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:280:0
  %3204 : int[] = prim::ListConstruct(%3200, %3201, %3202, %3203), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %query.14 : Float(17:512, 512:1, 1:1, 1:1) = aten::ones(%3204, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:280:0
  %3206 : int = aten::size(%query.14, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.27 : Long() = prim::NumToTensor(%3206), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3208 : int = aten::size(%query.14, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.28 : Long() = prim::NumToTensor(%3208), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3210 : int = aten::size(%query.14, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.20 : Long() = prim::NumToTensor(%3210), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3212 : int = aten::size(%query.14, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:472:0
  %3213 : Long() = aten::floor_divide(%seq_len.28, %131), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/tensor.py:424:0
  %chunks_count.20 : Long() = aten::sub(%3213, %132, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:478:0
  %3215 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%query.14, %125, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:481:0
  %3216 : Long() = aten::mul(%batch_size.27, %num_heads.20), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:481:0
  %3217 : int = aten::Int(%3216), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3218 : int[] = prim::ListConstruct(%3217, %3208, %3212), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %hidden_states.72 : Float(17:512, 512:1, 1:1) = aten::reshape(%3215, %3218), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:481:0
  %3220 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%float_mask.7, %125, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:482:0
  %3221 : Long() = aten::mul(%batch_size.27, %num_heads.20), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:482:0
  %3222 : int = aten::Int(%3221), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3223 : int[] = prim::ListConstruct(%3222, %3208, %3212), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %hidden_states.74 : Float(17:512, 512:1, 1:1) = aten::reshape(%3220, %3223), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:482:0
  %3225 : int = aten::size(%hidden_states.72, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:442:0
  %3226 : int = aten::size(%hidden_states.72, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:443:0
  %3227 : Long() = prim::NumToTensor(%3226), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3228 : Long() = aten::floor_divide(%3227, %133), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/tensor.py:424:0
  %3229 : int = aten::Int(%3228), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3230 : int = aten::size(%hidden_states.72, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:445:0
  %3231 : int[] = prim::ListConstruct(%3225, %3229, %134, %3230), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %hidden_states.73 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.72, %3231), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:441:0
  %3233 : int = aten::size(%hidden_states.73, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3234 : int = aten::size(%hidden_states.73, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3235 : Long() = prim::NumToTensor(%3234), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3236 : int = aten::size(%hidden_states.73, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3237 : int = aten::size(%hidden_states.73, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3238 : Long() = aten::mul(%3235, %135), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:450:0
  %3239 : Long() = aten::sub(%3238, %132, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:450:0
  %3240 : int = aten::Int(%3239), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3241 : int[] = prim::ListConstruct(%3233, %3240, %3236, %3237), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3242 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3243 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.73, %3241, %3242, %138), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:454:0
  %3244 : int = aten::size(%hidden_states.74, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:442:0
  %3245 : int = aten::size(%hidden_states.74, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:443:0
  %3246 : Long() = prim::NumToTensor(%3245), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3247 : Long() = aten::floor_divide(%3246, %133), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/tensor.py:424:0
  %3248 : int = aten::Int(%3247), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3249 : int = aten::size(%hidden_states.74, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:445:0
  %3250 : int[] = prim::ListConstruct(%3244, %3248, %134, %3249), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %hidden_states.75 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.74, %3250), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:441:0
  %3252 : int = aten::size(%hidden_states.75, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3253 : int = aten::size(%hidden_states.75, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3254 : Long() = prim::NumToTensor(%3253), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3255 : int = aten::size(%hidden_states.75, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3256 : int = aten::size(%hidden_states.75, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:449:0
  %3257 : Long() = aten::mul(%3254, %135), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:450:0
  %3258 : Long() = aten::sub(%3257, %132, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:450:0
  %3259 : int = aten::Int(%3258), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3260 : int[] = prim::ListConstruct(%3252, %3259, %3255, %3256), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3261 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3262 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.75, %3260, %3261, %138), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:454:0
  %3263 : Tensor[] = prim::ListConstruct(%3243, %3262), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %input.81 : Float(17:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %3263), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/functional.py:327:0
  %3265 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %hidden_states_padded.14 : Float(17:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.81, %3265, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/nn/functional.py:3552:0
  %3267 : int = aten::size(%hidden_states_padded.14, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:401:0
  %3268 : int = aten::size(%hidden_states_padded.14, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:401:0
  %3269 : int = aten::size(%hidden_states_padded.14, %140), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:401:0
  %3270 : int = aten::size(%hidden_states_padded.14, %141), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:401:0
  %3271 : int[] = prim::ListConstruct(%3267, %3268, %3269, %3270), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %diagonal_chunked_attention_scores.14 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.14, %3271), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:400:0
  %3273 : Long() = aten::mul(%batch_size.27, %num_heads.20), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:504:0
  %3274 : int = aten::Int(%3273), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3275 : Long() = aten::add(%chunks_count.20, %132, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:504:0
  %3276 : int = aten::Int(%3275), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3277 : int[] = prim::ListConstruct(%3274, %3276, %142, %143), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %diagonal_attention_scores.14 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.14, %3277, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:503:0
  %3279 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.14, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3280 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%3279, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3281 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%3280, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3282 : Float(17:262656, 1:262656, 256:513, 257:1) = aten::slice(%3281, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3283 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.14, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3284 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%3283, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3285 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%3284, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3286 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::slice(%3285, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3287 : int[] = prim::ListConstruct(%156, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3288 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::view(%3282, %3287), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3289 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::copy_(%3286, %3288, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:509:0
  %3290 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.14, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3291 : Float(17:262656, 512:513, 513:1) = aten::select(%3290, %125, %140), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3292 : Float(17:262656, 256:513, 513:1) = aten::slice(%3291, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3293 : Float(17:262656, 256:513, 257:1) = aten::slice(%3292, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3294 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.14, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3295 : Float(17:262656, 256:513, 513:1) = aten::select(%3294, %125, %140), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3296 : Float(17:262656, 256:513, 513:1) = aten::slice(%3295, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3297 : Float(17:262656, 256:513, 257:1) = aten::slice(%3296, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3298 : int[] = prim::ListConstruct(%156, %142, %148), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3299 : Float(17:262656, 256:513, 257:1) = aten::view(%3293, %3298), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3300 : Float(17:262656, 256:513, 257:1) = aten::copy_(%3297, %3299, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:512:0
  %3301 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.14, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3302 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%3301, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3303 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%3302, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3304 : Float(17:262656, 1:262656, 256:513, 256:1) = aten::slice(%3303, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3305 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.14, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3306 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%3305, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3307 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%3306, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3308 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::slice(%3307, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3309 : int[] = prim::ListConstruct(%156, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3310 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::view(%3304, %3309), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3311 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::copy_(%3308, %3310, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:516:0
  %3312 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.14, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3313 : Float(17:262656, 512:513, 513:1) = aten::select(%3312, %125, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3314 : Float(17:262656, 255:513, 513:1) = aten::slice(%3313, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3315 : Float(17:262656, 255:513, 255:1) = aten::slice(%3314, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3316 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.14, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3317 : Float(17:262656, 256:513, 513:1) = aten::select(%3316, %125, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3318 : Float(17:262656, 255:513, 513:1) = aten::slice(%3317, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3319 : Float(17:262656, 255:513, 255:1) = aten::slice(%3318, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3320 : int[] = prim::ListConstruct(%156, %151, %151), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3321 : Float(17:262656, 255:513, 255:1) = aten::view(%3315, %3320), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3322 : Float(17:262656, 255:513, 255:1) = aten::copy_(%3319, %3321, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:520:0
  %3323 : int[] = prim::ListConstruct(%3206, %3210, %3208, %143), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3324 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.14, %3323), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.20 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::transpose(%3324, %124, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:525:0
  %3326 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3327 : Float(256:257, 257:1) = aten::ones(%3326, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:458:0
  %3328 : Float(256:257, 257:1) = aten::tril(%3327, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:458:0
  %3329 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %beginning_mask_2d.14 : Float(256:257, 257:1) = aten::flip(%3328, %3329), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:458:0
  %3331 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.14, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:459:0
  %3332 : Float(1:65792, 256:257, 257:1) = aten::slice(%3331, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:459:0
  %3333 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%3332, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.14 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%3333, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:459:0
  %3335 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %ending_mask.14 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.14, %3335), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:460:0
  %3337 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.20, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:461:0
  %3338 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%3337, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:461:0
  %3339 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%3338, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.14 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%3339, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:461:0
  %3341 : int = aten::size(%beginning_input.14, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:462:0
  %3342 : int = aten::size(%beginning_input.14, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:462:0
  %3343 : int = aten::size(%beginning_input.14, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:462:0
  %3344 : int = aten::size(%beginning_input.14, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:462:0
  %3345 : int[] = prim::ListConstruct(%3341, %3342, %3343, %3344), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3346 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%beginning_mask.14, %3345, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:462:0
  %3347 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%3346, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/tensor.py:22:0
  %3348 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%beginning_input.14, %3347, %153), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:463:0
  %3349 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.20, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:464:0
  %3350 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%3349, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:464:0
  %3351 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%3350, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.14 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%3351, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:464:0
  %3353 : int = aten::size(%ending_input.14, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:465:0
  %3354 : int = aten::size(%ending_input.14, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:465:0
  %3355 : int = aten::size(%ending_input.14, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:465:0
  %3356 : int = aten::size(%ending_input.14, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:465:0
  %3357 : int[] = prim::ListConstruct(%3353, %3354, %3355, %3356), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3358 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%ending_mask.14, %3357, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:465:0
  %3359 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%3358, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/tensor.py:22:0
  %3360 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%ending_input.14, %3359, %153), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:466:0
  %attn_scores.7 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::add_(%input_tensor.19, %input_tensor.20, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:284:0
  %attn_probs_fp32.7 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::softmax(%attn_scores.7, %140, %144), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/nn/functional.py:1500:0
  %3363 : Bool(17:512, 512:1) = aten::slice(%is_index_masked.7, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:326:0
  %3364 : Bool(17:512, 512:1) = aten::slice(%3363, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:326:0
  %3365 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%3364, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:326:0
  %3366 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%3365, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:326:0
  %input.82 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::masked_fill(%attn_probs_fp32.7, %3366, %157), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:326:0
  %attn_probs.14 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::dropout(%input.82, %158, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/nn/functional.py:973:0
  %3369 : int[] = prim::ListConstruct(%3028, %3029, %128, %129), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3370 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%value_vectors.7, %3369), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:331:0
  %value.7 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%3370, %126, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:331:0
  %3372 : int = aten::size(%value.7, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:537:0
  %batch_size.28 : Long() = prim::NumToTensor(%3372), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3374 : int = aten::size(%value.7, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:537:0
  %seq_len.29 : Long() = prim::NumToTensor(%3374), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3376 : int = aten::size(%value.7, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:537:0
  %num_heads.21 : Long() = prim::NumToTensor(%3376), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3378 : int = aten::size(%value.7, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:537:0
  %3379 : Long() = aten::floor_divide(%seq_len.29, %131), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/tensor.py:424:0
  %chunks_count.21 : Long() = aten::sub(%3379, %132, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:542:0
  %3381 : Float(17:3151872, 12:513, 512:6156, 513:1) = aten::transpose(%attn_probs.14, %125, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:545:0
  %3382 : Long() = aten::mul(%batch_size.28, %num_heads.21), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:546:0
  %3383 : int = aten::Int(%3382), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3384 : Long() = aten::floor_divide(%seq_len.29, %131), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/tensor.py:424:0
  %3385 : int = aten::Int(%3384), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3386 : int[] = prim::ListConstruct(%3383, %3385, %142, %143), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %chunked_hidden_states.31 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::reshape(%3381, %3386), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:545:0
  %3388 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%value.7, %125, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:550:0
  %3389 : Long() = aten::mul(%batch_size.28, %num_heads.21), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:550:0
  %3390 : int = aten::Int(%3389), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3391 : int[] = prim::ListConstruct(%3390, %3374, %3378), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %input.83 : Float(204:64, 512:13056, 64:1) = aten::reshape(%3388, %3391), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:550:0
  %3393 : int[] = prim::ListConstruct(%126, %126, %142, %142), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %padded_value.7 : Float(204:65536, 1024:64, 64:1) = aten::constant_pad_nd(%input.83, %3393, %140), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/nn/functional.py:3552:0
  %3395 : Long() = aten::mul(%batch_size.28, %num_heads.21), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:556:0
  %3396 : int = aten::Int(%3395), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3397 : Long() = aten::add(%chunks_count.21, %132, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:556:0
  %3398 : int = aten::Int(%3397), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3399 : int[] = prim::ListConstruct(%3396, %3398, %159, %3378), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3400 : int[] = prim::ListConstruct(%160, %161, %129, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3401 : Float(204:65536, 2:16384, 768:64, 64:1) = aten::as_strided(%padded_value.7, %3399, %3400, %138), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:564:0
  %3402 : int = aten::size(%chunked_hidden_states.31, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:420:0
  %3403 : int = aten::size(%chunked_hidden_states.31, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:420:0
  %3404 : int = aten::size(%chunked_hidden_states.31, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:420:0
  %window_overlap.7 : Long() = prim::NumToTensor(%3404), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3406 : int = aten::size(%chunked_hidden_states.31, %130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:420:0
  %hidden_dim.7 : Long() = prim::NumToTensor(%3406), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3408 : Long() = aten::add(%window_overlap.7, %132, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:422:0
  %3409 : int = aten::Int(%3408), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3410 : int[] = prim::ListConstruct(%126, %3409), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %chunked_hidden_states.32 : Float(204:394240, 2:197120, 256:770, 770:1) = aten::constant_pad_nd(%chunked_hidden_states.31, %3410, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/nn/functional.py:3552:0
  %3412 : int[] = prim::ListConstruct(%3402, %3403, %140), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %chunked_hidden_states.33 : Float(204:394240, 2:197120, 197120:1) = aten::view(%chunked_hidden_states.32, %3412), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:424:0
  %3414 : Long() = aten::neg(%window_overlap.7), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:428:0
  %3415 : int = aten::Int(%3414), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3416 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%chunked_hidden_states.33, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:427:0
  %3417 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%3416, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:427:0
  %chunked_hidden_states.34 : Float(204:394240, 2:197120, 196864:1) = aten::slice(%3417, %124, %126, %3415, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:427:0
  %3419 : Long() = aten::add(%window_overlap.7, %hidden_dim.7, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:431:0
  %3420 : int = aten::Int(%3419), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3421 : int[] = prim::ListConstruct(%3402, %3403, %3404, %3420), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %chunked_hidden_states.35 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::view(%chunked_hidden_states.34, %3421), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:430:0
  %3423 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%chunked_hidden_states.35, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:433:0
  %3424 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%3423, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:433:0
  %3425 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%3424, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:433:0
  %3426 : Float(204:394240, 2:197120, 256:769, 768:1) = aten::slice(%3425, %130, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:433:0
  %3427 : Tensor[] = prim::ListConstruct(%3426, %3401), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %context.7 : Float(204:32768, 2:16384, 256:64, 64:1) = aten::einsum(%162, %3427), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/functional.py:327:0
  %3429 : int[] = prim::ListConstruct(%3372, %3376, %3374, %3378), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3430 : Float(17:393216, 12:32768, 512:64, 64:1) = aten::view(%context.7, %3429), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:569:0
  %attn_output.13 : Float(17:393216, 512:64, 12:32768, 64:1) = aten::transpose(%3430, %125, %124), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:569:0
  %3432 : Float(512:64, 17:393216, 12:32768, 64:1) = aten::transpose(%attn_output.13, %126, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:350:0
  %3433 : int[] = prim::ListConstruct(%3028, %3029, %3030), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %3434 : Float(512:13056, 17:768, 768:1) = aten::reshape(%3432, %3433), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:350:0
  %attn_output.14 : Float(512:13056, 17:768, 768:1) = aten::contiguous(%3434, %126), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:350:0
  %input.84 : Float(17:768, 512:13056, 768:1) = aten::transpose(%attn_output.14, %126, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_longformer.py:374:0
  %3437 : __torch__.torch.nn.modules.normalization.___torch_mangle_8172.LayerNorm = prim::GetAttr[name="LayerNorm"](%3004)
  %3438 : __torch__.torch.nn.modules.linear.___torch_mangle_8171.Linear = prim::GetAttr[name="dense"](%3004)
  %3439 : Tensor = prim::GetAttr[name="bias"](%3438)
  %3440 : Tensor = prim::GetAttr[name="weight"](%3438)
  %3441 : Float(768:1, 768:768) = aten::t(%3440), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %output.40 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.84, %3441), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %input.85 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.40, %3439, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.76 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.85, %158, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.dropout # torch/nn/functional.py:973:0
  %input.86 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.76, %hidden_states.67, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output # transformers/modeling_longformer.py:758:0
  %3446 : Tensor = prim::GetAttr[name="bias"](%3437)
  %3447 : Tensor = prim::GetAttr[name="weight"](%3437)
  %3448 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.LayerNorm
  %input_tensor.21 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.86, %3448, %3447, %3446, %123, %122), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %3450 : __torch__.torch.nn.modules.linear.___torch_mangle_8176.Linear = prim::GetAttr[name="dense"](%3002)
  %3451 : Tensor = prim::GetAttr[name="bias"](%3450)
  %3452 : Tensor = prim::GetAttr[name="weight"](%3450)
  %3453 : Float(768:1, 3072:768) = aten::t(%3452), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.intermediate/__module.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %output.41 : Float(17:1572864, 512:3072, 3072:1) = aten::matmul(%input_tensor.21, %3453), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.intermediate/__module.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %input.87 : Float(17:1572864, 512:3072, 3072:1) = aten::add_(%output.41, %3451, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.intermediate/__module.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1678:0
  %input.88 : Float(17:1572864, 512:3072, 3072:1) = aten::gelu(%input.87), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.intermediate # torch/nn/functional.py:1369:0
  %3457 : __torch__.torch.nn.modules.normalization.___torch_mangle_8179.LayerNorm = prim::GetAttr[name="LayerNorm"](%3001)
  %3458 : __torch__.torch.nn.modules.linear.___torch_mangle_8178.Linear = prim::GetAttr[name="dense"](%3001)
  %3459 : Tensor = prim::GetAttr[name="bias"](%3458)
  %3460 : Tensor = prim::GetAttr[name="weight"](%3458)
  %3461 : Float(3072:1, 768:3072) = aten::t(%3460), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %output.42 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.88, %3461), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %input.89 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.42, %3459, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.77 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.89, %158, %146), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.dropout # torch/nn/functional.py:973:0
  %input.90 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.77, %input_tensor.21, %125), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output # transformers/modeling_longformer.py:830:0
  %3466 : Tensor = prim::GetAttr[name="bias"](%3457)
  %3467 : Tensor = prim::GetAttr[name="weight"](%3457)
  %3468 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.LayerNorm
  %hidden_states.78 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.90, %3468, %3467, %3466, %123, %122), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.LayerNorm # torch/nn/functional.py:2048:0
  %3470 : __torch__.transformers.modeling_longformer.___torch_mangle_8200.LongformerOutput = prim::GetAttr[name="output"](%172)
  %3471 : __torch__.transformers.modeling_longformer.___torch_mangle_8196.LongformerIntermediate = prim::GetAttr[name="intermediate"](%172)
  %3472 : __torch__.transformers.modeling_longformer.___torch_mangle_8194.LongformerAttention = prim::GetAttr[name="attention"](%172)
  %3473 : __torch__.transformers.modeling_longformer.___torch_mangle_8193.LongformerSelfOutput = prim::GetAttr[name="output"](%3472)
  %3474 : __torch__.transformers.modeling_longformer.___torch_mangle_8189.LongformerSelfAttention = prim::GetAttr[name="self"](%3472)
  %3475 : __torch__.torch.nn.modules.linear.___torch_mangle_8185.Linear = prim::GetAttr[name="value"](%3474)
  %3476 : __torch__.torch.nn.modules.linear.___torch_mangle_8184.Linear = prim::GetAttr[name="key"](%3474)
  %3477 : __torch__.torch.nn.modules.linear.___torch_mangle_8183.Linear = prim::GetAttr[name="query"](%3474)
  %3478 : Float(17:512, 1:512, 512:1) = aten::squeeze(%attention_mask, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:241:0
  %3479 : Float(17:512, 512:1) = aten::squeeze(%3478, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:241:0
  %is_index_masked.8 : Bool(17:512, 512:1) = aten::lt(%3479, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/tensor.py:22:0
  %input.91 : Float(512:768, 17:393216, 768:1) = aten::transpose(%hidden_states.78, %126, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:248:0
  %3482 : Tensor = prim::GetAttr[name="bias"](%3477)
  %3483 : Tensor = prim::GetAttr[name="weight"](%3477)
  %3484 : Float(768:1, 768:768) = aten::t(%3483), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %output.43 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.91, %3484), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %query_vectors.15 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.43, %3482, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.query # torch/nn/functional.py:1678:0
  %3487 : Tensor = prim::GetAttr[name="bias"](%3476)
  %3488 : Tensor = prim::GetAttr[name="weight"](%3476)
  %3489 : Float(768:1, 768:768) = aten::t(%3488), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %output.44 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.91, %3489), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %key_vectors.8 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.44, %3487, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.key # torch/nn/functional.py:1678:0
  %3492 : Tensor = prim::GetAttr[name="bias"](%3475)
  %3493 : Tensor = prim::GetAttr[name="weight"](%3475)
  %3494 : Float(768:1, 768:768) = aten::t(%3493), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %output.45 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.91, %3494), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %value_vectors.8 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.45, %3492, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.value # torch/nn/functional.py:1678:0
  %3497 : int = aten::size(%input.91, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:255:0
  %3498 : int = aten::size(%input.91, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:255:0
  %3499 : int = aten::size(%input.91, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:255:0
  %query_vectors.16 : Float(512:13056, 17:768, 768:1) = aten::div_(%query_vectors.15, %127), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:261:0
  %3501 : int[] = prim::ListConstruct(%3497, %3498, %128, %129), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3502 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%query_vectors.16, %3501), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:263:0
  %query.15 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%3502, %126, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:263:0
  %3504 : int[] = prim::ListConstruct(%3497, %3498, %128, %129), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3505 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%key_vectors.8, %3504), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:264:0
  %key.8 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%3505, %126, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:264:0
  %3507 : int = aten::size(%query.15, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.30 : Long() = prim::NumToTensor(%3507), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3509 : int = aten::size(%query.15, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.31 : Long() = prim::NumToTensor(%3509), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3511 : int = aten::size(%query.15, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.22 : Long() = prim::NumToTensor(%3511), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3513 : int = aten::size(%query.15, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:472:0
  %3514 : Long() = aten::floor_divide(%seq_len.31, %131), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/tensor.py:424:0
  %chunks_count.22 : Long() = aten::sub(%3514, %132, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:478:0
  %3516 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%query.15, %125, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:481:0
  %3517 : Long() = aten::mul(%batch_size.30, %num_heads.22), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:481:0
  %3518 : int = aten::Int(%3517), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3519 : int[] = prim::ListConstruct(%3518, %3509, %3513), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %hidden_states.79 : Float(204:64, 512:13056, 64:1) = aten::reshape(%3516, %3519), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:481:0
  %3521 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%key.8, %125, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:482:0
  %3522 : Long() = aten::mul(%batch_size.30, %num_heads.22), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:482:0
  %3523 : int = aten::Int(%3522), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3524 : int[] = prim::ListConstruct(%3523, %3509, %3513), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %hidden_states.81 : Float(204:64, 512:13056, 64:1) = aten::reshape(%3521, %3524), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:482:0
  %3526 : int = aten::size(%hidden_states.79, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:442:0
  %3527 : int = aten::size(%hidden_states.79, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:443:0
  %3528 : Long() = prim::NumToTensor(%3527), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3529 : Long() = aten::floor_divide(%3528, %133), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/tensor.py:424:0
  %3530 : int = aten::Int(%3529), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3531 : int = aten::size(%hidden_states.79, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:445:0
  %3532 : int[] = prim::ListConstruct(%3526, %3530, %134, %3531), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %hidden_states.80 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.79, %3532), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:441:0
  %3534 : int = aten::size(%hidden_states.80, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3535 : int = aten::size(%hidden_states.80, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3536 : Long() = prim::NumToTensor(%3535), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3537 : int = aten::size(%hidden_states.80, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3538 : int = aten::size(%hidden_states.80, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3539 : Long() = aten::mul(%3536, %135), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:450:0
  %3540 : Long() = aten::sub(%3539, %132, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:450:0
  %3541 : int = aten::Int(%3540), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3542 : int[] = prim::ListConstruct(%3534, %3541, %3537, %3538), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3543 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3544 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.80, %3542, %3543, %138), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:454:0
  %3545 : int = aten::size(%hidden_states.81, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:442:0
  %3546 : int = aten::size(%hidden_states.81, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:443:0
  %3547 : Long() = prim::NumToTensor(%3546), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3548 : Long() = aten::floor_divide(%3547, %133), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/tensor.py:424:0
  %3549 : int = aten::Int(%3548), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3550 : int = aten::size(%hidden_states.81, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:445:0
  %3551 : int[] = prim::ListConstruct(%3545, %3549, %134, %3550), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %hidden_states.82 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.81, %3551), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:441:0
  %3553 : int = aten::size(%hidden_states.82, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3554 : int = aten::size(%hidden_states.82, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3555 : Long() = prim::NumToTensor(%3554), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3556 : int = aten::size(%hidden_states.82, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3557 : int = aten::size(%hidden_states.82, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3558 : Long() = aten::mul(%3555, %135), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:450:0
  %3559 : Long() = aten::sub(%3558, %132, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:450:0
  %3560 : int = aten::Int(%3559), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3561 : int[] = prim::ListConstruct(%3553, %3560, %3556, %3557), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3562 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3563 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.82, %3561, %3562, %138), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:454:0
  %3564 : Tensor[] = prim::ListConstruct(%3544, %3563), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %input.92 : Float(204:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %3564), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/functional.py:327:0
  %3566 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %hidden_states_padded.15 : Float(204:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.92, %3566, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/nn/functional.py:3552:0
  %3568 : int = aten::size(%hidden_states_padded.15, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:401:0
  %3569 : int = aten::size(%hidden_states_padded.15, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:401:0
  %3570 : int = aten::size(%hidden_states_padded.15, %140), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:401:0
  %3571 : int = aten::size(%hidden_states_padded.15, %141), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:401:0
  %3572 : int[] = prim::ListConstruct(%3568, %3569, %3570, %3571), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %diagonal_chunked_attention_scores.15 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.15, %3572), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:400:0
  %3574 : Long() = aten::mul(%batch_size.30, %num_heads.22), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:504:0
  %3575 : int = aten::Int(%3574), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3576 : Long() = aten::add(%chunks_count.22, %132, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:504:0
  %3577 : int = aten::Int(%3576), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3578 : int[] = prim::ListConstruct(%3575, %3577, %142, %143), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %diagonal_attention_scores.15 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.15, %3578, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:503:0
  %3580 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.15, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3581 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%3580, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3582 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%3581, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3583 : Float(204:262656, 1:262656, 256:513, 257:1) = aten::slice(%3582, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3584 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.15, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3585 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%3584, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3586 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%3585, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3587 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::slice(%3586, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3588 : int[] = prim::ListConstruct(%149, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3589 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::view(%3583, %3588), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3590 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::copy_(%3587, %3589, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3591 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.15, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3592 : Float(204:262656, 512:513, 513:1) = aten::select(%3591, %125, %140), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3593 : Float(204:262656, 256:513, 513:1) = aten::slice(%3592, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3594 : Float(204:262656, 256:513, 257:1) = aten::slice(%3593, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3595 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.15, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3596 : Float(204:262656, 256:513, 513:1) = aten::select(%3595, %125, %140), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3597 : Float(204:262656, 256:513, 513:1) = aten::slice(%3596, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3598 : Float(204:262656, 256:513, 257:1) = aten::slice(%3597, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3599 : int[] = prim::ListConstruct(%149, %142, %148), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3600 : Float(204:262656, 256:513, 257:1) = aten::view(%3594, %3599), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3601 : Float(204:262656, 256:513, 257:1) = aten::copy_(%3598, %3600, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3602 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.15, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3603 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%3602, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3604 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%3603, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3605 : Float(204:262656, 1:262656, 256:513, 256:1) = aten::slice(%3604, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3606 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.15, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3607 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%3606, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3608 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%3607, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3609 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::slice(%3608, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3610 : int[] = prim::ListConstruct(%149, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3611 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::view(%3605, %3610), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3612 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::copy_(%3609, %3611, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3613 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.15, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3614 : Float(204:262656, 512:513, 513:1) = aten::select(%3613, %125, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3615 : Float(204:262656, 255:513, 513:1) = aten::slice(%3614, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3616 : Float(204:262656, 255:513, 255:1) = aten::slice(%3615, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3617 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.15, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3618 : Float(204:262656, 256:513, 513:1) = aten::select(%3617, %125, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3619 : Float(204:262656, 255:513, 513:1) = aten::slice(%3618, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3620 : Float(204:262656, 255:513, 255:1) = aten::slice(%3619, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3621 : int[] = prim::ListConstruct(%149, %151, %151), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3622 : Float(204:262656, 255:513, 255:1) = aten::view(%3616, %3621), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3623 : Float(204:262656, 255:513, 255:1) = aten::copy_(%3620, %3622, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3624 : int[] = prim::ListConstruct(%3507, %3511, %3509, %143), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3625 : Float(17:3151872, 12:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.15, %3624), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.22 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::transpose(%3625, %124, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:525:0
  %3627 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3628 : Float(256:257, 257:1) = aten::ones(%3627, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:458:0
  %3629 : Float(256:257, 257:1) = aten::tril(%3628, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:458:0
  %3630 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %beginning_mask_2d.15 : Float(256:257, 257:1) = aten::flip(%3629, %3630), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:458:0
  %3632 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.15, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:459:0
  %3633 : Float(1:65792, 256:257, 257:1) = aten::slice(%3632, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:459:0
  %3634 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%3633, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.15 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%3634, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:459:0
  %3636 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %ending_mask.15 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.15, %3636), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:460:0
  %3638 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.22, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:461:0
  %3639 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%3638, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:461:0
  %3640 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%3639, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.15 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%3640, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:461:0
  %3642 : int = aten::size(%beginning_input.15, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:462:0
  %3643 : int = aten::size(%beginning_input.15, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:462:0
  %3644 : int = aten::size(%beginning_input.15, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:462:0
  %3645 : int = aten::size(%beginning_input.15, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:462:0
  %3646 : int[] = prim::ListConstruct(%3642, %3643, %3644, %3645), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3647 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%beginning_mask.15, %3646, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:462:0
  %3648 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%3647, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/tensor.py:22:0
  %3649 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%beginning_input.15, %3648, %153), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:463:0
  %3650 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.22, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:464:0
  %3651 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%3650, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:464:0
  %3652 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%3651, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.15 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%3652, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:464:0
  %3654 : int = aten::size(%ending_input.15, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:465:0
  %3655 : int = aten::size(%ending_input.15, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:465:0
  %3656 : int = aten::size(%ending_input.15, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:465:0
  %3657 : int = aten::size(%ending_input.15, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:465:0
  %3658 : int[] = prim::ListConstruct(%3654, %3655, %3656, %3657), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3659 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%ending_mask.15, %3658, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:465:0
  %3660 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%3659, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/tensor.py:22:0
  %3661 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%ending_input.15, %3660, %153), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:466:0
  %3662 : Bool(17:512, 512:1) = aten::ne(%3479, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/tensor.py:22:0
  %3663 : Bool(17:512, 512:1) = aten::slice(%3662, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:272:0
  %3664 : Bool(17:512, 512:1) = aten::slice(%3663, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:272:0
  %3665 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%3664, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:272:0
  %remove_from_windowed_attention_mask.8 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%3665, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:272:0
  %3667 : Float(17:512, 512:1, 1:1, 1:1) = aten::type_as(%remove_from_windowed_attention_mask.8, %query.15), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:275:0
  %float_mask.8 : Float(17:512, 512:1, 1:1, 1:1) = aten::masked_fill(%3667, %remove_from_windowed_attention_mask.8, %155), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:275:0
  %3669 : int = aten::size(%float_mask.8, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:280:0
  %3670 : int = aten::size(%float_mask.8, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:280:0
  %3671 : int = aten::size(%float_mask.8, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:280:0
  %3672 : int = aten::size(%float_mask.8, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:280:0
  %3673 : int[] = prim::ListConstruct(%3669, %3670, %3671, %3672), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %query.16 : Float(17:512, 512:1, 1:1, 1:1) = aten::ones(%3673, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:280:0
  %3675 : int = aten::size(%query.16, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.31 : Long() = prim::NumToTensor(%3675), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3677 : int = aten::size(%query.16, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.32 : Long() = prim::NumToTensor(%3677), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3679 : int = aten::size(%query.16, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.23 : Long() = prim::NumToTensor(%3679), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3681 : int = aten::size(%query.16, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:472:0
  %3682 : Long() = aten::floor_divide(%seq_len.32, %131), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/tensor.py:424:0
  %chunks_count.23 : Long() = aten::sub(%3682, %132, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:478:0
  %3684 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%query.16, %125, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:481:0
  %3685 : Long() = aten::mul(%batch_size.31, %num_heads.23), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:481:0
  %3686 : int = aten::Int(%3685), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3687 : int[] = prim::ListConstruct(%3686, %3677, %3681), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %hidden_states.83 : Float(17:512, 512:1, 1:1) = aten::reshape(%3684, %3687), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:481:0
  %3689 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%float_mask.8, %125, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:482:0
  %3690 : Long() = aten::mul(%batch_size.31, %num_heads.23), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:482:0
  %3691 : int = aten::Int(%3690), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3692 : int[] = prim::ListConstruct(%3691, %3677, %3681), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %hidden_states.85 : Float(17:512, 512:1, 1:1) = aten::reshape(%3689, %3692), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:482:0
  %3694 : int = aten::size(%hidden_states.83, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:442:0
  %3695 : int = aten::size(%hidden_states.83, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:443:0
  %3696 : Long() = prim::NumToTensor(%3695), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3697 : Long() = aten::floor_divide(%3696, %133), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/tensor.py:424:0
  %3698 : int = aten::Int(%3697), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3699 : int = aten::size(%hidden_states.83, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:445:0
  %3700 : int[] = prim::ListConstruct(%3694, %3698, %134, %3699), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %hidden_states.84 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.83, %3700), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:441:0
  %3702 : int = aten::size(%hidden_states.84, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3703 : int = aten::size(%hidden_states.84, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3704 : Long() = prim::NumToTensor(%3703), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3705 : int = aten::size(%hidden_states.84, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3706 : int = aten::size(%hidden_states.84, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3707 : Long() = aten::mul(%3704, %135), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:450:0
  %3708 : Long() = aten::sub(%3707, %132, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:450:0
  %3709 : int = aten::Int(%3708), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3710 : int[] = prim::ListConstruct(%3702, %3709, %3705, %3706), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3711 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3712 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.84, %3710, %3711, %138), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:454:0
  %3713 : int = aten::size(%hidden_states.85, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:442:0
  %3714 : int = aten::size(%hidden_states.85, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:443:0
  %3715 : Long() = prim::NumToTensor(%3714), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3716 : Long() = aten::floor_divide(%3715, %133), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/tensor.py:424:0
  %3717 : int = aten::Int(%3716), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3718 : int = aten::size(%hidden_states.85, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:445:0
  %3719 : int[] = prim::ListConstruct(%3713, %3717, %134, %3718), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %hidden_states.86 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.85, %3719), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:441:0
  %3721 : int = aten::size(%hidden_states.86, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3722 : int = aten::size(%hidden_states.86, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3723 : Long() = prim::NumToTensor(%3722), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3724 : int = aten::size(%hidden_states.86, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3725 : int = aten::size(%hidden_states.86, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:449:0
  %3726 : Long() = aten::mul(%3723, %135), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:450:0
  %3727 : Long() = aten::sub(%3726, %132, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:450:0
  %3728 : int = aten::Int(%3727), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3729 : int[] = prim::ListConstruct(%3721, %3728, %3724, %3725), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3730 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3731 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.86, %3729, %3730, %138), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:454:0
  %3732 : Tensor[] = prim::ListConstruct(%3712, %3731), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %input.93 : Float(17:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %3732), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/functional.py:327:0
  %3734 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %hidden_states_padded.16 : Float(17:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.93, %3734, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/nn/functional.py:3552:0
  %3736 : int = aten::size(%hidden_states_padded.16, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:401:0
  %3737 : int = aten::size(%hidden_states_padded.16, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:401:0
  %3738 : int = aten::size(%hidden_states_padded.16, %140), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:401:0
  %3739 : int = aten::size(%hidden_states_padded.16, %141), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:401:0
  %3740 : int[] = prim::ListConstruct(%3736, %3737, %3738, %3739), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %diagonal_chunked_attention_scores.16 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.16, %3740), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:400:0
  %3742 : Long() = aten::mul(%batch_size.31, %num_heads.23), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:504:0
  %3743 : int = aten::Int(%3742), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3744 : Long() = aten::add(%chunks_count.23, %132, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:504:0
  %3745 : int = aten::Int(%3744), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3746 : int[] = prim::ListConstruct(%3743, %3745, %142, %143), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %diagonal_attention_scores.16 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.16, %3746, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:503:0
  %3748 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.16, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3749 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%3748, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3750 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%3749, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3751 : Float(17:262656, 1:262656, 256:513, 257:1) = aten::slice(%3750, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3752 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.16, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3753 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%3752, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3754 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%3753, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3755 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::slice(%3754, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3756 : int[] = prim::ListConstruct(%156, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3757 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::view(%3751, %3756), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3758 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::copy_(%3755, %3757, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:509:0
  %3759 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.16, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3760 : Float(17:262656, 512:513, 513:1) = aten::select(%3759, %125, %140), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3761 : Float(17:262656, 256:513, 513:1) = aten::slice(%3760, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3762 : Float(17:262656, 256:513, 257:1) = aten::slice(%3761, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3763 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.16, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3764 : Float(17:262656, 256:513, 513:1) = aten::select(%3763, %125, %140), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3765 : Float(17:262656, 256:513, 513:1) = aten::slice(%3764, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3766 : Float(17:262656, 256:513, 257:1) = aten::slice(%3765, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3767 : int[] = prim::ListConstruct(%156, %142, %148), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3768 : Float(17:262656, 256:513, 257:1) = aten::view(%3762, %3767), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3769 : Float(17:262656, 256:513, 257:1) = aten::copy_(%3766, %3768, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:512:0
  %3770 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.16, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3771 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%3770, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3772 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%3771, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3773 : Float(17:262656, 1:262656, 256:513, 256:1) = aten::slice(%3772, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3774 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.16, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3775 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%3774, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3776 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%3775, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3777 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::slice(%3776, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3778 : int[] = prim::ListConstruct(%156, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3779 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::view(%3773, %3778), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3780 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::copy_(%3777, %3779, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:516:0
  %3781 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.16, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3782 : Float(17:262656, 512:513, 513:1) = aten::select(%3781, %125, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3783 : Float(17:262656, 255:513, 513:1) = aten::slice(%3782, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3784 : Float(17:262656, 255:513, 255:1) = aten::slice(%3783, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3785 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.16, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3786 : Float(17:262656, 256:513, 513:1) = aten::select(%3785, %125, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3787 : Float(17:262656, 255:513, 513:1) = aten::slice(%3786, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3788 : Float(17:262656, 255:513, 255:1) = aten::slice(%3787, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3789 : int[] = prim::ListConstruct(%156, %151, %151), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3790 : Float(17:262656, 255:513, 255:1) = aten::view(%3784, %3789), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3791 : Float(17:262656, 255:513, 255:1) = aten::copy_(%3788, %3790, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:520:0
  %3792 : int[] = prim::ListConstruct(%3675, %3679, %3677, %143), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3793 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.16, %3792), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.23 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::transpose(%3793, %124, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:525:0
  %3795 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3796 : Float(256:257, 257:1) = aten::ones(%3795, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:458:0
  %3797 : Float(256:257, 257:1) = aten::tril(%3796, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:458:0
  %3798 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %beginning_mask_2d.16 : Float(256:257, 257:1) = aten::flip(%3797, %3798), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:458:0
  %3800 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.16, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:459:0
  %3801 : Float(1:65792, 256:257, 257:1) = aten::slice(%3800, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:459:0
  %3802 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%3801, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.16 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%3802, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:459:0
  %3804 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %ending_mask.16 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.16, %3804), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:460:0
  %3806 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.23, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:461:0
  %3807 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%3806, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:461:0
  %3808 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%3807, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.16 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%3808, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:461:0
  %3810 : int = aten::size(%beginning_input.16, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:462:0
  %3811 : int = aten::size(%beginning_input.16, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:462:0
  %3812 : int = aten::size(%beginning_input.16, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:462:0
  %3813 : int = aten::size(%beginning_input.16, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:462:0
  %3814 : int[] = prim::ListConstruct(%3810, %3811, %3812, %3813), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3815 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%beginning_mask.16, %3814, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:462:0
  %3816 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%3815, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/tensor.py:22:0
  %3817 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%beginning_input.16, %3816, %153), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:463:0
  %3818 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.23, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:464:0
  %3819 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%3818, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:464:0
  %3820 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%3819, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.16 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%3820, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:464:0
  %3822 : int = aten::size(%ending_input.16, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:465:0
  %3823 : int = aten::size(%ending_input.16, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:465:0
  %3824 : int = aten::size(%ending_input.16, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:465:0
  %3825 : int = aten::size(%ending_input.16, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:465:0
  %3826 : int[] = prim::ListConstruct(%3822, %3823, %3824, %3825), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3827 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%ending_mask.16, %3826, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:465:0
  %3828 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%3827, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/tensor.py:22:0
  %3829 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%ending_input.16, %3828, %153), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:466:0
  %attn_scores.8 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::add_(%input_tensor.22, %input_tensor.23, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:284:0
  %attn_probs_fp32.8 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::softmax(%attn_scores.8, %140, %144), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/nn/functional.py:1500:0
  %3832 : Bool(17:512, 512:1) = aten::slice(%is_index_masked.8, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:326:0
  %3833 : Bool(17:512, 512:1) = aten::slice(%3832, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:326:0
  %3834 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%3833, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:326:0
  %3835 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%3834, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:326:0
  %input.94 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::masked_fill(%attn_probs_fp32.8, %3835, %157), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:326:0
  %attn_probs.16 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::dropout(%input.94, %158, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/nn/functional.py:973:0
  %3838 : int[] = prim::ListConstruct(%3497, %3498, %128, %129), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3839 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%value_vectors.8, %3838), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:331:0
  %value.8 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%3839, %126, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:331:0
  %3841 : int = aten::size(%value.8, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:537:0
  %batch_size.32 : Long() = prim::NumToTensor(%3841), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3843 : int = aten::size(%value.8, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:537:0
  %seq_len.33 : Long() = prim::NumToTensor(%3843), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3845 : int = aten::size(%value.8, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:537:0
  %num_heads.24 : Long() = prim::NumToTensor(%3845), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3847 : int = aten::size(%value.8, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:537:0
  %3848 : Long() = aten::floor_divide(%seq_len.33, %131), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/tensor.py:424:0
  %chunks_count.24 : Long() = aten::sub(%3848, %132, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:542:0
  %3850 : Float(17:3151872, 12:513, 512:6156, 513:1) = aten::transpose(%attn_probs.16, %125, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:545:0
  %3851 : Long() = aten::mul(%batch_size.32, %num_heads.24), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:546:0
  %3852 : int = aten::Int(%3851), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3853 : Long() = aten::floor_divide(%seq_len.33, %131), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/tensor.py:424:0
  %3854 : int = aten::Int(%3853), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3855 : int[] = prim::ListConstruct(%3852, %3854, %142, %143), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %chunked_hidden_states.36 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::reshape(%3850, %3855), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:545:0
  %3857 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%value.8, %125, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:550:0
  %3858 : Long() = aten::mul(%batch_size.32, %num_heads.24), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:550:0
  %3859 : int = aten::Int(%3858), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3860 : int[] = prim::ListConstruct(%3859, %3843, %3847), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %input.95 : Float(204:64, 512:13056, 64:1) = aten::reshape(%3857, %3860), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:550:0
  %3862 : int[] = prim::ListConstruct(%126, %126, %142, %142), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %padded_value.8 : Float(204:65536, 1024:64, 64:1) = aten::constant_pad_nd(%input.95, %3862, %140), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/nn/functional.py:3552:0
  %3864 : Long() = aten::mul(%batch_size.32, %num_heads.24), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:556:0
  %3865 : int = aten::Int(%3864), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3866 : Long() = aten::add(%chunks_count.24, %132, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:556:0
  %3867 : int = aten::Int(%3866), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3868 : int[] = prim::ListConstruct(%3865, %3867, %159, %3847), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3869 : int[] = prim::ListConstruct(%160, %161, %129, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3870 : Float(204:65536, 2:16384, 768:64, 64:1) = aten::as_strided(%padded_value.8, %3868, %3869, %138), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:564:0
  %3871 : int = aten::size(%chunked_hidden_states.36, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:420:0
  %3872 : int = aten::size(%chunked_hidden_states.36, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:420:0
  %3873 : int = aten::size(%chunked_hidden_states.36, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:420:0
  %window_overlap.8 : Long() = prim::NumToTensor(%3873), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3875 : int = aten::size(%chunked_hidden_states.36, %130), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:420:0
  %hidden_dim.8 : Long() = prim::NumToTensor(%3875), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3877 : Long() = aten::add(%window_overlap.8, %132, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:422:0
  %3878 : int = aten::Int(%3877), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3879 : int[] = prim::ListConstruct(%126, %3878), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %chunked_hidden_states.37 : Float(204:394240, 2:197120, 256:770, 770:1) = aten::constant_pad_nd(%chunked_hidden_states.36, %3879, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/nn/functional.py:3552:0
  %3881 : int[] = prim::ListConstruct(%3871, %3872, %140), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %chunked_hidden_states.38 : Float(204:394240, 2:197120, 197120:1) = aten::view(%chunked_hidden_states.37, %3881), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:424:0
  %3883 : Long() = aten::neg(%window_overlap.8), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:428:0
  %3884 : int = aten::Int(%3883), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3885 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%chunked_hidden_states.38, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:427:0
  %3886 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%3885, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:427:0
  %chunked_hidden_states.39 : Float(204:394240, 2:197120, 196864:1) = aten::slice(%3886, %124, %126, %3884, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:427:0
  %3888 : Long() = aten::add(%window_overlap.8, %hidden_dim.8, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:431:0
  %3889 : int = aten::Int(%3888), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3890 : int[] = prim::ListConstruct(%3871, %3872, %3873, %3889), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %chunked_hidden_states.40 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::view(%chunked_hidden_states.39, %3890), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:430:0
  %3892 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%chunked_hidden_states.40, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:433:0
  %3893 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%3892, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:433:0
  %3894 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%3893, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:433:0
  %3895 : Float(204:394240, 2:197120, 256:769, 768:1) = aten::slice(%3894, %130, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:433:0
  %3896 : Tensor[] = prim::ListConstruct(%3895, %3870), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %context.8 : Float(204:32768, 2:16384, 256:64, 64:1) = aten::einsum(%162, %3896), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/functional.py:327:0
  %3898 : int[] = prim::ListConstruct(%3841, %3845, %3843, %3847), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3899 : Float(17:393216, 12:32768, 512:64, 64:1) = aten::view(%context.8, %3898), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:569:0
  %attn_output.15 : Float(17:393216, 512:64, 12:32768, 64:1) = aten::transpose(%3899, %125, %124), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:569:0
  %3901 : Float(512:64, 17:393216, 12:32768, 64:1) = aten::transpose(%attn_output.15, %126, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:350:0
  %3902 : int[] = prim::ListConstruct(%3497, %3498, %3499), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %3903 : Float(512:13056, 17:768, 768:1) = aten::reshape(%3901, %3902), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:350:0
  %attn_output.16 : Float(512:13056, 17:768, 768:1) = aten::contiguous(%3903, %126), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:350:0
  %input.96 : Float(17:768, 512:13056, 768:1) = aten::transpose(%attn_output.16, %126, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_longformer.py:374:0
  %3906 : __torch__.torch.nn.modules.normalization.___torch_mangle_8191.LayerNorm = prim::GetAttr[name="LayerNorm"](%3473)
  %3907 : __torch__.torch.nn.modules.linear.___torch_mangle_8190.Linear = prim::GetAttr[name="dense"](%3473)
  %3908 : Tensor = prim::GetAttr[name="bias"](%3907)
  %3909 : Tensor = prim::GetAttr[name="weight"](%3907)
  %3910 : Float(768:1, 768:768) = aten::t(%3909), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %output.46 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.96, %3910), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %input.97 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.46, %3908, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.87 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.97, %158, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.dropout # torch/nn/functional.py:973:0
  %input.98 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.87, %hidden_states.78, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output # transformers/modeling_longformer.py:758:0
  %3915 : Tensor = prim::GetAttr[name="bias"](%3906)
  %3916 : Tensor = prim::GetAttr[name="weight"](%3906)
  %3917 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.LayerNorm
  %input_tensor.24 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.98, %3917, %3916, %3915, %123, %122), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %3919 : __torch__.torch.nn.modules.linear.___torch_mangle_8195.Linear = prim::GetAttr[name="dense"](%3471)
  %3920 : Tensor = prim::GetAttr[name="bias"](%3919)
  %3921 : Tensor = prim::GetAttr[name="weight"](%3919)
  %3922 : Float(768:1, 3072:768) = aten::t(%3921), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.intermediate/__module.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %output.47 : Float(17:1572864, 512:3072, 3072:1) = aten::matmul(%input_tensor.24, %3922), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.intermediate/__module.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %input.99 : Float(17:1572864, 512:3072, 3072:1) = aten::add_(%output.47, %3920, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.intermediate/__module.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1678:0
  %input.100 : Float(17:1572864, 512:3072, 3072:1) = aten::gelu(%input.99), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.intermediate # torch/nn/functional.py:1369:0
  %3926 : __torch__.torch.nn.modules.normalization.___torch_mangle_8198.LayerNorm = prim::GetAttr[name="LayerNorm"](%3470)
  %3927 : __torch__.torch.nn.modules.linear.___torch_mangle_8197.Linear = prim::GetAttr[name="dense"](%3470)
  %3928 : Tensor = prim::GetAttr[name="bias"](%3927)
  %3929 : Tensor = prim::GetAttr[name="weight"](%3927)
  %3930 : Float(3072:1, 768:3072) = aten::t(%3929), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %output.48 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.100, %3930), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %input.101 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.48, %3928, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.88 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.101, %158, %146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.dropout # torch/nn/functional.py:973:0
  %input.102 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.88, %input_tensor.24, %125), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output # transformers/modeling_longformer.py:830:0
  %3935 : Tensor = prim::GetAttr[name="bias"](%3926)
  %3936 : Tensor = prim::GetAttr[name="weight"](%3926)
  %3937 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.LayerNorm
  %hidden_states.89 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.102, %3937, %3936, %3935, %123, %122), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.LayerNorm # torch/nn/functional.py:2048:0
  %3939 : __torch__.transformers.modeling_longformer.___torch_mangle_8219.LongformerOutput = prim::GetAttr[name="output"](%170)
  %3940 : __torch__.transformers.modeling_longformer.___torch_mangle_8215.LongformerIntermediate = prim::GetAttr[name="intermediate"](%170)
  %3941 : __torch__.transformers.modeling_longformer.___torch_mangle_8213.LongformerAttention = prim::GetAttr[name="attention"](%170)
  %3942 : __torch__.transformers.modeling_longformer.___torch_mangle_8212.LongformerSelfOutput = prim::GetAttr[name="output"](%3941)
  %3943 : __torch__.transformers.modeling_longformer.___torch_mangle_8208.LongformerSelfAttention = prim::GetAttr[name="self"](%3941)
  %3944 : __torch__.torch.nn.modules.linear.___torch_mangle_8204.Linear = prim::GetAttr[name="value"](%3943)
  %3945 : __torch__.torch.nn.modules.linear.___torch_mangle_8203.Linear = prim::GetAttr[name="key"](%3943)
  %3946 : __torch__.torch.nn.modules.linear.___torch_mangle_8202.Linear = prim::GetAttr[name="query"](%3943)
  %3947 : Float(17:512, 1:512, 512:1) = aten::squeeze(%attention_mask, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:241:0
  %3948 : Float(17:512, 512:1) = aten::squeeze(%3947, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:241:0
  %is_index_masked.9 : Bool(17:512, 512:1) = aten::lt(%3948, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/tensor.py:22:0
  %input.103 : Float(512:768, 17:393216, 768:1) = aten::transpose(%hidden_states.89, %126, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:248:0
  %3951 : Tensor = prim::GetAttr[name="bias"](%3946)
  %3952 : Tensor = prim::GetAttr[name="weight"](%3946)
  %3953 : Float(768:1, 768:768) = aten::t(%3952), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %output.49 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.103, %3953), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %query_vectors.17 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.49, %3951, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.query # torch/nn/functional.py:1678:0
  %3956 : Tensor = prim::GetAttr[name="bias"](%3945)
  %3957 : Tensor = prim::GetAttr[name="weight"](%3945)
  %3958 : Float(768:1, 768:768) = aten::t(%3957), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %output.50 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.103, %3958), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %key_vectors.9 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.50, %3956, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.key # torch/nn/functional.py:1678:0
  %3961 : Tensor = prim::GetAttr[name="bias"](%3944)
  %3962 : Tensor = prim::GetAttr[name="weight"](%3944)
  %3963 : Float(768:1, 768:768) = aten::t(%3962), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %output.51 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.103, %3963), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %value_vectors.9 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.51, %3961, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.value # torch/nn/functional.py:1678:0
  %3966 : int = aten::size(%input.103, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:255:0
  %3967 : int = aten::size(%input.103, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:255:0
  %3968 : int = aten::size(%input.103, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:255:0
  %query_vectors.18 : Float(512:13056, 17:768, 768:1) = aten::div_(%query_vectors.17, %127), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:261:0
  %3970 : int[] = prim::ListConstruct(%3966, %3967, %128, %129), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %3971 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%query_vectors.18, %3970), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:263:0
  %query.17 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%3971, %126, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:263:0
  %3973 : int[] = prim::ListConstruct(%3966, %3967, %128, %129), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %3974 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%key_vectors.9, %3973), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:264:0
  %key.9 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%3974, %126, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:264:0
  %3976 : int = aten::size(%query.17, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.34 : Long() = prim::NumToTensor(%3976), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %3978 : int = aten::size(%query.17, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.35 : Long() = prim::NumToTensor(%3978), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %3980 : int = aten::size(%query.17, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.25 : Long() = prim::NumToTensor(%3980), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %3982 : int = aten::size(%query.17, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:472:0
  %3983 : Long() = aten::floor_divide(%seq_len.35, %131), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/tensor.py:424:0
  %chunks_count.25 : Long() = aten::sub(%3983, %132, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:478:0
  %3985 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%query.17, %125, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:481:0
  %3986 : Long() = aten::mul(%batch_size.34, %num_heads.25), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:481:0
  %3987 : int = aten::Int(%3986), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %3988 : int[] = prim::ListConstruct(%3987, %3978, %3982), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %hidden_states.90 : Float(204:64, 512:13056, 64:1) = aten::reshape(%3985, %3988), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:481:0
  %3990 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%key.9, %125, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:482:0
  %3991 : Long() = aten::mul(%batch_size.34, %num_heads.25), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:482:0
  %3992 : int = aten::Int(%3991), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %3993 : int[] = prim::ListConstruct(%3992, %3978, %3982), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %hidden_states.92 : Float(204:64, 512:13056, 64:1) = aten::reshape(%3990, %3993), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:482:0
  %3995 : int = aten::size(%hidden_states.90, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:442:0
  %3996 : int = aten::size(%hidden_states.90, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:443:0
  %3997 : Long() = prim::NumToTensor(%3996), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %3998 : Long() = aten::floor_divide(%3997, %133), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/tensor.py:424:0
  %3999 : int = aten::Int(%3998), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4000 : int = aten::size(%hidden_states.90, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:445:0
  %4001 : int[] = prim::ListConstruct(%3995, %3999, %134, %4000), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %hidden_states.91 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.90, %4001), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:441:0
  %4003 : int = aten::size(%hidden_states.91, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4004 : int = aten::size(%hidden_states.91, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4005 : Long() = prim::NumToTensor(%4004), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4006 : int = aten::size(%hidden_states.91, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4007 : int = aten::size(%hidden_states.91, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4008 : Long() = aten::mul(%4005, %135), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:450:0
  %4009 : Long() = aten::sub(%4008, %132, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:450:0
  %4010 : int = aten::Int(%4009), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4011 : int[] = prim::ListConstruct(%4003, %4010, %4006, %4007), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4012 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4013 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.91, %4011, %4012, %138), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:454:0
  %4014 : int = aten::size(%hidden_states.92, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:442:0
  %4015 : int = aten::size(%hidden_states.92, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:443:0
  %4016 : Long() = prim::NumToTensor(%4015), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4017 : Long() = aten::floor_divide(%4016, %133), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/tensor.py:424:0
  %4018 : int = aten::Int(%4017), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4019 : int = aten::size(%hidden_states.92, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:445:0
  %4020 : int[] = prim::ListConstruct(%4014, %4018, %134, %4019), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %hidden_states.93 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.92, %4020), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:441:0
  %4022 : int = aten::size(%hidden_states.93, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4023 : int = aten::size(%hidden_states.93, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4024 : Long() = prim::NumToTensor(%4023), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4025 : int = aten::size(%hidden_states.93, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4026 : int = aten::size(%hidden_states.93, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4027 : Long() = aten::mul(%4024, %135), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:450:0
  %4028 : Long() = aten::sub(%4027, %132, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:450:0
  %4029 : int = aten::Int(%4028), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4030 : int[] = prim::ListConstruct(%4022, %4029, %4025, %4026), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4031 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4032 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.93, %4030, %4031, %138), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:454:0
  %4033 : Tensor[] = prim::ListConstruct(%4013, %4032), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %input.104 : Float(204:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %4033), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/functional.py:327:0
  %4035 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %hidden_states_padded.17 : Float(204:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.104, %4035, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/nn/functional.py:3552:0
  %4037 : int = aten::size(%hidden_states_padded.17, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:401:0
  %4038 : int = aten::size(%hidden_states_padded.17, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:401:0
  %4039 : int = aten::size(%hidden_states_padded.17, %140), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:401:0
  %4040 : int = aten::size(%hidden_states_padded.17, %141), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:401:0
  %4041 : int[] = prim::ListConstruct(%4037, %4038, %4039, %4040), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %diagonal_chunked_attention_scores.17 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.17, %4041), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:400:0
  %4043 : Long() = aten::mul(%batch_size.34, %num_heads.25), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:504:0
  %4044 : int = aten::Int(%4043), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4045 : Long() = aten::add(%chunks_count.25, %132, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:504:0
  %4046 : int = aten::Int(%4045), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4047 : int[] = prim::ListConstruct(%4044, %4046, %142, %143), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %diagonal_attention_scores.17 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.17, %4047, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:503:0
  %4049 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.17, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4050 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%4049, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4051 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%4050, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4052 : Float(204:262656, 1:262656, 256:513, 257:1) = aten::slice(%4051, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4053 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.17, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4054 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%4053, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4055 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%4054, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4056 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::slice(%4055, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4057 : int[] = prim::ListConstruct(%149, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4058 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::view(%4052, %4057), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4059 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::copy_(%4056, %4058, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4060 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.17, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4061 : Float(204:262656, 512:513, 513:1) = aten::select(%4060, %125, %140), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4062 : Float(204:262656, 256:513, 513:1) = aten::slice(%4061, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4063 : Float(204:262656, 256:513, 257:1) = aten::slice(%4062, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4064 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.17, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4065 : Float(204:262656, 256:513, 513:1) = aten::select(%4064, %125, %140), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4066 : Float(204:262656, 256:513, 513:1) = aten::slice(%4065, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4067 : Float(204:262656, 256:513, 257:1) = aten::slice(%4066, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4068 : int[] = prim::ListConstruct(%149, %142, %148), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4069 : Float(204:262656, 256:513, 257:1) = aten::view(%4063, %4068), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4070 : Float(204:262656, 256:513, 257:1) = aten::copy_(%4067, %4069, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4071 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.17, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4072 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%4071, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4073 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%4072, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4074 : Float(204:262656, 1:262656, 256:513, 256:1) = aten::slice(%4073, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4075 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.17, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4076 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%4075, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4077 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%4076, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4078 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::slice(%4077, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4079 : int[] = prim::ListConstruct(%149, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4080 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::view(%4074, %4079), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4081 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::copy_(%4078, %4080, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4082 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.17, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4083 : Float(204:262656, 512:513, 513:1) = aten::select(%4082, %125, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4084 : Float(204:262656, 255:513, 513:1) = aten::slice(%4083, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4085 : Float(204:262656, 255:513, 255:1) = aten::slice(%4084, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4086 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.17, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4087 : Float(204:262656, 256:513, 513:1) = aten::select(%4086, %125, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4088 : Float(204:262656, 255:513, 513:1) = aten::slice(%4087, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4089 : Float(204:262656, 255:513, 255:1) = aten::slice(%4088, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4090 : int[] = prim::ListConstruct(%149, %151, %151), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4091 : Float(204:262656, 255:513, 255:1) = aten::view(%4085, %4090), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4092 : Float(204:262656, 255:513, 255:1) = aten::copy_(%4089, %4091, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4093 : int[] = prim::ListConstruct(%3976, %3980, %3978, %143), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4094 : Float(17:3151872, 12:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.17, %4093), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.25 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::transpose(%4094, %124, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:525:0
  %4096 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4097 : Float(256:257, 257:1) = aten::ones(%4096, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:458:0
  %4098 : Float(256:257, 257:1) = aten::tril(%4097, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:458:0
  %4099 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %beginning_mask_2d.17 : Float(256:257, 257:1) = aten::flip(%4098, %4099), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:458:0
  %4101 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.17, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:459:0
  %4102 : Float(1:65792, 256:257, 257:1) = aten::slice(%4101, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:459:0
  %4103 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%4102, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.17 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%4103, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:459:0
  %4105 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %ending_mask.17 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.17, %4105), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:460:0
  %4107 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.25, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:461:0
  %4108 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%4107, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:461:0
  %4109 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%4108, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.17 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%4109, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:461:0
  %4111 : int = aten::size(%beginning_input.17, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:462:0
  %4112 : int = aten::size(%beginning_input.17, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:462:0
  %4113 : int = aten::size(%beginning_input.17, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:462:0
  %4114 : int = aten::size(%beginning_input.17, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:462:0
  %4115 : int[] = prim::ListConstruct(%4111, %4112, %4113, %4114), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4116 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%beginning_mask.17, %4115, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:462:0
  %4117 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%4116, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/tensor.py:22:0
  %4118 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%beginning_input.17, %4117, %153), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:463:0
  %4119 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.25, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:464:0
  %4120 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%4119, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:464:0
  %4121 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%4120, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.17 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%4121, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:464:0
  %4123 : int = aten::size(%ending_input.17, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:465:0
  %4124 : int = aten::size(%ending_input.17, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:465:0
  %4125 : int = aten::size(%ending_input.17, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:465:0
  %4126 : int = aten::size(%ending_input.17, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:465:0
  %4127 : int[] = prim::ListConstruct(%4123, %4124, %4125, %4126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4128 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%ending_mask.17, %4127, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:465:0
  %4129 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%4128, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/tensor.py:22:0
  %4130 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%ending_input.17, %4129, %153), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:466:0
  %4131 : Bool(17:512, 512:1) = aten::ne(%3948, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/tensor.py:22:0
  %4132 : Bool(17:512, 512:1) = aten::slice(%4131, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:272:0
  %4133 : Bool(17:512, 512:1) = aten::slice(%4132, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:272:0
  %4134 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%4133, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:272:0
  %remove_from_windowed_attention_mask.9 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%4134, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:272:0
  %4136 : Float(17:512, 512:1, 1:1, 1:1) = aten::type_as(%remove_from_windowed_attention_mask.9, %query.17), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:275:0
  %float_mask.9 : Float(17:512, 512:1, 1:1, 1:1) = aten::masked_fill(%4136, %remove_from_windowed_attention_mask.9, %155), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:275:0
  %4138 : int = aten::size(%float_mask.9, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:280:0
  %4139 : int = aten::size(%float_mask.9, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:280:0
  %4140 : int = aten::size(%float_mask.9, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:280:0
  %4141 : int = aten::size(%float_mask.9, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:280:0
  %4142 : int[] = prim::ListConstruct(%4138, %4139, %4140, %4141), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %query.18 : Float(17:512, 512:1, 1:1, 1:1) = aten::ones(%4142, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:280:0
  %4144 : int = aten::size(%query.18, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.35 : Long() = prim::NumToTensor(%4144), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4146 : int = aten::size(%query.18, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.36 : Long() = prim::NumToTensor(%4146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4148 : int = aten::size(%query.18, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.26 : Long() = prim::NumToTensor(%4148), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4150 : int = aten::size(%query.18, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:472:0
  %4151 : Long() = aten::floor_divide(%seq_len.36, %131), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/tensor.py:424:0
  %chunks_count.26 : Long() = aten::sub(%4151, %132, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:478:0
  %4153 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%query.18, %125, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:481:0
  %4154 : Long() = aten::mul(%batch_size.35, %num_heads.26), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:481:0
  %4155 : int = aten::Int(%4154), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4156 : int[] = prim::ListConstruct(%4155, %4146, %4150), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %hidden_states.94 : Float(17:512, 512:1, 1:1) = aten::reshape(%4153, %4156), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:481:0
  %4158 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%float_mask.9, %125, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:482:0
  %4159 : Long() = aten::mul(%batch_size.35, %num_heads.26), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:482:0
  %4160 : int = aten::Int(%4159), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4161 : int[] = prim::ListConstruct(%4160, %4146, %4150), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %hidden_states.96 : Float(17:512, 512:1, 1:1) = aten::reshape(%4158, %4161), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:482:0
  %4163 : int = aten::size(%hidden_states.94, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:442:0
  %4164 : int = aten::size(%hidden_states.94, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:443:0
  %4165 : Long() = prim::NumToTensor(%4164), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4166 : Long() = aten::floor_divide(%4165, %133), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/tensor.py:424:0
  %4167 : int = aten::Int(%4166), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4168 : int = aten::size(%hidden_states.94, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:445:0
  %4169 : int[] = prim::ListConstruct(%4163, %4167, %134, %4168), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %hidden_states.95 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.94, %4169), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:441:0
  %4171 : int = aten::size(%hidden_states.95, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4172 : int = aten::size(%hidden_states.95, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4173 : Long() = prim::NumToTensor(%4172), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4174 : int = aten::size(%hidden_states.95, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4175 : int = aten::size(%hidden_states.95, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4176 : Long() = aten::mul(%4173, %135), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:450:0
  %4177 : Long() = aten::sub(%4176, %132, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:450:0
  %4178 : int = aten::Int(%4177), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4179 : int[] = prim::ListConstruct(%4171, %4178, %4174, %4175), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4180 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4181 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.95, %4179, %4180, %138), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:454:0
  %4182 : int = aten::size(%hidden_states.96, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:442:0
  %4183 : int = aten::size(%hidden_states.96, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:443:0
  %4184 : Long() = prim::NumToTensor(%4183), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4185 : Long() = aten::floor_divide(%4184, %133), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/tensor.py:424:0
  %4186 : int = aten::Int(%4185), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4187 : int = aten::size(%hidden_states.96, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:445:0
  %4188 : int[] = prim::ListConstruct(%4182, %4186, %134, %4187), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %hidden_states.97 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.96, %4188), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:441:0
  %4190 : int = aten::size(%hidden_states.97, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4191 : int = aten::size(%hidden_states.97, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4192 : Long() = prim::NumToTensor(%4191), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4193 : int = aten::size(%hidden_states.97, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4194 : int = aten::size(%hidden_states.97, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:449:0
  %4195 : Long() = aten::mul(%4192, %135), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:450:0
  %4196 : Long() = aten::sub(%4195, %132, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:450:0
  %4197 : int = aten::Int(%4196), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4198 : int[] = prim::ListConstruct(%4190, %4197, %4193, %4194), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4199 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4200 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.97, %4198, %4199, %138), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:454:0
  %4201 : Tensor[] = prim::ListConstruct(%4181, %4200), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %input.105 : Float(17:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %4201), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/functional.py:327:0
  %4203 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %hidden_states_padded.18 : Float(17:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.105, %4203, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/nn/functional.py:3552:0
  %4205 : int = aten::size(%hidden_states_padded.18, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:401:0
  %4206 : int = aten::size(%hidden_states_padded.18, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:401:0
  %4207 : int = aten::size(%hidden_states_padded.18, %140), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:401:0
  %4208 : int = aten::size(%hidden_states_padded.18, %141), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:401:0
  %4209 : int[] = prim::ListConstruct(%4205, %4206, %4207, %4208), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %diagonal_chunked_attention_scores.18 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.18, %4209), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:400:0
  %4211 : Long() = aten::mul(%batch_size.35, %num_heads.26), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:504:0
  %4212 : int = aten::Int(%4211), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4213 : Long() = aten::add(%chunks_count.26, %132, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:504:0
  %4214 : int = aten::Int(%4213), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4215 : int[] = prim::ListConstruct(%4212, %4214, %142, %143), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %diagonal_attention_scores.18 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.18, %4215, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:503:0
  %4217 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.18, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4218 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%4217, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4219 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%4218, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4220 : Float(17:262656, 1:262656, 256:513, 257:1) = aten::slice(%4219, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4221 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.18, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4222 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%4221, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4223 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%4222, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4224 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::slice(%4223, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4225 : int[] = prim::ListConstruct(%156, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4226 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::view(%4220, %4225), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4227 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::copy_(%4224, %4226, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:509:0
  %4228 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.18, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4229 : Float(17:262656, 512:513, 513:1) = aten::select(%4228, %125, %140), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4230 : Float(17:262656, 256:513, 513:1) = aten::slice(%4229, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4231 : Float(17:262656, 256:513, 257:1) = aten::slice(%4230, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4232 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.18, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4233 : Float(17:262656, 256:513, 513:1) = aten::select(%4232, %125, %140), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4234 : Float(17:262656, 256:513, 513:1) = aten::slice(%4233, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4235 : Float(17:262656, 256:513, 257:1) = aten::slice(%4234, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4236 : int[] = prim::ListConstruct(%156, %142, %148), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4237 : Float(17:262656, 256:513, 257:1) = aten::view(%4231, %4236), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4238 : Float(17:262656, 256:513, 257:1) = aten::copy_(%4235, %4237, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:512:0
  %4239 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.18, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4240 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%4239, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4241 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%4240, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4242 : Float(17:262656, 1:262656, 256:513, 256:1) = aten::slice(%4241, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4243 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.18, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4244 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%4243, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4245 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%4244, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4246 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::slice(%4245, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4247 : int[] = prim::ListConstruct(%156, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4248 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::view(%4242, %4247), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4249 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::copy_(%4246, %4248, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:516:0
  %4250 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.18, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4251 : Float(17:262656, 512:513, 513:1) = aten::select(%4250, %125, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4252 : Float(17:262656, 255:513, 513:1) = aten::slice(%4251, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4253 : Float(17:262656, 255:513, 255:1) = aten::slice(%4252, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4254 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.18, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4255 : Float(17:262656, 256:513, 513:1) = aten::select(%4254, %125, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4256 : Float(17:262656, 255:513, 513:1) = aten::slice(%4255, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4257 : Float(17:262656, 255:513, 255:1) = aten::slice(%4256, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4258 : int[] = prim::ListConstruct(%156, %151, %151), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4259 : Float(17:262656, 255:513, 255:1) = aten::view(%4253, %4258), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4260 : Float(17:262656, 255:513, 255:1) = aten::copy_(%4257, %4259, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:520:0
  %4261 : int[] = prim::ListConstruct(%4144, %4148, %4146, %143), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4262 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.18, %4261), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.26 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::transpose(%4262, %124, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:525:0
  %4264 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4265 : Float(256:257, 257:1) = aten::ones(%4264, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:458:0
  %4266 : Float(256:257, 257:1) = aten::tril(%4265, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:458:0
  %4267 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %beginning_mask_2d.18 : Float(256:257, 257:1) = aten::flip(%4266, %4267), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:458:0
  %4269 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.18, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:459:0
  %4270 : Float(1:65792, 256:257, 257:1) = aten::slice(%4269, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:459:0
  %4271 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%4270, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.18 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%4271, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:459:0
  %4273 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %ending_mask.18 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.18, %4273), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:460:0
  %4275 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.26, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:461:0
  %4276 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%4275, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:461:0
  %4277 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%4276, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.18 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%4277, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:461:0
  %4279 : int = aten::size(%beginning_input.18, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:462:0
  %4280 : int = aten::size(%beginning_input.18, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:462:0
  %4281 : int = aten::size(%beginning_input.18, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:462:0
  %4282 : int = aten::size(%beginning_input.18, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:462:0
  %4283 : int[] = prim::ListConstruct(%4279, %4280, %4281, %4282), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4284 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%beginning_mask.18, %4283, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:462:0
  %4285 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%4284, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/tensor.py:22:0
  %4286 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%beginning_input.18, %4285, %153), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:463:0
  %4287 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.26, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:464:0
  %4288 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%4287, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:464:0
  %4289 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%4288, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.18 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%4289, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:464:0
  %4291 : int = aten::size(%ending_input.18, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:465:0
  %4292 : int = aten::size(%ending_input.18, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:465:0
  %4293 : int = aten::size(%ending_input.18, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:465:0
  %4294 : int = aten::size(%ending_input.18, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:465:0
  %4295 : int[] = prim::ListConstruct(%4291, %4292, %4293, %4294), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4296 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%ending_mask.18, %4295, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:465:0
  %4297 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%4296, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/tensor.py:22:0
  %4298 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%ending_input.18, %4297, %153), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:466:0
  %attn_scores.9 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::add_(%input_tensor.25, %input_tensor.26, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:284:0
  %attn_probs_fp32.9 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::softmax(%attn_scores.9, %140, %144), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/nn/functional.py:1500:0
  %4301 : Bool(17:512, 512:1) = aten::slice(%is_index_masked.9, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:326:0
  %4302 : Bool(17:512, 512:1) = aten::slice(%4301, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:326:0
  %4303 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%4302, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:326:0
  %4304 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%4303, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:326:0
  %input.106 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::masked_fill(%attn_probs_fp32.9, %4304, %157), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:326:0
  %attn_probs.18 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::dropout(%input.106, %158, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/nn/functional.py:973:0
  %4307 : int[] = prim::ListConstruct(%3966, %3967, %128, %129), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4308 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%value_vectors.9, %4307), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:331:0
  %value.9 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%4308, %126, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:331:0
  %4310 : int = aten::size(%value.9, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:537:0
  %batch_size.36 : Long() = prim::NumToTensor(%4310), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4312 : int = aten::size(%value.9, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:537:0
  %seq_len.37 : Long() = prim::NumToTensor(%4312), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4314 : int = aten::size(%value.9, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:537:0
  %num_heads.27 : Long() = prim::NumToTensor(%4314), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4316 : int = aten::size(%value.9, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:537:0
  %4317 : Long() = aten::floor_divide(%seq_len.37, %131), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/tensor.py:424:0
  %chunks_count.27 : Long() = aten::sub(%4317, %132, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:542:0
  %4319 : Float(17:3151872, 12:513, 512:6156, 513:1) = aten::transpose(%attn_probs.18, %125, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:545:0
  %4320 : Long() = aten::mul(%batch_size.36, %num_heads.27), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:546:0
  %4321 : int = aten::Int(%4320), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4322 : Long() = aten::floor_divide(%seq_len.37, %131), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/tensor.py:424:0
  %4323 : int = aten::Int(%4322), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4324 : int[] = prim::ListConstruct(%4321, %4323, %142, %143), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %chunked_hidden_states.41 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::reshape(%4319, %4324), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:545:0
  %4326 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%value.9, %125, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:550:0
  %4327 : Long() = aten::mul(%batch_size.36, %num_heads.27), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:550:0
  %4328 : int = aten::Int(%4327), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4329 : int[] = prim::ListConstruct(%4328, %4312, %4316), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %input.107 : Float(204:64, 512:13056, 64:1) = aten::reshape(%4326, %4329), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:550:0
  %4331 : int[] = prim::ListConstruct(%126, %126, %142, %142), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %padded_value.9 : Float(204:65536, 1024:64, 64:1) = aten::constant_pad_nd(%input.107, %4331, %140), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/nn/functional.py:3552:0
  %4333 : Long() = aten::mul(%batch_size.36, %num_heads.27), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:556:0
  %4334 : int = aten::Int(%4333), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4335 : Long() = aten::add(%chunks_count.27, %132, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:556:0
  %4336 : int = aten::Int(%4335), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4337 : int[] = prim::ListConstruct(%4334, %4336, %159, %4316), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4338 : int[] = prim::ListConstruct(%160, %161, %129, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4339 : Float(204:65536, 2:16384, 768:64, 64:1) = aten::as_strided(%padded_value.9, %4337, %4338, %138), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:564:0
  %4340 : int = aten::size(%chunked_hidden_states.41, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:420:0
  %4341 : int = aten::size(%chunked_hidden_states.41, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:420:0
  %4342 : int = aten::size(%chunked_hidden_states.41, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:420:0
  %window_overlap.9 : Long() = prim::NumToTensor(%4342), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4344 : int = aten::size(%chunked_hidden_states.41, %130), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:420:0
  %hidden_dim.9 : Long() = prim::NumToTensor(%4344), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4346 : Long() = aten::add(%window_overlap.9, %132, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:422:0
  %4347 : int = aten::Int(%4346), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4348 : int[] = prim::ListConstruct(%126, %4347), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %chunked_hidden_states.42 : Float(204:394240, 2:197120, 256:770, 770:1) = aten::constant_pad_nd(%chunked_hidden_states.41, %4348, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/nn/functional.py:3552:0
  %4350 : int[] = prim::ListConstruct(%4340, %4341, %140), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %chunked_hidden_states.43 : Float(204:394240, 2:197120, 197120:1) = aten::view(%chunked_hidden_states.42, %4350), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:424:0
  %4352 : Long() = aten::neg(%window_overlap.9), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:428:0
  %4353 : int = aten::Int(%4352), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4354 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%chunked_hidden_states.43, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:427:0
  %4355 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%4354, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:427:0
  %chunked_hidden_states.44 : Float(204:394240, 2:197120, 196864:1) = aten::slice(%4355, %124, %126, %4353, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:427:0
  %4357 : Long() = aten::add(%window_overlap.9, %hidden_dim.9, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:431:0
  %4358 : int = aten::Int(%4357), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4359 : int[] = prim::ListConstruct(%4340, %4341, %4342, %4358), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %chunked_hidden_states.45 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::view(%chunked_hidden_states.44, %4359), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:430:0
  %4361 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%chunked_hidden_states.45, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:433:0
  %4362 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%4361, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:433:0
  %4363 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%4362, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:433:0
  %4364 : Float(204:394240, 2:197120, 256:769, 768:1) = aten::slice(%4363, %130, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:433:0
  %4365 : Tensor[] = prim::ListConstruct(%4364, %4339), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %context.9 : Float(204:32768, 2:16384, 256:64, 64:1) = aten::einsum(%162, %4365), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/functional.py:327:0
  %4367 : int[] = prim::ListConstruct(%4310, %4314, %4312, %4316), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4368 : Float(17:393216, 12:32768, 512:64, 64:1) = aten::view(%context.9, %4367), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:569:0
  %attn_output.17 : Float(17:393216, 512:64, 12:32768, 64:1) = aten::transpose(%4368, %125, %124), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:569:0
  %4370 : Float(512:64, 17:393216, 12:32768, 64:1) = aten::transpose(%attn_output.17, %126, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:350:0
  %4371 : int[] = prim::ListConstruct(%3966, %3967, %3968), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %4372 : Float(512:13056, 17:768, 768:1) = aten::reshape(%4370, %4371), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:350:0
  %attn_output.18 : Float(512:13056, 17:768, 768:1) = aten::contiguous(%4372, %126), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:350:0
  %input.108 : Float(17:768, 512:13056, 768:1) = aten::transpose(%attn_output.18, %126, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_longformer.py:374:0
  %4375 : __torch__.torch.nn.modules.normalization.___torch_mangle_8210.LayerNorm = prim::GetAttr[name="LayerNorm"](%3942)
  %4376 : __torch__.torch.nn.modules.linear.___torch_mangle_8209.Linear = prim::GetAttr[name="dense"](%3942)
  %4377 : Tensor = prim::GetAttr[name="bias"](%4376)
  %4378 : Tensor = prim::GetAttr[name="weight"](%4376)
  %4379 : Float(768:1, 768:768) = aten::t(%4378), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %output.52 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.108, %4379), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %input.109 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.52, %4377, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.98 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.109, %158, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.dropout # torch/nn/functional.py:973:0
  %input.110 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.98, %hidden_states.89, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output # transformers/modeling_longformer.py:758:0
  %4384 : Tensor = prim::GetAttr[name="bias"](%4375)
  %4385 : Tensor = prim::GetAttr[name="weight"](%4375)
  %4386 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.LayerNorm
  %input_tensor.27 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.110, %4386, %4385, %4384, %123, %122), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %4388 : __torch__.torch.nn.modules.linear.___torch_mangle_8214.Linear = prim::GetAttr[name="dense"](%3940)
  %4389 : Tensor = prim::GetAttr[name="bias"](%4388)
  %4390 : Tensor = prim::GetAttr[name="weight"](%4388)
  %4391 : Float(768:1, 3072:768) = aten::t(%4390), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.intermediate/__module.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %output.53 : Float(17:1572864, 512:3072, 3072:1) = aten::matmul(%input_tensor.27, %4391), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.intermediate/__module.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %input.111 : Float(17:1572864, 512:3072, 3072:1) = aten::add_(%output.53, %4389, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.intermediate/__module.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1678:0
  %input.112 : Float(17:1572864, 512:3072, 3072:1) = aten::gelu(%input.111), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.intermediate # torch/nn/functional.py:1369:0
  %4395 : __torch__.torch.nn.modules.normalization.___torch_mangle_8217.LayerNorm = prim::GetAttr[name="LayerNorm"](%3939)
  %4396 : __torch__.torch.nn.modules.linear.___torch_mangle_8216.Linear = prim::GetAttr[name="dense"](%3939)
  %4397 : Tensor = prim::GetAttr[name="bias"](%4396)
  %4398 : Tensor = prim::GetAttr[name="weight"](%4396)
  %4399 : Float(3072:1, 768:3072) = aten::t(%4398), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %output.54 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.112, %4399), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %input.113 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.54, %4397, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.99 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.113, %158, %146), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.dropout # torch/nn/functional.py:973:0
  %input.114 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.99, %input_tensor.27, %125), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output # transformers/modeling_longformer.py:830:0
  %4404 : Tensor = prim::GetAttr[name="bias"](%4395)
  %4405 : Tensor = prim::GetAttr[name="weight"](%4395)
  %4406 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.LayerNorm
  %hidden_states.100 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.114, %4406, %4405, %4404, %123, %122), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.LayerNorm # torch/nn/functional.py:2048:0
  %4408 : __torch__.transformers.modeling_longformer.___torch_mangle_8238.LongformerOutput = prim::GetAttr[name="output"](%168)
  %4409 : __torch__.transformers.modeling_longformer.___torch_mangle_8234.LongformerIntermediate = prim::GetAttr[name="intermediate"](%168)
  %4410 : __torch__.transformers.modeling_longformer.___torch_mangle_8232.LongformerAttention = prim::GetAttr[name="attention"](%168)
  %4411 : __torch__.transformers.modeling_longformer.___torch_mangle_8231.LongformerSelfOutput = prim::GetAttr[name="output"](%4410)
  %4412 : __torch__.transformers.modeling_longformer.___torch_mangle_8227.LongformerSelfAttention = prim::GetAttr[name="self"](%4410)
  %4413 : __torch__.torch.nn.modules.linear.___torch_mangle_8223.Linear = prim::GetAttr[name="value"](%4412)
  %4414 : __torch__.torch.nn.modules.linear.___torch_mangle_8222.Linear = prim::GetAttr[name="key"](%4412)
  %4415 : __torch__.torch.nn.modules.linear.___torch_mangle_8221.Linear = prim::GetAttr[name="query"](%4412)
  %4416 : Float(17:512, 1:512, 512:1) = aten::squeeze(%attention_mask, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:241:0
  %4417 : Float(17:512, 512:1) = aten::squeeze(%4416, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:241:0
  %is_index_masked.10 : Bool(17:512, 512:1) = aten::lt(%4417, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/tensor.py:22:0
  %input.115 : Float(512:768, 17:393216, 768:1) = aten::transpose(%hidden_states.100, %126, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:248:0
  %4420 : Tensor = prim::GetAttr[name="bias"](%4415)
  %4421 : Tensor = prim::GetAttr[name="weight"](%4415)
  %4422 : Float(768:1, 768:768) = aten::t(%4421), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %output.55 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.115, %4422), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %query_vectors.19 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.55, %4420, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.query # torch/nn/functional.py:1678:0
  %4425 : Tensor = prim::GetAttr[name="bias"](%4414)
  %4426 : Tensor = prim::GetAttr[name="weight"](%4414)
  %4427 : Float(768:1, 768:768) = aten::t(%4426), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %output.56 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.115, %4427), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %key_vectors.10 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.56, %4425, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.key # torch/nn/functional.py:1678:0
  %4430 : Tensor = prim::GetAttr[name="bias"](%4413)
  %4431 : Tensor = prim::GetAttr[name="weight"](%4413)
  %4432 : Float(768:1, 768:768) = aten::t(%4431), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %output.57 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.115, %4432), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %value_vectors.10 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.57, %4430, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.value # torch/nn/functional.py:1678:0
  %4435 : int = aten::size(%input.115, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:255:0
  %4436 : int = aten::size(%input.115, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:255:0
  %4437 : int = aten::size(%input.115, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:255:0
  %query_vectors.20 : Float(512:13056, 17:768, 768:1) = aten::div_(%query_vectors.19, %127), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:261:0
  %4439 : int[] = prim::ListConstruct(%4435, %4436, %128, %129), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4440 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%query_vectors.20, %4439), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:263:0
  %query.19 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%4440, %126, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:263:0
  %4442 : int[] = prim::ListConstruct(%4435, %4436, %128, %129), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4443 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%key_vectors.10, %4442), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:264:0
  %key.10 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%4443, %126, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:264:0
  %4445 : int = aten::size(%query.19, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.38 : Long() = prim::NumToTensor(%4445), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4447 : int = aten::size(%query.19, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.39 : Long() = prim::NumToTensor(%4447), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4449 : int = aten::size(%query.19, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.28 : Long() = prim::NumToTensor(%4449), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4451 : int = aten::size(%query.19, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:472:0
  %4452 : Long() = aten::floor_divide(%seq_len.39, %131), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/tensor.py:424:0
  %chunks_count.28 : Long() = aten::sub(%4452, %132, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:478:0
  %4454 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%query.19, %125, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:481:0
  %4455 : Long() = aten::mul(%batch_size.38, %num_heads.28), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:481:0
  %4456 : int = aten::Int(%4455), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4457 : int[] = prim::ListConstruct(%4456, %4447, %4451), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %hidden_states.101 : Float(204:64, 512:13056, 64:1) = aten::reshape(%4454, %4457), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:481:0
  %4459 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%key.10, %125, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:482:0
  %4460 : Long() = aten::mul(%batch_size.38, %num_heads.28), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:482:0
  %4461 : int = aten::Int(%4460), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4462 : int[] = prim::ListConstruct(%4461, %4447, %4451), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %hidden_states.103 : Float(204:64, 512:13056, 64:1) = aten::reshape(%4459, %4462), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:482:0
  %4464 : int = aten::size(%hidden_states.101, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:442:0
  %4465 : int = aten::size(%hidden_states.101, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:443:0
  %4466 : Long() = prim::NumToTensor(%4465), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4467 : Long() = aten::floor_divide(%4466, %133), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/tensor.py:424:0
  %4468 : int = aten::Int(%4467), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4469 : int = aten::size(%hidden_states.101, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:445:0
  %4470 : int[] = prim::ListConstruct(%4464, %4468, %134, %4469), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %hidden_states.102 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.101, %4470), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:441:0
  %4472 : int = aten::size(%hidden_states.102, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4473 : int = aten::size(%hidden_states.102, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4474 : Long() = prim::NumToTensor(%4473), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4475 : int = aten::size(%hidden_states.102, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4476 : int = aten::size(%hidden_states.102, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4477 : Long() = aten::mul(%4474, %135), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:450:0
  %4478 : Long() = aten::sub(%4477, %132, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:450:0
  %4479 : int = aten::Int(%4478), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4480 : int[] = prim::ListConstruct(%4472, %4479, %4475, %4476), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4481 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4482 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.102, %4480, %4481, %138), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:454:0
  %4483 : int = aten::size(%hidden_states.103, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:442:0
  %4484 : int = aten::size(%hidden_states.103, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:443:0
  %4485 : Long() = prim::NumToTensor(%4484), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4486 : Long() = aten::floor_divide(%4485, %133), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/tensor.py:424:0
  %4487 : int = aten::Int(%4486), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4488 : int = aten::size(%hidden_states.103, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:445:0
  %4489 : int[] = prim::ListConstruct(%4483, %4487, %134, %4488), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %hidden_states.104 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.103, %4489), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:441:0
  %4491 : int = aten::size(%hidden_states.104, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4492 : int = aten::size(%hidden_states.104, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4493 : Long() = prim::NumToTensor(%4492), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4494 : int = aten::size(%hidden_states.104, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4495 : int = aten::size(%hidden_states.104, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4496 : Long() = aten::mul(%4493, %135), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:450:0
  %4497 : Long() = aten::sub(%4496, %132, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:450:0
  %4498 : int = aten::Int(%4497), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4499 : int[] = prim::ListConstruct(%4491, %4498, %4494, %4495), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4500 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4501 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.104, %4499, %4500, %138), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:454:0
  %4502 : Tensor[] = prim::ListConstruct(%4482, %4501), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %input.116 : Float(204:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %4502), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/functional.py:327:0
  %4504 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %hidden_states_padded.19 : Float(204:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.116, %4504, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/nn/functional.py:3552:0
  %4506 : int = aten::size(%hidden_states_padded.19, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:401:0
  %4507 : int = aten::size(%hidden_states_padded.19, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:401:0
  %4508 : int = aten::size(%hidden_states_padded.19, %140), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:401:0
  %4509 : int = aten::size(%hidden_states_padded.19, %141), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:401:0
  %4510 : int[] = prim::ListConstruct(%4506, %4507, %4508, %4509), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %diagonal_chunked_attention_scores.19 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.19, %4510), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:400:0
  %4512 : Long() = aten::mul(%batch_size.38, %num_heads.28), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:504:0
  %4513 : int = aten::Int(%4512), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4514 : Long() = aten::add(%chunks_count.28, %132, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:504:0
  %4515 : int = aten::Int(%4514), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4516 : int[] = prim::ListConstruct(%4513, %4515, %142, %143), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %diagonal_attention_scores.19 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.19, %4516, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:503:0
  %4518 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.19, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4519 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%4518, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4520 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%4519, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4521 : Float(204:262656, 1:262656, 256:513, 257:1) = aten::slice(%4520, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4522 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.19, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4523 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%4522, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4524 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%4523, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4525 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::slice(%4524, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4526 : int[] = prim::ListConstruct(%149, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4527 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::view(%4521, %4526), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4528 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::copy_(%4525, %4527, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4529 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.19, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4530 : Float(204:262656, 512:513, 513:1) = aten::select(%4529, %125, %140), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4531 : Float(204:262656, 256:513, 513:1) = aten::slice(%4530, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4532 : Float(204:262656, 256:513, 257:1) = aten::slice(%4531, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4533 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.19, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4534 : Float(204:262656, 256:513, 513:1) = aten::select(%4533, %125, %140), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4535 : Float(204:262656, 256:513, 513:1) = aten::slice(%4534, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4536 : Float(204:262656, 256:513, 257:1) = aten::slice(%4535, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4537 : int[] = prim::ListConstruct(%149, %142, %148), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4538 : Float(204:262656, 256:513, 257:1) = aten::view(%4532, %4537), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4539 : Float(204:262656, 256:513, 257:1) = aten::copy_(%4536, %4538, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4540 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.19, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4541 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%4540, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4542 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%4541, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4543 : Float(204:262656, 1:262656, 256:513, 256:1) = aten::slice(%4542, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4544 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.19, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4545 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%4544, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4546 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%4545, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4547 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::slice(%4546, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4548 : int[] = prim::ListConstruct(%149, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4549 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::view(%4543, %4548), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4550 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::copy_(%4547, %4549, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4551 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.19, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4552 : Float(204:262656, 512:513, 513:1) = aten::select(%4551, %125, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4553 : Float(204:262656, 255:513, 513:1) = aten::slice(%4552, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4554 : Float(204:262656, 255:513, 255:1) = aten::slice(%4553, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4555 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.19, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4556 : Float(204:262656, 256:513, 513:1) = aten::select(%4555, %125, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4557 : Float(204:262656, 255:513, 513:1) = aten::slice(%4556, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4558 : Float(204:262656, 255:513, 255:1) = aten::slice(%4557, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4559 : int[] = prim::ListConstruct(%149, %151, %151), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4560 : Float(204:262656, 255:513, 255:1) = aten::view(%4554, %4559), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4561 : Float(204:262656, 255:513, 255:1) = aten::copy_(%4558, %4560, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4562 : int[] = prim::ListConstruct(%4445, %4449, %4447, %143), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4563 : Float(17:3151872, 12:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.19, %4562), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.28 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::transpose(%4563, %124, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:525:0
  %4565 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4566 : Float(256:257, 257:1) = aten::ones(%4565, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:458:0
  %4567 : Float(256:257, 257:1) = aten::tril(%4566, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:458:0
  %4568 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %beginning_mask_2d.19 : Float(256:257, 257:1) = aten::flip(%4567, %4568), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:458:0
  %4570 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.19, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:459:0
  %4571 : Float(1:65792, 256:257, 257:1) = aten::slice(%4570, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:459:0
  %4572 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%4571, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.19 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%4572, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:459:0
  %4574 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %ending_mask.19 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.19, %4574), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:460:0
  %4576 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.28, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:461:0
  %4577 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%4576, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:461:0
  %4578 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%4577, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.19 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%4578, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:461:0
  %4580 : int = aten::size(%beginning_input.19, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:462:0
  %4581 : int = aten::size(%beginning_input.19, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:462:0
  %4582 : int = aten::size(%beginning_input.19, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:462:0
  %4583 : int = aten::size(%beginning_input.19, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:462:0
  %4584 : int[] = prim::ListConstruct(%4580, %4581, %4582, %4583), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4585 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%beginning_mask.19, %4584, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:462:0
  %4586 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%4585, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/tensor.py:22:0
  %4587 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%beginning_input.19, %4586, %153), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:463:0
  %4588 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.28, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:464:0
  %4589 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%4588, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:464:0
  %4590 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%4589, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.19 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%4590, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:464:0
  %4592 : int = aten::size(%ending_input.19, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:465:0
  %4593 : int = aten::size(%ending_input.19, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:465:0
  %4594 : int = aten::size(%ending_input.19, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:465:0
  %4595 : int = aten::size(%ending_input.19, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:465:0
  %4596 : int[] = prim::ListConstruct(%4592, %4593, %4594, %4595), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4597 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%ending_mask.19, %4596, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:465:0
  %4598 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%4597, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/tensor.py:22:0
  %4599 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%ending_input.19, %4598, %153), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:466:0
  %4600 : Bool(17:512, 512:1) = aten::ne(%4417, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/tensor.py:22:0
  %4601 : Bool(17:512, 512:1) = aten::slice(%4600, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:272:0
  %4602 : Bool(17:512, 512:1) = aten::slice(%4601, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:272:0
  %4603 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%4602, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:272:0
  %remove_from_windowed_attention_mask.10 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%4603, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:272:0
  %4605 : Float(17:512, 512:1, 1:1, 1:1) = aten::type_as(%remove_from_windowed_attention_mask.10, %query.19), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:275:0
  %float_mask.10 : Float(17:512, 512:1, 1:1, 1:1) = aten::masked_fill(%4605, %remove_from_windowed_attention_mask.10, %155), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:275:0
  %4607 : int = aten::size(%float_mask.10, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:280:0
  %4608 : int = aten::size(%float_mask.10, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:280:0
  %4609 : int = aten::size(%float_mask.10, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:280:0
  %4610 : int = aten::size(%float_mask.10, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:280:0
  %4611 : int[] = prim::ListConstruct(%4607, %4608, %4609, %4610), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %query.20 : Float(17:512, 512:1, 1:1, 1:1) = aten::ones(%4611, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:280:0
  %4613 : int = aten::size(%query.20, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.39 : Long() = prim::NumToTensor(%4613), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4615 : int = aten::size(%query.20, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.40 : Long() = prim::NumToTensor(%4615), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4617 : int = aten::size(%query.20, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.29 : Long() = prim::NumToTensor(%4617), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4619 : int = aten::size(%query.20, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:472:0
  %4620 : Long() = aten::floor_divide(%seq_len.40, %131), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/tensor.py:424:0
  %chunks_count.29 : Long() = aten::sub(%4620, %132, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:478:0
  %4622 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%query.20, %125, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:481:0
  %4623 : Long() = aten::mul(%batch_size.39, %num_heads.29), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:481:0
  %4624 : int = aten::Int(%4623), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4625 : int[] = prim::ListConstruct(%4624, %4615, %4619), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %hidden_states.105 : Float(17:512, 512:1, 1:1) = aten::reshape(%4622, %4625), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:481:0
  %4627 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%float_mask.10, %125, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:482:0
  %4628 : Long() = aten::mul(%batch_size.39, %num_heads.29), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:482:0
  %4629 : int = aten::Int(%4628), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4630 : int[] = prim::ListConstruct(%4629, %4615, %4619), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %hidden_states.107 : Float(17:512, 512:1, 1:1) = aten::reshape(%4627, %4630), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:482:0
  %4632 : int = aten::size(%hidden_states.105, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:442:0
  %4633 : int = aten::size(%hidden_states.105, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:443:0
  %4634 : Long() = prim::NumToTensor(%4633), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4635 : Long() = aten::floor_divide(%4634, %133), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/tensor.py:424:0
  %4636 : int = aten::Int(%4635), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4637 : int = aten::size(%hidden_states.105, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:445:0
  %4638 : int[] = prim::ListConstruct(%4632, %4636, %134, %4637), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %hidden_states.106 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.105, %4638), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:441:0
  %4640 : int = aten::size(%hidden_states.106, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4641 : int = aten::size(%hidden_states.106, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4642 : Long() = prim::NumToTensor(%4641), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4643 : int = aten::size(%hidden_states.106, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4644 : int = aten::size(%hidden_states.106, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4645 : Long() = aten::mul(%4642, %135), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:450:0
  %4646 : Long() = aten::sub(%4645, %132, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:450:0
  %4647 : int = aten::Int(%4646), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4648 : int[] = prim::ListConstruct(%4640, %4647, %4643, %4644), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4649 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4650 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.106, %4648, %4649, %138), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:454:0
  %4651 : int = aten::size(%hidden_states.107, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:442:0
  %4652 : int = aten::size(%hidden_states.107, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:443:0
  %4653 : Long() = prim::NumToTensor(%4652), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4654 : Long() = aten::floor_divide(%4653, %133), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/tensor.py:424:0
  %4655 : int = aten::Int(%4654), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4656 : int = aten::size(%hidden_states.107, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:445:0
  %4657 : int[] = prim::ListConstruct(%4651, %4655, %134, %4656), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %hidden_states.108 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.107, %4657), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:441:0
  %4659 : int = aten::size(%hidden_states.108, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4660 : int = aten::size(%hidden_states.108, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4661 : Long() = prim::NumToTensor(%4660), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4662 : int = aten::size(%hidden_states.108, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4663 : int = aten::size(%hidden_states.108, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:449:0
  %4664 : Long() = aten::mul(%4661, %135), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:450:0
  %4665 : Long() = aten::sub(%4664, %132, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:450:0
  %4666 : int = aten::Int(%4665), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4667 : int[] = prim::ListConstruct(%4659, %4666, %4662, %4663), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4668 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4669 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.108, %4667, %4668, %138), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:454:0
  %4670 : Tensor[] = prim::ListConstruct(%4650, %4669), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %input.117 : Float(17:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %4670), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/functional.py:327:0
  %4672 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %hidden_states_padded.20 : Float(17:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.117, %4672, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/nn/functional.py:3552:0
  %4674 : int = aten::size(%hidden_states_padded.20, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:401:0
  %4675 : int = aten::size(%hidden_states_padded.20, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:401:0
  %4676 : int = aten::size(%hidden_states_padded.20, %140), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:401:0
  %4677 : int = aten::size(%hidden_states_padded.20, %141), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:401:0
  %4678 : int[] = prim::ListConstruct(%4674, %4675, %4676, %4677), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %diagonal_chunked_attention_scores.20 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.20, %4678), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:400:0
  %4680 : Long() = aten::mul(%batch_size.39, %num_heads.29), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:504:0
  %4681 : int = aten::Int(%4680), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4682 : Long() = aten::add(%chunks_count.29, %132, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:504:0
  %4683 : int = aten::Int(%4682), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4684 : int[] = prim::ListConstruct(%4681, %4683, %142, %143), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %diagonal_attention_scores.20 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.20, %4684, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:503:0
  %4686 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.20, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4687 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%4686, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4688 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%4687, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4689 : Float(17:262656, 1:262656, 256:513, 257:1) = aten::slice(%4688, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4690 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.20, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4691 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%4690, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4692 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%4691, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4693 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::slice(%4692, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4694 : int[] = prim::ListConstruct(%156, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4695 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::view(%4689, %4694), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4696 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::copy_(%4693, %4695, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:509:0
  %4697 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.20, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4698 : Float(17:262656, 512:513, 513:1) = aten::select(%4697, %125, %140), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4699 : Float(17:262656, 256:513, 513:1) = aten::slice(%4698, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4700 : Float(17:262656, 256:513, 257:1) = aten::slice(%4699, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4701 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.20, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4702 : Float(17:262656, 256:513, 513:1) = aten::select(%4701, %125, %140), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4703 : Float(17:262656, 256:513, 513:1) = aten::slice(%4702, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4704 : Float(17:262656, 256:513, 257:1) = aten::slice(%4703, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4705 : int[] = prim::ListConstruct(%156, %142, %148), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4706 : Float(17:262656, 256:513, 257:1) = aten::view(%4700, %4705), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4707 : Float(17:262656, 256:513, 257:1) = aten::copy_(%4704, %4706, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:512:0
  %4708 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.20, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4709 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%4708, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4710 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%4709, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4711 : Float(17:262656, 1:262656, 256:513, 256:1) = aten::slice(%4710, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4712 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.20, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4713 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%4712, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4714 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%4713, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4715 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::slice(%4714, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4716 : int[] = prim::ListConstruct(%156, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4717 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::view(%4711, %4716), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4718 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::copy_(%4715, %4717, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:516:0
  %4719 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.20, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4720 : Float(17:262656, 512:513, 513:1) = aten::select(%4719, %125, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4721 : Float(17:262656, 255:513, 513:1) = aten::slice(%4720, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4722 : Float(17:262656, 255:513, 255:1) = aten::slice(%4721, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4723 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.20, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4724 : Float(17:262656, 256:513, 513:1) = aten::select(%4723, %125, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4725 : Float(17:262656, 255:513, 513:1) = aten::slice(%4724, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4726 : Float(17:262656, 255:513, 255:1) = aten::slice(%4725, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4727 : int[] = prim::ListConstruct(%156, %151, %151), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4728 : Float(17:262656, 255:513, 255:1) = aten::view(%4722, %4727), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4729 : Float(17:262656, 255:513, 255:1) = aten::copy_(%4726, %4728, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:520:0
  %4730 : int[] = prim::ListConstruct(%4613, %4617, %4615, %143), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4731 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.20, %4730), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.29 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::transpose(%4731, %124, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:525:0
  %4733 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4734 : Float(256:257, 257:1) = aten::ones(%4733, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:458:0
  %4735 : Float(256:257, 257:1) = aten::tril(%4734, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:458:0
  %4736 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %beginning_mask_2d.20 : Float(256:257, 257:1) = aten::flip(%4735, %4736), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:458:0
  %4738 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.20, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:459:0
  %4739 : Float(1:65792, 256:257, 257:1) = aten::slice(%4738, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:459:0
  %4740 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%4739, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.20 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%4740, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:459:0
  %4742 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %ending_mask.20 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.20, %4742), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:460:0
  %4744 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.29, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:461:0
  %4745 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%4744, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:461:0
  %4746 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%4745, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.20 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%4746, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:461:0
  %4748 : int = aten::size(%beginning_input.20, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:462:0
  %4749 : int = aten::size(%beginning_input.20, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:462:0
  %4750 : int = aten::size(%beginning_input.20, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:462:0
  %4751 : int = aten::size(%beginning_input.20, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:462:0
  %4752 : int[] = prim::ListConstruct(%4748, %4749, %4750, %4751), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4753 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%beginning_mask.20, %4752, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:462:0
  %4754 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%4753, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/tensor.py:22:0
  %4755 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%beginning_input.20, %4754, %153), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:463:0
  %4756 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.29, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:464:0
  %4757 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%4756, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:464:0
  %4758 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%4757, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.20 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%4758, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:464:0
  %4760 : int = aten::size(%ending_input.20, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:465:0
  %4761 : int = aten::size(%ending_input.20, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:465:0
  %4762 : int = aten::size(%ending_input.20, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:465:0
  %4763 : int = aten::size(%ending_input.20, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:465:0
  %4764 : int[] = prim::ListConstruct(%4760, %4761, %4762, %4763), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4765 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%ending_mask.20, %4764, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:465:0
  %4766 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%4765, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/tensor.py:22:0
  %4767 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%ending_input.20, %4766, %153), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:466:0
  %attn_scores.10 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::add_(%input_tensor.28, %input_tensor.29, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:284:0
  %attn_probs_fp32.10 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::softmax(%attn_scores.10, %140, %144), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/nn/functional.py:1500:0
  %4770 : Bool(17:512, 512:1) = aten::slice(%is_index_masked.10, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:326:0
  %4771 : Bool(17:512, 512:1) = aten::slice(%4770, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:326:0
  %4772 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%4771, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:326:0
  %4773 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%4772, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:326:0
  %input.118 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::masked_fill(%attn_probs_fp32.10, %4773, %157), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:326:0
  %attn_probs.20 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::dropout(%input.118, %158, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/nn/functional.py:973:0
  %4776 : int[] = prim::ListConstruct(%4435, %4436, %128, %129), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4777 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%value_vectors.10, %4776), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:331:0
  %value.10 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%4777, %126, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:331:0
  %4779 : int = aten::size(%value.10, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:537:0
  %batch_size.40 : Long() = prim::NumToTensor(%4779), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4781 : int = aten::size(%value.10, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:537:0
  %seq_len.41 : Long() = prim::NumToTensor(%4781), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4783 : int = aten::size(%value.10, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:537:0
  %num_heads.30 : Long() = prim::NumToTensor(%4783), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4785 : int = aten::size(%value.10, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:537:0
  %4786 : Long() = aten::floor_divide(%seq_len.41, %131), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/tensor.py:424:0
  %chunks_count.30 : Long() = aten::sub(%4786, %132, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:542:0
  %4788 : Float(17:3151872, 12:513, 512:6156, 513:1) = aten::transpose(%attn_probs.20, %125, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:545:0
  %4789 : Long() = aten::mul(%batch_size.40, %num_heads.30), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:546:0
  %4790 : int = aten::Int(%4789), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4791 : Long() = aten::floor_divide(%seq_len.41, %131), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/tensor.py:424:0
  %4792 : int = aten::Int(%4791), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4793 : int[] = prim::ListConstruct(%4790, %4792, %142, %143), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %chunked_hidden_states.46 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::reshape(%4788, %4793), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:545:0
  %4795 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%value.10, %125, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:550:0
  %4796 : Long() = aten::mul(%batch_size.40, %num_heads.30), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:550:0
  %4797 : int = aten::Int(%4796), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4798 : int[] = prim::ListConstruct(%4797, %4781, %4785), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %input.119 : Float(204:64, 512:13056, 64:1) = aten::reshape(%4795, %4798), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:550:0
  %4800 : int[] = prim::ListConstruct(%126, %126, %142, %142), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %padded_value.10 : Float(204:65536, 1024:64, 64:1) = aten::constant_pad_nd(%input.119, %4800, %140), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/nn/functional.py:3552:0
  %4802 : Long() = aten::mul(%batch_size.40, %num_heads.30), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:556:0
  %4803 : int = aten::Int(%4802), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4804 : Long() = aten::add(%chunks_count.30, %132, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:556:0
  %4805 : int = aten::Int(%4804), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4806 : int[] = prim::ListConstruct(%4803, %4805, %159, %4785), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4807 : int[] = prim::ListConstruct(%160, %161, %129, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4808 : Float(204:65536, 2:16384, 768:64, 64:1) = aten::as_strided(%padded_value.10, %4806, %4807, %138), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:564:0
  %4809 : int = aten::size(%chunked_hidden_states.46, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:420:0
  %4810 : int = aten::size(%chunked_hidden_states.46, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:420:0
  %4811 : int = aten::size(%chunked_hidden_states.46, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:420:0
  %window_overlap.10 : Long() = prim::NumToTensor(%4811), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4813 : int = aten::size(%chunked_hidden_states.46, %130), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:420:0
  %hidden_dim.10 : Long() = prim::NumToTensor(%4813), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4815 : Long() = aten::add(%window_overlap.10, %132, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:422:0
  %4816 : int = aten::Int(%4815), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4817 : int[] = prim::ListConstruct(%126, %4816), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %chunked_hidden_states.47 : Float(204:394240, 2:197120, 256:770, 770:1) = aten::constant_pad_nd(%chunked_hidden_states.46, %4817, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/nn/functional.py:3552:0
  %4819 : int[] = prim::ListConstruct(%4809, %4810, %140), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %chunked_hidden_states.48 : Float(204:394240, 2:197120, 197120:1) = aten::view(%chunked_hidden_states.47, %4819), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:424:0
  %4821 : Long() = aten::neg(%window_overlap.10), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:428:0
  %4822 : int = aten::Int(%4821), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4823 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%chunked_hidden_states.48, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:427:0
  %4824 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%4823, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:427:0
  %chunked_hidden_states.49 : Float(204:394240, 2:197120, 196864:1) = aten::slice(%4824, %124, %126, %4822, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:427:0
  %4826 : Long() = aten::add(%window_overlap.10, %hidden_dim.10, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:431:0
  %4827 : int = aten::Int(%4826), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4828 : int[] = prim::ListConstruct(%4809, %4810, %4811, %4827), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %chunked_hidden_states.50 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::view(%chunked_hidden_states.49, %4828), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:430:0
  %4830 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%chunked_hidden_states.50, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:433:0
  %4831 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%4830, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:433:0
  %4832 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%4831, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:433:0
  %4833 : Float(204:394240, 2:197120, 256:769, 768:1) = aten::slice(%4832, %130, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:433:0
  %4834 : Tensor[] = prim::ListConstruct(%4833, %4808), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %context.10 : Float(204:32768, 2:16384, 256:64, 64:1) = aten::einsum(%162, %4834), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/functional.py:327:0
  %4836 : int[] = prim::ListConstruct(%4779, %4783, %4781, %4785), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4837 : Float(17:393216, 12:32768, 512:64, 64:1) = aten::view(%context.10, %4836), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:569:0
  %attn_output.19 : Float(17:393216, 512:64, 12:32768, 64:1) = aten::transpose(%4837, %125, %124), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:569:0
  %4839 : Float(512:64, 17:393216, 12:32768, 64:1) = aten::transpose(%attn_output.19, %126, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:350:0
  %4840 : int[] = prim::ListConstruct(%4435, %4436, %4437), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %4841 : Float(512:13056, 17:768, 768:1) = aten::reshape(%4839, %4840), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:350:0
  %attn_output.20 : Float(512:13056, 17:768, 768:1) = aten::contiguous(%4841, %126), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:350:0
  %input.120 : Float(17:768, 512:13056, 768:1) = aten::transpose(%attn_output.20, %126, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_longformer.py:374:0
  %4844 : __torch__.torch.nn.modules.normalization.___torch_mangle_8229.LayerNorm = prim::GetAttr[name="LayerNorm"](%4411)
  %4845 : __torch__.torch.nn.modules.linear.___torch_mangle_8228.Linear = prim::GetAttr[name="dense"](%4411)
  %4846 : Tensor = prim::GetAttr[name="bias"](%4845)
  %4847 : Tensor = prim::GetAttr[name="weight"](%4845)
  %4848 : Float(768:1, 768:768) = aten::t(%4847), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %output.58 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.120, %4848), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %input.121 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.58, %4846, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.109 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.121, %158, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.dropout # torch/nn/functional.py:973:0
  %input.122 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.109, %hidden_states.100, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output # transformers/modeling_longformer.py:758:0
  %4853 : Tensor = prim::GetAttr[name="bias"](%4844)
  %4854 : Tensor = prim::GetAttr[name="weight"](%4844)
  %4855 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.LayerNorm
  %input_tensor.30 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.122, %4855, %4854, %4853, %123, %122), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %4857 : __torch__.torch.nn.modules.linear.___torch_mangle_8233.Linear = prim::GetAttr[name="dense"](%4409)
  %4858 : Tensor = prim::GetAttr[name="bias"](%4857)
  %4859 : Tensor = prim::GetAttr[name="weight"](%4857)
  %4860 : Float(768:1, 3072:768) = aten::t(%4859), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.intermediate/__module.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %output.59 : Float(17:1572864, 512:3072, 3072:1) = aten::matmul(%input_tensor.30, %4860), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.intermediate/__module.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %input.123 : Float(17:1572864, 512:3072, 3072:1) = aten::add_(%output.59, %4858, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.intermediate/__module.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1678:0
  %input.124 : Float(17:1572864, 512:3072, 3072:1) = aten::gelu(%input.123), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.intermediate # torch/nn/functional.py:1369:0
  %4864 : __torch__.torch.nn.modules.normalization.___torch_mangle_8236.LayerNorm = prim::GetAttr[name="LayerNorm"](%4408)
  %4865 : __torch__.torch.nn.modules.linear.___torch_mangle_8235.Linear = prim::GetAttr[name="dense"](%4408)
  %4866 : Tensor = prim::GetAttr[name="bias"](%4865)
  %4867 : Tensor = prim::GetAttr[name="weight"](%4865)
  %4868 : Float(3072:1, 768:3072) = aten::t(%4867), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %output.60 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.124, %4868), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %input.125 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.60, %4866, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.110 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.125, %158, %146), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.dropout # torch/nn/functional.py:973:0
  %input.126 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.110, %input_tensor.30, %125), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output # transformers/modeling_longformer.py:830:0
  %4873 : Tensor = prim::GetAttr[name="bias"](%4864)
  %4874 : Tensor = prim::GetAttr[name="weight"](%4864)
  %4875 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.LayerNorm
  %hidden_states.111 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.126, %4875, %4874, %4873, %123, %122), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.LayerNorm # torch/nn/functional.py:2048:0
  %4877 : __torch__.transformers.modeling_longformer.___torch_mangle_8257.LongformerOutput = prim::GetAttr[name="output"](%166)
  %4878 : __torch__.transformers.modeling_longformer.___torch_mangle_8253.LongformerIntermediate = prim::GetAttr[name="intermediate"](%166)
  %4879 : __torch__.transformers.modeling_longformer.___torch_mangle_8251.LongformerAttention = prim::GetAttr[name="attention"](%166)
  %4880 : __torch__.transformers.modeling_longformer.___torch_mangle_8250.LongformerSelfOutput = prim::GetAttr[name="output"](%4879)
  %4881 : __torch__.transformers.modeling_longformer.___torch_mangle_8246.LongformerSelfAttention = prim::GetAttr[name="self"](%4879)
  %4882 : __torch__.torch.nn.modules.linear.___torch_mangle_8242.Linear = prim::GetAttr[name="value"](%4881)
  %4883 : __torch__.torch.nn.modules.linear.___torch_mangle_8241.Linear = prim::GetAttr[name="key"](%4881)
  %4884 : __torch__.torch.nn.modules.linear.___torch_mangle_8240.Linear = prim::GetAttr[name="query"](%4881)
  %4885 : Float(17:512, 1:512, 512:1) = aten::squeeze(%attention_mask, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:241:0
  %4886 : Float(17:512, 512:1) = aten::squeeze(%4885, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:241:0
  %is_index_masked.11 : Bool(17:512, 512:1) = aten::lt(%4886, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/tensor.py:22:0
  %input.127 : Float(512:768, 17:393216, 768:1) = aten::transpose(%hidden_states.111, %126, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:248:0
  %4889 : Tensor = prim::GetAttr[name="bias"](%4884)
  %4890 : Tensor = prim::GetAttr[name="weight"](%4884)
  %4891 : Float(768:1, 768:768) = aten::t(%4890), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %output.61 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.127, %4891), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %query_vectors.21 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.61, %4889, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.query # torch/nn/functional.py:1678:0
  %4894 : Tensor = prim::GetAttr[name="bias"](%4883)
  %4895 : Tensor = prim::GetAttr[name="weight"](%4883)
  %4896 : Float(768:1, 768:768) = aten::t(%4895), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %output.62 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.127, %4896), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %key_vectors.11 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.62, %4894, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.key # torch/nn/functional.py:1678:0
  %4899 : Tensor = prim::GetAttr[name="bias"](%4882)
  %4900 : Tensor = prim::GetAttr[name="weight"](%4882)
  %4901 : Float(768:1, 768:768) = aten::t(%4900), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %output.63 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.127, %4901), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %value_vectors.11 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.63, %4899, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.value # torch/nn/functional.py:1678:0
  %4904 : int = aten::size(%input.127, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:255:0
  %4905 : int = aten::size(%input.127, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:255:0
  %4906 : int = aten::size(%input.127, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:255:0
  %query_vectors.22 : Float(512:13056, 17:768, 768:1) = aten::div_(%query_vectors.21, %127), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:261:0
  %4908 : int[] = prim::ListConstruct(%4904, %4905, %128, %129), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4909 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%query_vectors.22, %4908), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:263:0
  %query.21 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%4909, %126, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:263:0
  %4911 : int[] = prim::ListConstruct(%4904, %4905, %128, %129), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4912 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%key_vectors.11, %4911), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:264:0
  %key.11 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%4912, %126, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:264:0
  %4914 : int = aten::size(%query.21, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.42 : Long() = prim::NumToTensor(%4914), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4916 : int = aten::size(%query.21, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.43 : Long() = prim::NumToTensor(%4916), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4918 : int = aten::size(%query.21, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.31 : Long() = prim::NumToTensor(%4918), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4920 : int = aten::size(%query.21, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:472:0
  %4921 : Long() = aten::floor_divide(%seq_len.43, %131), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/tensor.py:424:0
  %chunks_count.31 : Long() = aten::sub(%4921, %132, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:478:0
  %4923 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%query.21, %125, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:481:0
  %4924 : Long() = aten::mul(%batch_size.42, %num_heads.31), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:481:0
  %4925 : int = aten::Int(%4924), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4926 : int[] = prim::ListConstruct(%4925, %4916, %4920), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %hidden_states.112 : Float(204:64, 512:13056, 64:1) = aten::reshape(%4923, %4926), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:481:0
  %4928 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%key.11, %125, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:482:0
  %4929 : Long() = aten::mul(%batch_size.42, %num_heads.31), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:482:0
  %4930 : int = aten::Int(%4929), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4931 : int[] = prim::ListConstruct(%4930, %4916, %4920), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %hidden_states.114 : Float(204:64, 512:13056, 64:1) = aten::reshape(%4928, %4931), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:482:0
  %4933 : int = aten::size(%hidden_states.112, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:442:0
  %4934 : int = aten::size(%hidden_states.112, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:443:0
  %4935 : Long() = prim::NumToTensor(%4934), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4936 : Long() = aten::floor_divide(%4935, %133), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/tensor.py:424:0
  %4937 : int = aten::Int(%4936), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4938 : int = aten::size(%hidden_states.112, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:445:0
  %4939 : int[] = prim::ListConstruct(%4933, %4937, %134, %4938), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %hidden_states.113 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.112, %4939), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:441:0
  %4941 : int = aten::size(%hidden_states.113, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %4942 : int = aten::size(%hidden_states.113, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %4943 : Long() = prim::NumToTensor(%4942), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4944 : int = aten::size(%hidden_states.113, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %4945 : int = aten::size(%hidden_states.113, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %4946 : Long() = aten::mul(%4943, %135), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:450:0
  %4947 : Long() = aten::sub(%4946, %132, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:450:0
  %4948 : int = aten::Int(%4947), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4949 : int[] = prim::ListConstruct(%4941, %4948, %4944, %4945), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4950 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4951 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.113, %4949, %4950, %138), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:454:0
  %4952 : int = aten::size(%hidden_states.114, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:442:0
  %4953 : int = aten::size(%hidden_states.114, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:443:0
  %4954 : Long() = prim::NumToTensor(%4953), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4955 : Long() = aten::floor_divide(%4954, %133), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/tensor.py:424:0
  %4956 : int = aten::Int(%4955), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4957 : int = aten::size(%hidden_states.114, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:445:0
  %4958 : int[] = prim::ListConstruct(%4952, %4956, %134, %4957), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %hidden_states.115 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.114, %4958), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:441:0
  %4960 : int = aten::size(%hidden_states.115, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %4961 : int = aten::size(%hidden_states.115, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %4962 : Long() = prim::NumToTensor(%4961), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4963 : int = aten::size(%hidden_states.115, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %4964 : int = aten::size(%hidden_states.115, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %4965 : Long() = aten::mul(%4962, %135), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:450:0
  %4966 : Long() = aten::sub(%4965, %132, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:450:0
  %4967 : int = aten::Int(%4966), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4968 : int[] = prim::ListConstruct(%4960, %4967, %4963, %4964), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4969 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4970 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.115, %4968, %4969, %138), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:454:0
  %4971 : Tensor[] = prim::ListConstruct(%4951, %4970), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %input.128 : Float(204:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %4971), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/functional.py:327:0
  %4973 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %hidden_states_padded.21 : Float(204:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.128, %4973, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/nn/functional.py:3552:0
  %4975 : int = aten::size(%hidden_states_padded.21, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:401:0
  %4976 : int = aten::size(%hidden_states_padded.21, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:401:0
  %4977 : int = aten::size(%hidden_states_padded.21, %140), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:401:0
  %4978 : int = aten::size(%hidden_states_padded.21, %141), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:401:0
  %4979 : int[] = prim::ListConstruct(%4975, %4976, %4977, %4978), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %diagonal_chunked_attention_scores.21 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.21, %4979), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:400:0
  %4981 : Long() = aten::mul(%batch_size.42, %num_heads.31), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:504:0
  %4982 : int = aten::Int(%4981), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4983 : Long() = aten::add(%chunks_count.31, %132, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:504:0
  %4984 : int = aten::Int(%4983), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4985 : int[] = prim::ListConstruct(%4982, %4984, %142, %143), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %diagonal_attention_scores.21 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.21, %4985, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:503:0
  %4987 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.21, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %4988 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%4987, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %4989 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%4988, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %4990 : Float(204:262656, 1:262656, 256:513, 257:1) = aten::slice(%4989, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %4991 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.21, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %4992 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%4991, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %4993 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%4992, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %4994 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::slice(%4993, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %4995 : int[] = prim::ListConstruct(%149, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %4996 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::view(%4990, %4995), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %4997 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::copy_(%4994, %4996, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %4998 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.21, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %4999 : Float(204:262656, 512:513, 513:1) = aten::select(%4998, %125, %140), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5000 : Float(204:262656, 256:513, 513:1) = aten::slice(%4999, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5001 : Float(204:262656, 256:513, 257:1) = aten::slice(%5000, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5002 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.21, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5003 : Float(204:262656, 256:513, 513:1) = aten::select(%5002, %125, %140), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5004 : Float(204:262656, 256:513, 513:1) = aten::slice(%5003, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5005 : Float(204:262656, 256:513, 257:1) = aten::slice(%5004, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5006 : int[] = prim::ListConstruct(%149, %142, %148), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5007 : Float(204:262656, 256:513, 257:1) = aten::view(%5001, %5006), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5008 : Float(204:262656, 256:513, 257:1) = aten::copy_(%5005, %5007, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5009 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.21, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5010 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%5009, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5011 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%5010, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5012 : Float(204:262656, 1:262656, 256:513, 256:1) = aten::slice(%5011, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5013 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.21, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5014 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%5013, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5015 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%5014, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5016 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::slice(%5015, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5017 : int[] = prim::ListConstruct(%149, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5018 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::view(%5012, %5017), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5019 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::copy_(%5016, %5018, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5020 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.21, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5021 : Float(204:262656, 512:513, 513:1) = aten::select(%5020, %125, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5022 : Float(204:262656, 255:513, 513:1) = aten::slice(%5021, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5023 : Float(204:262656, 255:513, 255:1) = aten::slice(%5022, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5024 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.21, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5025 : Float(204:262656, 256:513, 513:1) = aten::select(%5024, %125, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5026 : Float(204:262656, 255:513, 513:1) = aten::slice(%5025, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5027 : Float(204:262656, 255:513, 255:1) = aten::slice(%5026, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5028 : int[] = prim::ListConstruct(%149, %151, %151), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5029 : Float(204:262656, 255:513, 255:1) = aten::view(%5023, %5028), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5030 : Float(204:262656, 255:513, 255:1) = aten::copy_(%5027, %5029, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5031 : int[] = prim::ListConstruct(%4914, %4918, %4916, %143), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5032 : Float(17:3151872, 12:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.21, %5031), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.31 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::transpose(%5032, %124, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:525:0
  %5034 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5035 : Float(256:257, 257:1) = aten::ones(%5034, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:458:0
  %5036 : Float(256:257, 257:1) = aten::tril(%5035, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:458:0
  %5037 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %beginning_mask_2d.21 : Float(256:257, 257:1) = aten::flip(%5036, %5037), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:458:0
  %5039 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.21, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:459:0
  %5040 : Float(1:65792, 256:257, 257:1) = aten::slice(%5039, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:459:0
  %5041 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%5040, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.21 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%5041, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:459:0
  %5043 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %ending_mask.21 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.21, %5043), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:460:0
  %5045 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.31, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:461:0
  %5046 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%5045, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:461:0
  %5047 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%5046, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.21 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%5047, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:461:0
  %5049 : int = aten::size(%beginning_input.21, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:462:0
  %5050 : int = aten::size(%beginning_input.21, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:462:0
  %5051 : int = aten::size(%beginning_input.21, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:462:0
  %5052 : int = aten::size(%beginning_input.21, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:462:0
  %5053 : int[] = prim::ListConstruct(%5049, %5050, %5051, %5052), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5054 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%beginning_mask.21, %5053, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:462:0
  %5055 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%5054, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/tensor.py:22:0
  %5056 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%beginning_input.21, %5055, %153), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:463:0
  %5057 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.31, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:464:0
  %5058 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%5057, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:464:0
  %5059 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%5058, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.21 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%5059, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:464:0
  %5061 : int = aten::size(%ending_input.21, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:465:0
  %5062 : int = aten::size(%ending_input.21, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:465:0
  %5063 : int = aten::size(%ending_input.21, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:465:0
  %5064 : int = aten::size(%ending_input.21, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:465:0
  %5065 : int[] = prim::ListConstruct(%5061, %5062, %5063, %5064), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5066 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%ending_mask.21, %5065, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:465:0
  %5067 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%5066, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/tensor.py:22:0
  %5068 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%ending_input.21, %5067, %153), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:466:0
  %5069 : Bool(17:512, 512:1) = aten::ne(%4886, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/tensor.py:22:0
  %5070 : Bool(17:512, 512:1) = aten::slice(%5069, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:272:0
  %5071 : Bool(17:512, 512:1) = aten::slice(%5070, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:272:0
  %5072 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%5071, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:272:0
  %remove_from_windowed_attention_mask.11 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%5072, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:272:0
  %5074 : Float(17:512, 512:1, 1:1, 1:1) = aten::type_as(%remove_from_windowed_attention_mask.11, %query.21), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:275:0
  %float_mask.11 : Float(17:512, 512:1, 1:1, 1:1) = aten::masked_fill(%5074, %remove_from_windowed_attention_mask.11, %155), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:275:0
  %5076 : int = aten::size(%float_mask.11, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:280:0
  %5077 : int = aten::size(%float_mask.11, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:280:0
  %5078 : int = aten::size(%float_mask.11, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:280:0
  %5079 : int = aten::size(%float_mask.11, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:280:0
  %5080 : int[] = prim::ListConstruct(%5076, %5077, %5078, %5079), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %query.22 : Float(17:512, 512:1, 1:1, 1:1) = aten::ones(%5080, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:280:0
  %5082 : int = aten::size(%query.22, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.43 : Long() = prim::NumToTensor(%5082), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5084 : int = aten::size(%query.22, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.44 : Long() = prim::NumToTensor(%5084), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5086 : int = aten::size(%query.22, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.32 : Long() = prim::NumToTensor(%5086), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5088 : int = aten::size(%query.22, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:472:0
  %5089 : Long() = aten::floor_divide(%seq_len.44, %131), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/tensor.py:424:0
  %chunks_count.32 : Long() = aten::sub(%5089, %132, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:478:0
  %5091 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%query.22, %125, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:481:0
  %5092 : Long() = aten::mul(%batch_size.43, %num_heads.32), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:481:0
  %5093 : int = aten::Int(%5092), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5094 : int[] = prim::ListConstruct(%5093, %5084, %5088), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %hidden_states.116 : Float(17:512, 512:1, 1:1) = aten::reshape(%5091, %5094), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:481:0
  %5096 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%float_mask.11, %125, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:482:0
  %5097 : Long() = aten::mul(%batch_size.43, %num_heads.32), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:482:0
  %5098 : int = aten::Int(%5097), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5099 : int[] = prim::ListConstruct(%5098, %5084, %5088), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %hidden_states.118 : Float(17:512, 512:1, 1:1) = aten::reshape(%5096, %5099), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:482:0
  %5101 : int = aten::size(%hidden_states.116, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:442:0
  %5102 : int = aten::size(%hidden_states.116, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:443:0
  %5103 : Long() = prim::NumToTensor(%5102), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5104 : Long() = aten::floor_divide(%5103, %133), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/tensor.py:424:0
  %5105 : int = aten::Int(%5104), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5106 : int = aten::size(%hidden_states.116, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:445:0
  %5107 : int[] = prim::ListConstruct(%5101, %5105, %134, %5106), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %hidden_states.117 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.116, %5107), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:441:0
  %5109 : int = aten::size(%hidden_states.117, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %5110 : int = aten::size(%hidden_states.117, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %5111 : Long() = prim::NumToTensor(%5110), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5112 : int = aten::size(%hidden_states.117, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %5113 : int = aten::size(%hidden_states.117, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %5114 : Long() = aten::mul(%5111, %135), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:450:0
  %5115 : Long() = aten::sub(%5114, %132, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:450:0
  %5116 : int = aten::Int(%5115), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5117 : int[] = prim::ListConstruct(%5109, %5116, %5112, %5113), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5118 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5119 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.117, %5117, %5118, %138), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:454:0
  %5120 : int = aten::size(%hidden_states.118, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:442:0
  %5121 : int = aten::size(%hidden_states.118, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:443:0
  %5122 : Long() = prim::NumToTensor(%5121), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5123 : Long() = aten::floor_divide(%5122, %133), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/tensor.py:424:0
  %5124 : int = aten::Int(%5123), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5125 : int = aten::size(%hidden_states.118, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:445:0
  %5126 : int[] = prim::ListConstruct(%5120, %5124, %134, %5125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %hidden_states.119 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.118, %5126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:441:0
  %5128 : int = aten::size(%hidden_states.119, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %5129 : int = aten::size(%hidden_states.119, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %5130 : Long() = prim::NumToTensor(%5129), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5131 : int = aten::size(%hidden_states.119, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %5132 : int = aten::size(%hidden_states.119, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:449:0
  %5133 : Long() = aten::mul(%5130, %135), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:450:0
  %5134 : Long() = aten::sub(%5133, %132, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:450:0
  %5135 : int = aten::Int(%5134), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5136 : int[] = prim::ListConstruct(%5128, %5135, %5131, %5132), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5137 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5138 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.119, %5136, %5137, %138), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:454:0
  %5139 : Tensor[] = prim::ListConstruct(%5119, %5138), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %input.129 : Float(17:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %5139), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/functional.py:327:0
  %5141 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %hidden_states_padded.22 : Float(17:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.129, %5141, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/nn/functional.py:3552:0
  %5143 : int = aten::size(%hidden_states_padded.22, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:401:0
  %5144 : int = aten::size(%hidden_states_padded.22, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:401:0
  %5145 : int = aten::size(%hidden_states_padded.22, %140), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:401:0
  %5146 : int = aten::size(%hidden_states_padded.22, %141), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:401:0
  %5147 : int[] = prim::ListConstruct(%5143, %5144, %5145, %5146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %diagonal_chunked_attention_scores.22 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.22, %5147), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:400:0
  %5149 : Long() = aten::mul(%batch_size.43, %num_heads.32), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:504:0
  %5150 : int = aten::Int(%5149), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5151 : Long() = aten::add(%chunks_count.32, %132, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:504:0
  %5152 : int = aten::Int(%5151), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5153 : int[] = prim::ListConstruct(%5150, %5152, %142, %143), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %diagonal_attention_scores.22 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.22, %5153, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:503:0
  %5155 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.22, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %5156 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%5155, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %5157 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%5156, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %5158 : Float(17:262656, 1:262656, 256:513, 257:1) = aten::slice(%5157, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %5159 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.22, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %5160 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%5159, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %5161 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%5160, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %5162 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::slice(%5161, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %5163 : int[] = prim::ListConstruct(%156, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5164 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::view(%5158, %5163), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %5165 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::copy_(%5162, %5164, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:509:0
  %5166 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.22, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5167 : Float(17:262656, 512:513, 513:1) = aten::select(%5166, %125, %140), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5168 : Float(17:262656, 256:513, 513:1) = aten::slice(%5167, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5169 : Float(17:262656, 256:513, 257:1) = aten::slice(%5168, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5170 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.22, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5171 : Float(17:262656, 256:513, 513:1) = aten::select(%5170, %125, %140), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5172 : Float(17:262656, 256:513, 513:1) = aten::slice(%5171, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5173 : Float(17:262656, 256:513, 257:1) = aten::slice(%5172, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5174 : int[] = prim::ListConstruct(%156, %142, %148), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5175 : Float(17:262656, 256:513, 257:1) = aten::view(%5169, %5174), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5176 : Float(17:262656, 256:513, 257:1) = aten::copy_(%5173, %5175, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:512:0
  %5177 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.22, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5178 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%5177, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5179 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%5178, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5180 : Float(17:262656, 1:262656, 256:513, 256:1) = aten::slice(%5179, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5181 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.22, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5182 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%5181, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5183 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%5182, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5184 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::slice(%5183, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5185 : int[] = prim::ListConstruct(%156, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5186 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::view(%5180, %5185), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5187 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::copy_(%5184, %5186, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:516:0
  %5188 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.22, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5189 : Float(17:262656, 512:513, 513:1) = aten::select(%5188, %125, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5190 : Float(17:262656, 255:513, 513:1) = aten::slice(%5189, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5191 : Float(17:262656, 255:513, 255:1) = aten::slice(%5190, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5192 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.22, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5193 : Float(17:262656, 256:513, 513:1) = aten::select(%5192, %125, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5194 : Float(17:262656, 255:513, 513:1) = aten::slice(%5193, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5195 : Float(17:262656, 255:513, 255:1) = aten::slice(%5194, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5196 : int[] = prim::ListConstruct(%156, %151, %151), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5197 : Float(17:262656, 255:513, 255:1) = aten::view(%5191, %5196), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5198 : Float(17:262656, 255:513, 255:1) = aten::copy_(%5195, %5197, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:520:0
  %5199 : int[] = prim::ListConstruct(%5082, %5086, %5084, %143), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5200 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.22, %5199), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.32 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::transpose(%5200, %124, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:525:0
  %5202 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5203 : Float(256:257, 257:1) = aten::ones(%5202, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:458:0
  %5204 : Float(256:257, 257:1) = aten::tril(%5203, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:458:0
  %5205 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %beginning_mask_2d.22 : Float(256:257, 257:1) = aten::flip(%5204, %5205), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:458:0
  %5207 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.22, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:459:0
  %5208 : Float(1:65792, 256:257, 257:1) = aten::slice(%5207, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:459:0
  %5209 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%5208, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.22 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%5209, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:459:0
  %5211 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %ending_mask.22 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.22, %5211), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:460:0
  %5213 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.32, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:461:0
  %5214 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%5213, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:461:0
  %5215 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%5214, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.22 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%5215, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:461:0
  %5217 : int = aten::size(%beginning_input.22, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:462:0
  %5218 : int = aten::size(%beginning_input.22, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:462:0
  %5219 : int = aten::size(%beginning_input.22, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:462:0
  %5220 : int = aten::size(%beginning_input.22, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:462:0
  %5221 : int[] = prim::ListConstruct(%5217, %5218, %5219, %5220), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5222 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%beginning_mask.22, %5221, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:462:0
  %5223 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%5222, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/tensor.py:22:0
  %5224 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%beginning_input.22, %5223, %153), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:463:0
  %5225 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.32, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:464:0
  %5226 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%5225, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:464:0
  %5227 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%5226, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.22 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%5227, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:464:0
  %5229 : int = aten::size(%ending_input.22, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:465:0
  %5230 : int = aten::size(%ending_input.22, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:465:0
  %5231 : int = aten::size(%ending_input.22, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:465:0
  %5232 : int = aten::size(%ending_input.22, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:465:0
  %5233 : int[] = prim::ListConstruct(%5229, %5230, %5231, %5232), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5234 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%ending_mask.22, %5233, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:465:0
  %5235 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%5234, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/tensor.py:22:0
  %5236 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%ending_input.22, %5235, %153), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:466:0
  %attn_scores.11 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::add_(%input_tensor.31, %input_tensor.32, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:284:0
  %attn_probs_fp32.11 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::softmax(%attn_scores.11, %140, %144), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/nn/functional.py:1500:0
  %5239 : Bool(17:512, 512:1) = aten::slice(%is_index_masked.11, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:326:0
  %5240 : Bool(17:512, 512:1) = aten::slice(%5239, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:326:0
  %5241 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%5240, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:326:0
  %5242 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%5241, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:326:0
  %input.130 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::masked_fill(%attn_probs_fp32.11, %5242, %157), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:326:0
  %attn_probs.22 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::dropout(%input.130, %158, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/nn/functional.py:973:0
  %5245 : int[] = prim::ListConstruct(%4904, %4905, %128, %129), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5246 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%value_vectors.11, %5245), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:331:0
  %value.11 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%5246, %126, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:331:0
  %5248 : int = aten::size(%value.11, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:537:0
  %batch_size.44 : Long() = prim::NumToTensor(%5248), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5250 : int = aten::size(%value.11, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:537:0
  %seq_len.45 : Long() = prim::NumToTensor(%5250), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5252 : int = aten::size(%value.11, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:537:0
  %num_heads.33 : Long() = prim::NumToTensor(%5252), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5254 : int = aten::size(%value.11, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:537:0
  %5255 : Long() = aten::floor_divide(%seq_len.45, %131), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/tensor.py:424:0
  %chunks_count.33 : Long() = aten::sub(%5255, %132, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:542:0
  %5257 : Float(17:3151872, 12:513, 512:6156, 513:1) = aten::transpose(%attn_probs.22, %125, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:545:0
  %5258 : Long() = aten::mul(%batch_size.44, %num_heads.33), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:546:0
  %5259 : int = aten::Int(%5258), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5260 : Long() = aten::floor_divide(%seq_len.45, %131), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/tensor.py:424:0
  %5261 : int = aten::Int(%5260), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5262 : int[] = prim::ListConstruct(%5259, %5261, %142, %143), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %chunked_hidden_states.51 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::reshape(%5257, %5262), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:545:0
  %5264 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%value.11, %125, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:550:0
  %5265 : Long() = aten::mul(%batch_size.44, %num_heads.33), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:550:0
  %5266 : int = aten::Int(%5265), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5267 : int[] = prim::ListConstruct(%5266, %5250, %5254), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %input.131 : Float(204:64, 512:13056, 64:1) = aten::reshape(%5264, %5267), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:550:0
  %5269 : int[] = prim::ListConstruct(%126, %126, %142, %142), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %padded_value.11 : Float(204:65536, 1024:64, 64:1) = aten::constant_pad_nd(%input.131, %5269, %140), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/nn/functional.py:3552:0
  %5271 : Long() = aten::mul(%batch_size.44, %num_heads.33), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:556:0
  %5272 : int = aten::Int(%5271), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5273 : Long() = aten::add(%chunks_count.33, %132, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:556:0
  %5274 : int = aten::Int(%5273), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5275 : int[] = prim::ListConstruct(%5272, %5274, %159, %5254), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5276 : int[] = prim::ListConstruct(%160, %161, %129, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5277 : Float(204:65536, 2:16384, 768:64, 64:1) = aten::as_strided(%padded_value.11, %5275, %5276, %138), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:564:0
  %5278 : int = aten::size(%chunked_hidden_states.51, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:420:0
  %5279 : int = aten::size(%chunked_hidden_states.51, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:420:0
  %5280 : int = aten::size(%chunked_hidden_states.51, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:420:0
  %window_overlap.11 : Long() = prim::NumToTensor(%5280), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5282 : int = aten::size(%chunked_hidden_states.51, %130), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:420:0
  %hidden_dim.11 : Long() = prim::NumToTensor(%5282), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5284 : Long() = aten::add(%window_overlap.11, %132, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:422:0
  %5285 : int = aten::Int(%5284), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5286 : int[] = prim::ListConstruct(%126, %5285), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %chunked_hidden_states.52 : Float(204:394240, 2:197120, 256:770, 770:1) = aten::constant_pad_nd(%chunked_hidden_states.51, %5286, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/nn/functional.py:3552:0
  %5288 : int[] = prim::ListConstruct(%5278, %5279, %140), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %chunked_hidden_states.53 : Float(204:394240, 2:197120, 197120:1) = aten::view(%chunked_hidden_states.52, %5288), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:424:0
  %5290 : Long() = aten::neg(%window_overlap.11), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:428:0
  %5291 : int = aten::Int(%5290), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5292 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%chunked_hidden_states.53, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:427:0
  %5293 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%5292, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:427:0
  %chunked_hidden_states.54 : Float(204:394240, 2:197120, 196864:1) = aten::slice(%5293, %124, %126, %5291, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:427:0
  %5295 : Long() = aten::add(%window_overlap.11, %hidden_dim.11, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:431:0
  %5296 : int = aten::Int(%5295), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5297 : int[] = prim::ListConstruct(%5278, %5279, %5280, %5296), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %chunked_hidden_states.55 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::view(%chunked_hidden_states.54, %5297), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:430:0
  %5299 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%chunked_hidden_states.55, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:433:0
  %5300 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%5299, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:433:0
  %5301 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%5300, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:433:0
  %5302 : Float(204:394240, 2:197120, 256:769, 768:1) = aten::slice(%5301, %130, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:433:0
  %5303 : Tensor[] = prim::ListConstruct(%5302, %5277), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %context.11 : Float(204:32768, 2:16384, 256:64, 64:1) = aten::einsum(%162, %5303), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/functional.py:327:0
  %5305 : int[] = prim::ListConstruct(%5248, %5252, %5250, %5254), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5306 : Float(17:393216, 12:32768, 512:64, 64:1) = aten::view(%context.11, %5305), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:569:0
  %attn_output.21 : Float(17:393216, 512:64, 12:32768, 64:1) = aten::transpose(%5306, %125, %124), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:569:0
  %5308 : Float(512:64, 17:393216, 12:32768, 64:1) = aten::transpose(%attn_output.21, %126, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:350:0
  %5309 : int[] = prim::ListConstruct(%4904, %4905, %4906), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %5310 : Float(512:13056, 17:768, 768:1) = aten::reshape(%5308, %5309), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:350:0
  %attn_output.22 : Float(512:13056, 17:768, 768:1) = aten::contiguous(%5310, %126), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:350:0
  %input.132 : Float(17:768, 512:13056, 768:1) = aten::transpose(%attn_output.22, %126, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_longformer.py:374:0
  %5313 : __torch__.torch.nn.modules.normalization.___torch_mangle_8248.LayerNorm = prim::GetAttr[name="LayerNorm"](%4880)
  %5314 : __torch__.torch.nn.modules.linear.___torch_mangle_8247.Linear = prim::GetAttr[name="dense"](%4880)
  %5315 : Tensor = prim::GetAttr[name="bias"](%5314)
  %5316 : Tensor = prim::GetAttr[name="weight"](%5314)
  %5317 : Float(768:1, 768:768) = aten::t(%5316), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %output.64 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.132, %5317), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %input.133 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.64, %5315, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.120 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.133, %158, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.dropout # torch/nn/functional.py:973:0
  %input.134 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.120, %hidden_states.111, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output # transformers/modeling_longformer.py:758:0
  %5322 : Tensor = prim::GetAttr[name="bias"](%5313)
  %5323 : Tensor = prim::GetAttr[name="weight"](%5313)
  %5324 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.LayerNorm
  %input_tensor.33 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.134, %5324, %5323, %5322, %123, %122), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %5326 : __torch__.torch.nn.modules.linear.___torch_mangle_8252.Linear = prim::GetAttr[name="dense"](%4878)
  %5327 : Tensor = prim::GetAttr[name="bias"](%5326)
  %5328 : Tensor = prim::GetAttr[name="weight"](%5326)
  %5329 : Float(768:1, 3072:768) = aten::t(%5328), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.intermediate/__module.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %output.65 : Float(17:1572864, 512:3072, 3072:1) = aten::matmul(%input_tensor.33, %5329), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.intermediate/__module.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %input.135 : Float(17:1572864, 512:3072, 3072:1) = aten::add_(%output.65, %5327, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.intermediate/__module.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1678:0
  %input.136 : Float(17:1572864, 512:3072, 3072:1) = aten::gelu(%input.135), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.intermediate # torch/nn/functional.py:1369:0
  %5333 : __torch__.torch.nn.modules.normalization.___torch_mangle_8255.LayerNorm = prim::GetAttr[name="LayerNorm"](%4877)
  %5334 : __torch__.torch.nn.modules.linear.___torch_mangle_8254.Linear = prim::GetAttr[name="dense"](%4877)
  %5335 : Tensor = prim::GetAttr[name="bias"](%5334)
  %5336 : Tensor = prim::GetAttr[name="weight"](%5334)
  %5337 : Float(3072:1, 768:3072) = aten::t(%5336), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %output.66 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.136, %5337), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %input.137 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.66, %5335, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.121 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.137, %158, %146), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.dropout # torch/nn/functional.py:973:0
  %input.138 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.121, %input_tensor.33, %125), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output # transformers/modeling_longformer.py:830:0
  %5342 : Tensor = prim::GetAttr[name="bias"](%5333)
  %5343 : Tensor = prim::GetAttr[name="weight"](%5333)
  %5344 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.LayerNorm
  %hidden_states.122 : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.138, %5344, %5343, %5342, %123, %122), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.LayerNorm # torch/nn/functional.py:2048:0
  %5346 : __torch__.transformers.modeling_longformer.___torch_mangle_8276.LongformerOutput = prim::GetAttr[name="output"](%164)
  %5347 : __torch__.transformers.modeling_longformer.___torch_mangle_8272.LongformerIntermediate = prim::GetAttr[name="intermediate"](%164)
  %5348 : __torch__.transformers.modeling_longformer.___torch_mangle_8270.LongformerAttention = prim::GetAttr[name="attention"](%164)
  %5349 : __torch__.transformers.modeling_longformer.___torch_mangle_8269.LongformerSelfOutput = prim::GetAttr[name="output"](%5348)
  %5350 : __torch__.transformers.modeling_longformer.___torch_mangle_8265.LongformerSelfAttention = prim::GetAttr[name="self"](%5348)
  %5351 : __torch__.torch.nn.modules.linear.___torch_mangle_8261.Linear = prim::GetAttr[name="value"](%5350)
  %5352 : __torch__.torch.nn.modules.linear.___torch_mangle_8260.Linear = prim::GetAttr[name="key"](%5350)
  %5353 : __torch__.torch.nn.modules.linear.___torch_mangle_8259.Linear = prim::GetAttr[name="query"](%5350)
  %5354 : Float(17:512, 1:512, 512:1) = aten::squeeze(%attention_mask, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:241:0
  %5355 : Float(17:512, 512:1) = aten::squeeze(%5354, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:241:0
  %is_index_masked : Bool(17:512, 512:1) = aten::lt(%5355, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/tensor.py:22:0
  %input.139 : Float(512:768, 17:393216, 768:1) = aten::transpose(%hidden_states.122, %126, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:248:0
  %5358 : Tensor = prim::GetAttr[name="bias"](%5353)
  %5359 : Tensor = prim::GetAttr[name="weight"](%5353)
  %5360 : Float(768:1, 768:768) = aten::t(%5359), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %output.67 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.139, %5360), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %query_vectors.23 : Float(512:13056, 17:768, 768:1) = aten::add_(%output.67, %5358, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.query # torch/nn/functional.py:1678:0
  %5363 : Tensor = prim::GetAttr[name="bias"](%5352)
  %5364 : Tensor = prim::GetAttr[name="weight"](%5352)
  %5365 : Float(768:1, 768:768) = aten::t(%5364), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %output.68 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.139, %5365), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %key_vectors : Float(512:13056, 17:768, 768:1) = aten::add_(%output.68, %5363, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.key # torch/nn/functional.py:1678:0
  %5368 : Tensor = prim::GetAttr[name="bias"](%5351)
  %5369 : Tensor = prim::GetAttr[name="weight"](%5351)
  %5370 : Float(768:1, 768:768) = aten::t(%5369), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %output.69 : Float(512:13056, 17:768, 768:1) = aten::matmul(%input.139, %5370), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %value_vectors : Float(512:13056, 17:768, 768:1) = aten::add_(%output.69, %5368, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.value # torch/nn/functional.py:1678:0
  %5373 : int = aten::size(%input.139, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:255:0
  %5374 : int = aten::size(%input.139, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:255:0
  %5375 : int = aten::size(%input.139, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:255:0
  %query_vectors : Float(512:13056, 17:768, 768:1) = aten::div_(%query_vectors.23, %127), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:261:0
  %5377 : int[] = prim::ListConstruct(%5373, %5374, %128, %129), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5378 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%query_vectors, %5377), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:263:0
  %query.23 : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%5378, %126, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:263:0
  %5380 : int[] = prim::ListConstruct(%5373, %5374, %128, %129), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5381 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%key_vectors, %5380), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:264:0
  %key : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%5381, %126, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:264:0
  %5383 : int = aten::size(%query.23, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.46 : Long() = prim::NumToTensor(%5383), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5385 : int = aten::size(%query.23, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.47 : Long() = prim::NumToTensor(%5385), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5387 : int = aten::size(%query.23, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.34 : Long() = prim::NumToTensor(%5387), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5389 : int = aten::size(%query.23, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:472:0
  %5390 : Long() = aten::floor_divide(%seq_len.47, %131), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/tensor.py:424:0
  %chunks_count.34 : Long() = aten::sub(%5390, %132, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:478:0
  %5392 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%query.23, %125, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:481:0
  %5393 : Long() = aten::mul(%batch_size.46, %num_heads.34), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:481:0
  %5394 : int = aten::Int(%5393), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5395 : int[] = prim::ListConstruct(%5394, %5385, %5389), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %hidden_states.123 : Float(204:64, 512:13056, 64:1) = aten::reshape(%5392, %5395), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:481:0
  %5397 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%key, %125, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:482:0
  %5398 : Long() = aten::mul(%batch_size.46, %num_heads.34), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:482:0
  %5399 : int = aten::Int(%5398), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5400 : int[] = prim::ListConstruct(%5399, %5385, %5389), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %hidden_states.125 : Float(204:64, 512:13056, 64:1) = aten::reshape(%5397, %5400), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:482:0
  %5402 : int = aten::size(%hidden_states.123, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:442:0
  %5403 : int = aten::size(%hidden_states.123, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:443:0
  %5404 : Long() = prim::NumToTensor(%5403), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5405 : Long() = aten::floor_divide(%5404, %133), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/tensor.py:424:0
  %5406 : int = aten::Int(%5405), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5407 : int = aten::size(%hidden_states.123, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:445:0
  %5408 : int[] = prim::ListConstruct(%5402, %5406, %134, %5407), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %hidden_states.124 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.123, %5408), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:441:0
  %5410 : int = aten::size(%hidden_states.124, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5411 : int = aten::size(%hidden_states.124, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5412 : Long() = prim::NumToTensor(%5411), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5413 : int = aten::size(%hidden_states.124, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5414 : int = aten::size(%hidden_states.124, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5415 : Long() = aten::mul(%5412, %135), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:450:0
  %5416 : Long() = aten::sub(%5415, %132, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:450:0
  %5417 : int = aten::Int(%5416), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5418 : int[] = prim::ListConstruct(%5410, %5417, %5413, %5414), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5419 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5420 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.124, %5418, %5419, %138), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:454:0
  %5421 : int = aten::size(%hidden_states.125, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:442:0
  %5422 : int = aten::size(%hidden_states.125, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:443:0
  %5423 : Long() = prim::NumToTensor(%5422), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5424 : Long() = aten::floor_divide(%5423, %133), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/tensor.py:424:0
  %5425 : int = aten::Int(%5424), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5426 : int = aten::size(%hidden_states.125, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:445:0
  %5427 : int[] = prim::ListConstruct(%5421, %5425, %134, %5426), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %hidden_states.126 : Float(204:64, 1:6684672, 512:13056, 64:1) = aten::view(%hidden_states.125, %5427), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:441:0
  %5429 : int = aten::size(%hidden_states.126, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5430 : int = aten::size(%hidden_states.126, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5431 : Long() = prim::NumToTensor(%5430), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5432 : int = aten::size(%hidden_states.126, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5433 : int = aten::size(%hidden_states.126, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5434 : Long() = aten::mul(%5431, %135), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:450:0
  %5435 : Long() = aten::sub(%5434, %132, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:450:0
  %5436 : int = aten::Int(%5435), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5437 : int[] = prim::ListConstruct(%5429, %5436, %5432, %5433), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5438 : int[] = prim::ListConstruct(%129, %136, %137, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5439 : Float(204:64, 1:3342336, 512:13056, 64:1) = aten::as_strided(%hidden_states.126, %5437, %5438, %138), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:454:0
  %5440 : Tensor[] = prim::ListConstruct(%5420, %5439), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %input.140 : Float(204:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %5440), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/functional.py:327:0
  %5442 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %hidden_states_padded.23 : Float(204:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.140, %5442, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/nn/functional.py:3552:0
  %5444 : int = aten::size(%hidden_states_padded.23, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:401:0
  %5445 : int = aten::size(%hidden_states_padded.23, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:401:0
  %5446 : int = aten::size(%hidden_states_padded.23, %140), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:401:0
  %5447 : int = aten::size(%hidden_states_padded.23, %141), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:401:0
  %5448 : int[] = prim::ListConstruct(%5444, %5445, %5446, %5447), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %diagonal_chunked_attention_scores.23 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded.23, %5448), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:400:0
  %5450 : Long() = aten::mul(%batch_size.46, %num_heads.34), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:504:0
  %5451 : int = aten::Int(%5450), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5452 : Long() = aten::add(%chunks_count.34, %132, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:504:0
  %5453 : int = aten::Int(%5452), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5454 : int[] = prim::ListConstruct(%5451, %5453, %142, %143), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %diagonal_attention_scores.23 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores.23, %5454, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:503:0
  %5456 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.23, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5457 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%5456, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5458 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%5457, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5459 : Float(204:262656, 1:262656, 256:513, 257:1) = aten::slice(%5458, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5460 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.23, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5461 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%5460, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5462 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%5461, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5463 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::slice(%5462, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5464 : int[] = prim::ListConstruct(%149, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5465 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::view(%5459, %5464), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5466 : Float(204:262656, 1:131328, 256:513, 257:1) = aten::copy_(%5463, %5465, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5467 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.23, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5468 : Float(204:262656, 512:513, 513:1) = aten::select(%5467, %125, %140), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5469 : Float(204:262656, 256:513, 513:1) = aten::slice(%5468, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5470 : Float(204:262656, 256:513, 257:1) = aten::slice(%5469, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5471 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.23, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5472 : Float(204:262656, 256:513, 513:1) = aten::select(%5471, %125, %140), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5473 : Float(204:262656, 256:513, 513:1) = aten::slice(%5472, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5474 : Float(204:262656, 256:513, 257:1) = aten::slice(%5473, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5475 : int[] = prim::ListConstruct(%149, %142, %148), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5476 : Float(204:262656, 256:513, 257:1) = aten::view(%5470, %5475), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5477 : Float(204:262656, 256:513, 257:1) = aten::copy_(%5474, %5476, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5478 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.23, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5479 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%5478, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5480 : Float(204:262656, 1:262656, 256:513, 513:1) = aten::slice(%5479, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5481 : Float(204:262656, 1:262656, 256:513, 256:1) = aten::slice(%5480, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5482 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.23, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5483 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%5482, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5484 : Float(204:262656, 1:131328, 256:513, 513:1) = aten::slice(%5483, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5485 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::slice(%5484, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5486 : int[] = prim::ListConstruct(%149, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5487 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::view(%5481, %5486), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5488 : Float(204:262656, 1:131328, 256:513, 256:1) = aten::copy_(%5485, %5487, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5489 : Float(204:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores.23, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5490 : Float(204:262656, 512:513, 513:1) = aten::select(%5489, %125, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5491 : Float(204:262656, 255:513, 513:1) = aten::slice(%5490, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5492 : Float(204:262656, 255:513, 255:1) = aten::slice(%5491, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5493 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores.23, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5494 : Float(204:262656, 256:513, 513:1) = aten::select(%5493, %125, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5495 : Float(204:262656, 255:513, 513:1) = aten::slice(%5494, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5496 : Float(204:262656, 255:513, 255:1) = aten::slice(%5495, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5497 : int[] = prim::ListConstruct(%149, %151, %151), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5498 : Float(204:262656, 255:513, 255:1) = aten::view(%5492, %5497), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5499 : Float(204:262656, 255:513, 255:1) = aten::copy_(%5496, %5498, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5500 : int[] = prim::ListConstruct(%5383, %5387, %5385, %143), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5501 : Float(17:3151872, 12:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores.23, %5500), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.34 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::transpose(%5501, %124, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:525:0
  %5503 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5504 : Float(256:257, 257:1) = aten::ones(%5503, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:458:0
  %5505 : Float(256:257, 257:1) = aten::tril(%5504, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:458:0
  %5506 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %beginning_mask_2d.23 : Float(256:257, 257:1) = aten::flip(%5505, %5506), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:458:0
  %5508 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d.23, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:459:0
  %5509 : Float(1:65792, 256:257, 257:1) = aten::slice(%5508, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:459:0
  %5510 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%5509, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask.23 : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%5510, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:459:0
  %5512 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %ending_mask.23 : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask.23, %5512), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:460:0
  %5514 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.34, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:461:0
  %5515 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%5514, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:461:0
  %5516 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%5515, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input.23 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%5516, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:461:0
  %5518 : int = aten::size(%beginning_input.23, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:462:0
  %5519 : int = aten::size(%beginning_input.23, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:462:0
  %5520 : int = aten::size(%beginning_input.23, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:462:0
  %5521 : int = aten::size(%beginning_input.23, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:462:0
  %5522 : int[] = prim::ListConstruct(%5518, %5519, %5520, %5521), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5523 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%beginning_mask.23, %5522, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:462:0
  %5524 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%5523, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/tensor.py:22:0
  %5525 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%beginning_input.23, %5524, %153), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:463:0
  %5526 : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::slice(%input_tensor.34, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:464:0
  %5527 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%5526, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:464:0
  %5528 : Float(17:3151872, 256:513, 12:262656, 513:1) = aten::slice(%5527, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input.23 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::slice(%5528, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:464:0
  %5530 : int = aten::size(%ending_input.23, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:465:0
  %5531 : int = aten::size(%ending_input.23, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:465:0
  %5532 : int = aten::size(%ending_input.23, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:465:0
  %5533 : int = aten::size(%ending_input.23, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:465:0
  %5534 : int[] = prim::ListConstruct(%5530, %5531, %5532, %5533), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5535 : Float(17:0, 256:257, 12:0, 257:1) = aten::expand(%ending_mask.23, %5534, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:465:0
  %5536 : Bool(17:789504, 256:3084, 12:257, 257:1) = aten::eq(%5535, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/tensor.py:22:0
  %5537 : Float(17:3151872, 256:513, 12:262656, 257:1) = aten::masked_fill_(%ending_input.23, %5536, %153), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:466:0
  %5538 : Bool(17:512, 512:1) = aten::ne(%5355, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/tensor.py:22:0
  %5539 : Bool(17:512, 512:1) = aten::slice(%5538, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:272:0
  %5540 : Bool(17:512, 512:1) = aten::slice(%5539, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:272:0
  %5541 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%5540, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:272:0
  %remove_from_windowed_attention_mask : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%5541, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:272:0
  %5543 : Float(17:512, 512:1, 1:1, 1:1) = aten::type_as(%remove_from_windowed_attention_mask, %query.23), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:275:0
  %float_mask : Float(17:512, 512:1, 1:1, 1:1) = aten::masked_fill(%5543, %remove_from_windowed_attention_mask, %155), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:275:0
  %5545 : int = aten::size(%float_mask, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:280:0
  %5546 : int = aten::size(%float_mask, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:280:0
  %5547 : int = aten::size(%float_mask, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:280:0
  %5548 : int = aten::size(%float_mask, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:280:0
  %5549 : int[] = prim::ListConstruct(%5545, %5546, %5547, %5548), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %query : Float(17:512, 512:1, 1:1, 1:1) = aten::ones(%5549, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:280:0
  %5551 : int = aten::size(%query, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:472:0
  %batch_size.47 : Long() = prim::NumToTensor(%5551), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5553 : int = aten::size(%query, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:472:0
  %seq_len.48 : Long() = prim::NumToTensor(%5553), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5555 : int = aten::size(%query, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:472:0
  %num_heads.35 : Long() = prim::NumToTensor(%5555), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5557 : int = aten::size(%query, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:472:0
  %5558 : Long() = aten::floor_divide(%seq_len.48, %131), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/tensor.py:424:0
  %chunks_count.35 : Long() = aten::sub(%5558, %132, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:478:0
  %5560 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%query, %125, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:481:0
  %5561 : Long() = aten::mul(%batch_size.47, %num_heads.35), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:481:0
  %5562 : int = aten::Int(%5561), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5563 : int[] = prim::ListConstruct(%5562, %5553, %5557), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %hidden_states.127 : Float(17:512, 512:1, 1:1) = aten::reshape(%5560, %5563), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:481:0
  %5565 : Float(17:512, 1:1, 512:1, 1:1) = aten::transpose(%float_mask, %125, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:482:0
  %5566 : Long() = aten::mul(%batch_size.47, %num_heads.35), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:482:0
  %5567 : int = aten::Int(%5566), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5568 : int[] = prim::ListConstruct(%5567, %5553, %5557), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %hidden_states.129 : Float(17:512, 512:1, 1:1) = aten::reshape(%5565, %5568), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:482:0
  %5570 : int = aten::size(%hidden_states.127, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:442:0
  %5571 : int = aten::size(%hidden_states.127, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:443:0
  %5572 : Long() = prim::NumToTensor(%5571), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5573 : Long() = aten::floor_divide(%5572, %133), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/tensor.py:424:0
  %5574 : int = aten::Int(%5573), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5575 : int = aten::size(%hidden_states.127, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:445:0
  %5576 : int[] = prim::ListConstruct(%5570, %5574, %134, %5575), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %hidden_states.128 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.127, %5576), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:441:0
  %5578 : int = aten::size(%hidden_states.128, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5579 : int = aten::size(%hidden_states.128, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5580 : Long() = prim::NumToTensor(%5579), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5581 : int = aten::size(%hidden_states.128, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5582 : int = aten::size(%hidden_states.128, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5583 : Long() = aten::mul(%5580, %135), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:450:0
  %5584 : Long() = aten::sub(%5583, %132, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:450:0
  %5585 : int = aten::Int(%5584), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5586 : int[] = prim::ListConstruct(%5578, %5585, %5581, %5582), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5587 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5588 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.128, %5586, %5587, %138), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:454:0
  %5589 : int = aten::size(%hidden_states.129, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:442:0
  %5590 : int = aten::size(%hidden_states.129, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:443:0
  %5591 : Long() = prim::NumToTensor(%5590), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5592 : Long() = aten::floor_divide(%5591, %133), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/tensor.py:424:0
  %5593 : int = aten::Int(%5592), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5594 : int = aten::size(%hidden_states.129, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:445:0
  %5595 : int[] = prim::ListConstruct(%5589, %5593, %134, %5594), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %hidden_states.130 : Float(17:512, 1:512, 512:1, 1:1) = aten::view(%hidden_states.129, %5595), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:441:0
  %5597 : int = aten::size(%hidden_states.130, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5598 : int = aten::size(%hidden_states.130, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5599 : Long() = prim::NumToTensor(%5598), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5600 : int = aten::size(%hidden_states.130, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5601 : int = aten::size(%hidden_states.130, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:449:0
  %5602 : Long() = aten::mul(%5599, %135), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:450:0
  %5603 : Long() = aten::sub(%5602, %132, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:450:0
  %5604 : int = aten::Int(%5603), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5605 : int[] = prim::ListConstruct(%5597, %5604, %5600, %5601), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5606 : int[] = prim::ListConstruct(%134, %142, %125, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5607 : Float(17:512, 1:256, 512:1, 1:1) = aten::as_strided(%hidden_states.130, %5605, %5606, %138), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:454:0
  %5608 : Tensor[] = prim::ListConstruct(%5588, %5607), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %input.141 : Float(17:262144, 1:262144, 512:512, 512:1) = aten::einsum(%139, %5608), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/functional.py:327:0
  %5610 : int[] = prim::ListConstruct(%126, %126, %126, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %hidden_states_padded : Float(17:262656, 1:262656, 513:512, 512:1) = aten::constant_pad_nd(%input.141, %5610, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/nn/functional.py:3552:0
  %5612 : int = aten::size(%hidden_states_padded, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:401:0
  %5613 : int = aten::size(%hidden_states_padded, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:401:0
  %5614 : int = aten::size(%hidden_states_padded, %140), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:401:0
  %5615 : int = aten::size(%hidden_states_padded, %141), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:401:0
  %5616 : int[] = prim::ListConstruct(%5612, %5613, %5614, %5615), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %diagonal_chunked_attention_scores : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%hidden_states_padded, %5616), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:400:0
  %5618 : Long() = aten::mul(%batch_size.47, %num_heads.35), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:504:0
  %5619 : int = aten::Int(%5618), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5620 : Long() = aten::add(%chunks_count.35, %132, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:504:0
  %5621 : int = aten::Int(%5620), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5622 : int[] = prim::ListConstruct(%5619, %5621, %142, %143), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %diagonal_attention_scores : Float(17:262656, 2:131328, 256:513, 513:1) = aten::new_empty(%diagonal_chunked_attention_scores, %5622, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:503:0
  %5624 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5625 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%5624, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5626 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%5625, %124, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5627 : Float(17:262656, 1:262656, 256:513, 257:1) = aten::slice(%5626, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5628 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5629 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%5628, %125, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5630 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%5629, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5631 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::slice(%5630, %130, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5632 : int[] = prim::ListConstruct(%156, %125, %142, %148), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5633 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::view(%5627, %5632), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5634 : Float(17:262656, 1:131328, 256:513, 257:1) = aten::copy_(%5631, %5633, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:509:0
  %5635 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5636 : Float(17:262656, 512:513, 513:1) = aten::select(%5635, %125, %140), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5637 : Float(17:262656, 256:513, 513:1) = aten::slice(%5636, %125, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5638 : Float(17:262656, 256:513, 257:1) = aten::slice(%5637, %124, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5639 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5640 : Float(17:262656, 256:513, 513:1) = aten::select(%5639, %125, %140), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5641 : Float(17:262656, 256:513, 513:1) = aten::slice(%5640, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5642 : Float(17:262656, 256:513, 257:1) = aten::slice(%5641, %124, %142, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5643 : int[] = prim::ListConstruct(%156, %142, %148), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5644 : Float(17:262656, 256:513, 257:1) = aten::view(%5638, %5643), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5645 : Float(17:262656, 256:513, 257:1) = aten::copy_(%5642, %5644, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:512:0
  %5646 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5647 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%5646, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5648 : Float(17:262656, 1:262656, 256:513, 513:1) = aten::slice(%5647, %124, %150, %140, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5649 : Float(17:262656, 1:262656, 256:513, 256:1) = aten::slice(%5648, %130, %148, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5650 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5651 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%5650, %125, %125, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5652 : Float(17:262656, 1:131328, 256:513, 513:1) = aten::slice(%5651, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5653 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::slice(%5652, %130, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5654 : int[] = prim::ListConstruct(%156, %125, %142, %142), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5655 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::view(%5649, %5654), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5656 : Float(17:262656, 1:131328, 256:513, 256:1) = aten::copy_(%5653, %5655, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:516:0
  %5657 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::slice(%diagonal_chunked_attention_scores, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5658 : Float(17:262656, 512:513, 513:1) = aten::select(%5657, %125, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5659 : Float(17:262656, 255:513, 513:1) = aten::slice(%5658, %125, %126, %151, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5660 : Float(17:262656, 255:513, 255:1) = aten::slice(%5659, %124, %152, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5661 : Float(17:262656, 2:131328, 256:513, 513:1) = aten::slice(%diagonal_attention_scores, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5662 : Float(17:262656, 256:513, 513:1) = aten::select(%5661, %125, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5663 : Float(17:262656, 255:513, 513:1) = aten::slice(%5662, %125, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5664 : Float(17:262656, 255:513, 255:1) = aten::slice(%5663, %124, %125, %142, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5665 : int[] = prim::ListConstruct(%156, %151, %151), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5666 : Float(17:262656, 255:513, 255:1) = aten::view(%5660, %5665), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5667 : Float(17:262656, 255:513, 255:1) = aten::copy_(%5664, %5666, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:520:0
  %5668 : int[] = prim::ListConstruct(%5551, %5555, %5553, %143), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5669 : Float(17:262656, 1:262656, 512:513, 513:1) = aten::view(%diagonal_attention_scores, %5668), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:525:0
  %input_tensor.35 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::transpose(%5669, %124, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:525:0
  %5671 : int[] = prim::ListConstruct(%142, %148), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5672 : Float(256:257, 257:1) = aten::ones(%5671, %144, %126, %145, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:458:0
  %5673 : Float(256:257, 257:1) = aten::tril(%5672, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:458:0
  %5674 : int[] = prim::ListConstruct(%126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %beginning_mask_2d : Float(256:257, 257:1) = aten::flip(%5673, %5674), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:458:0
  %5676 : Float(1:65792, 256:257, 257:1) = aten::unsqueeze(%beginning_mask_2d, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:459:0
  %5677 : Float(1:65792, 256:257, 257:1) = aten::slice(%5676, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:459:0
  %5678 : Float(1:65792, 256:257, 1:257, 257:1) = aten::unsqueeze(%5677, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:459:0
  %beginning_mask : Float(1:65792, 256:257, 1:257, 257:1) = aten::slice(%5678, %130, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:459:0
  %5680 : int[] = prim::ListConstruct(%125, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %ending_mask : Float(1:65792, 256:257, 1:257, 257:1) = aten::flip(%beginning_mask, %5680), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:460:0
  %5682 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.35, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:461:0
  %5683 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%5682, %125, %126, %142, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:461:0
  %5684 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%5683, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:461:0
  %beginning_input : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%5684, %130, %126, %148, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:461:0
  %5686 : int = aten::size(%beginning_input, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:462:0
  %5687 : int = aten::size(%beginning_input, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:462:0
  %5688 : int = aten::size(%beginning_input, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:462:0
  %5689 : int = aten::size(%beginning_input, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:462:0
  %5690 : int[] = prim::ListConstruct(%5686, %5687, %5688, %5689), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5691 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%beginning_mask, %5690, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:462:0
  %5692 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%5691, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/tensor.py:22:0
  %5693 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%beginning_input, %5692, %153), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:463:0
  %5694 : Float(17:262656, 512:513, 1:262656, 513:1) = aten::slice(%input_tensor.35, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:464:0
  %5695 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%5694, %125, %154, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:464:0
  %5696 : Float(17:262656, 256:513, 1:262656, 513:1) = aten::slice(%5695, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:464:0
  %ending_input : Float(17:262656, 256:513, 1:262656, 257:1) = aten::slice(%5696, %130, %150, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:464:0
  %5698 : int = aten::size(%ending_input, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:465:0
  %5699 : int = aten::size(%ending_input, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:465:0
  %5700 : int = aten::size(%ending_input, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:465:0
  %5701 : int = aten::size(%ending_input, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:465:0
  %5702 : int[] = prim::ListConstruct(%5698, %5699, %5700, %5701), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5703 : Float(17:0, 256:257, 1:257, 257:1) = aten::expand(%ending_mask, %5702, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:465:0
  %5704 : Bool(17:65792, 256:257, 1:257, 257:1) = aten::eq(%5703, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/tensor.py:22:0
  %5705 : Float(17:262656, 256:513, 1:262656, 257:1) = aten::masked_fill_(%ending_input, %5704, %153), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:466:0
  %attn_scores : Float(17:3151872, 512:513, 12:262656, 513:1) = aten::add_(%input_tensor.34, %input_tensor.35, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:284:0
  %attn_probs_fp32 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::softmax(%attn_scores, %140, %144), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/nn/functional.py:1500:0
  %5708 : Bool(17:512, 512:1) = aten::slice(%is_index_masked, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:326:0
  %5709 : Bool(17:512, 512:1) = aten::slice(%5708, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:326:0
  %5710 : Bool(17:512, 512:1, 1:1) = aten::unsqueeze(%5709, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:326:0
  %5711 : Bool(17:512, 512:1, 1:1, 1:1) = aten::unsqueeze(%5710, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:326:0
  %input.142 : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::masked_fill(%attn_probs_fp32, %5711, %157), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:326:0
  %attn_probs : Float(17:3151872, 512:6156, 12:513, 513:1) = aten::dropout(%input.142, %158, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/nn/functional.py:973:0
  %5714 : int[] = prim::ListConstruct(%5373, %5374, %128, %129), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5715 : Float(512:13056, 17:768, 12:64, 64:1) = aten::view(%value_vectors, %5714), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:331:0
  %value : Float(17:768, 512:13056, 12:64, 64:1) = aten::transpose(%5715, %126, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:331:0
  %5717 : int = aten::size(%value, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:537:0
  %batch_size : Long() = prim::NumToTensor(%5717), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5719 : int = aten::size(%value, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:537:0
  %seq_len : Long() = prim::NumToTensor(%5719), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5721 : int = aten::size(%value, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:537:0
  %num_heads : Long() = prim::NumToTensor(%5721), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5723 : int = aten::size(%value, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:537:0
  %5724 : Long() = aten::floor_divide(%seq_len, %131), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/tensor.py:424:0
  %chunks_count : Long() = aten::sub(%5724, %132, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:542:0
  %5726 : Float(17:3151872, 12:513, 512:6156, 513:1) = aten::transpose(%attn_probs, %125, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:545:0
  %5727 : Long() = aten::mul(%batch_size, %num_heads), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:546:0
  %5728 : int = aten::Int(%5727), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5729 : Long() = aten::floor_divide(%seq_len, %131), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/tensor.py:424:0
  %5730 : int = aten::Int(%5729), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5731 : int[] = prim::ListConstruct(%5728, %5730, %142, %143), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %chunked_hidden_states.56 : Float(204:262656, 2:131328, 256:513, 513:1) = aten::reshape(%5726, %5731), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:545:0
  %5733 : Float(17:768, 12:64, 512:13056, 64:1) = aten::transpose(%value, %125, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:550:0
  %5734 : Long() = aten::mul(%batch_size, %num_heads), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:550:0
  %5735 : int = aten::Int(%5734), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5736 : int[] = prim::ListConstruct(%5735, %5719, %5723), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %input.143 : Float(204:64, 512:13056, 64:1) = aten::reshape(%5733, %5736), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:550:0
  %5738 : int[] = prim::ListConstruct(%126, %126, %142, %142), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %padded_value : Float(204:65536, 1024:64, 64:1) = aten::constant_pad_nd(%input.143, %5738, %140), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/nn/functional.py:3552:0
  %5740 : Long() = aten::mul(%batch_size, %num_heads), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:556:0
  %5741 : int = aten::Int(%5740), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5742 : Long() = aten::add(%chunks_count, %132, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:556:0
  %5743 : int = aten::Int(%5742), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5744 : int[] = prim::ListConstruct(%5741, %5743, %159, %5723), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5745 : int[] = prim::ListConstruct(%160, %161, %129, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5746 : Float(204:65536, 2:16384, 768:64, 64:1) = aten::as_strided(%padded_value, %5744, %5745, %138), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:564:0
  %5747 : int = aten::size(%chunked_hidden_states.56, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:420:0
  %5748 : int = aten::size(%chunked_hidden_states.56, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:420:0
  %5749 : int = aten::size(%chunked_hidden_states.56, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:420:0
  %window_overlap : Long() = prim::NumToTensor(%5749), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5751 : int = aten::size(%chunked_hidden_states.56, %130), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:420:0
  %hidden_dim : Long() = prim::NumToTensor(%5751), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5753 : Long() = aten::add(%window_overlap, %132, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:422:0
  %5754 : int = aten::Int(%5753), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5755 : int[] = prim::ListConstruct(%126, %5754), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %chunked_hidden_states.57 : Float(204:394240, 2:197120, 256:770, 770:1) = aten::constant_pad_nd(%chunked_hidden_states.56, %5755, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/nn/functional.py:3552:0
  %5757 : int[] = prim::ListConstruct(%5747, %5748, %140), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %chunked_hidden_states.58 : Float(204:394240, 2:197120, 197120:1) = aten::view(%chunked_hidden_states.57, %5757), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:424:0
  %5759 : Long() = aten::neg(%window_overlap), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:428:0
  %5760 : int = aten::Int(%5759), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5761 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%chunked_hidden_states.58, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:427:0
  %5762 : Float(204:394240, 2:197120, 197120:1) = aten::slice(%5761, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:427:0
  %chunked_hidden_states.59 : Float(204:394240, 2:197120, 196864:1) = aten::slice(%5762, %124, %126, %5760, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:427:0
  %5764 : Long() = aten::add(%window_overlap, %hidden_dim, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:431:0
  %5765 : int = aten::Int(%5764), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5766 : int[] = prim::ListConstruct(%5747, %5748, %5749, %5765), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %chunked_hidden_states : Float(204:394240, 2:197120, 256:769, 769:1) = aten::view(%chunked_hidden_states.59, %5766), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:430:0
  %5768 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%chunked_hidden_states, %126, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:433:0
  %5769 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%5768, %125, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:433:0
  %5770 : Float(204:394240, 2:197120, 256:769, 769:1) = aten::slice(%5769, %124, %126, %147, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:433:0
  %5771 : Float(204:394240, 2:197120, 256:769, 768:1) = aten::slice(%5770, %130, %126, %140, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:433:0
  %5772 : Tensor[] = prim::ListConstruct(%5771, %5746), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %context : Float(204:32768, 2:16384, 256:64, 64:1) = aten::einsum(%162, %5772), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/functional.py:327:0
  %5774 : int[] = prim::ListConstruct(%5717, %5721, %5719, %5723), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5775 : Float(17:393216, 12:32768, 512:64, 64:1) = aten::view(%context, %5774), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:569:0
  %attn_output.23 : Float(17:393216, 512:64, 12:32768, 64:1) = aten::transpose(%5775, %125, %124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:569:0
  %5777 : Float(512:64, 17:393216, 12:32768, 64:1) = aten::transpose(%attn_output.23, %126, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:350:0
  %5778 : int[] = prim::ListConstruct(%5373, %5374, %5375), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %5779 : Float(512:13056, 17:768, 768:1) = aten::reshape(%5777, %5778), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:350:0
  %attn_output : Float(512:13056, 17:768, 768:1) = aten::contiguous(%5779, %126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:350:0
  %input.144 : Float(17:768, 512:13056, 768:1) = aten::transpose(%attn_output, %126, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_longformer.py:374:0
  %5782 : __torch__.torch.nn.modules.normalization.___torch_mangle_8267.LayerNorm = prim::GetAttr[name="LayerNorm"](%5349)
  %5783 : __torch__.torch.nn.modules.linear.___torch_mangle_8266.Linear = prim::GetAttr[name="dense"](%5349)
  %5784 : Tensor = prim::GetAttr[name="bias"](%5783)
  %5785 : Tensor = prim::GetAttr[name="weight"](%5783)
  %5786 : Float(768:1, 768:768) = aten::t(%5785), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %output.70 : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.144, %5786), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %input.145 : Float(17:393216, 512:768, 768:1) = aten::add_(%output.70, %5784, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.131 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.145, %158, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.dropout # torch/nn/functional.py:973:0
  %input.146 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.131, %hidden_states.122, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output # transformers/modeling_longformer.py:758:0
  %5791 : Tensor = prim::GetAttr[name="bias"](%5782)
  %5792 : Tensor = prim::GetAttr[name="weight"](%5782)
  %5793 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.LayerNorm
  %input_tensor : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.146, %5793, %5792, %5791, %123, %122), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %5795 : __torch__.torch.nn.modules.linear.___torch_mangle_8271.Linear = prim::GetAttr[name="dense"](%5347)
  %5796 : Tensor = prim::GetAttr[name="bias"](%5795)
  %5797 : Tensor = prim::GetAttr[name="weight"](%5795)
  %5798 : Float(768:1, 3072:768) = aten::t(%5797), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.intermediate/__module.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %output.71 : Float(17:1572864, 512:3072, 3072:1) = aten::matmul(%input_tensor, %5798), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.intermediate/__module.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %input.147 : Float(17:1572864, 512:3072, 3072:1) = aten::add_(%output.71, %5796, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.intermediate/__module.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1678:0
  %input.148 : Float(17:1572864, 512:3072, 3072:1) = aten::gelu(%input.147), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.intermediate # torch/nn/functional.py:1369:0
  %5802 : __torch__.torch.nn.modules.normalization.___torch_mangle_8274.LayerNorm = prim::GetAttr[name="LayerNorm"](%5346)
  %5803 : __torch__.torch.nn.modules.linear.___torch_mangle_8273.Linear = prim::GetAttr[name="dense"](%5346)
  %5804 : Tensor = prim::GetAttr[name="bias"](%5803)
  %5805 : Tensor = prim::GetAttr[name="weight"](%5803)
  %5806 : Float(3072:1, 768:3072) = aten::t(%5805), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %output : Float(17:393216, 512:768, 768:1) = aten::matmul(%input.148, %5806), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %input.149 : Float(17:393216, 512:768, 768:1) = aten::add_(%output, %5804, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.132 : Float(17:393216, 512:768, 768:1) = aten::dropout(%input.149, %158, %146), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.dropout # torch/nn/functional.py:973:0
  %input.150 : Float(17:393216, 512:768, 768:1) = aten::add(%hidden_states.132, %input_tensor, %125), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output # transformers/modeling_longformer.py:830:0
  %5811 : Tensor = prim::GetAttr[name="bias"](%5802)
  %5812 : Tensor = prim::GetAttr[name="weight"](%5802)
  %5813 : int[] = prim::ListConstruct(%159), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.LayerNorm
  %hidden_states : Float(17:393216, 512:768, 768:1) = aten::layer_norm(%input.150, %5813, %5812, %5811, %123, %122), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.LayerNorm # torch/nn/functional.py:2048:0
  %5815 : int = prim::Constant[value=1](), scope: __module.pooler # transformers/modeling_longformer.py:934:0
  %5816 : int = prim::Constant[value=9223372036854775807](), scope: __module.pooler # transformers/modeling_longformer.py:934:0
  %5817 : int = prim::Constant[value=0](), scope: __module.pooler # transformers/modeling_longformer.py:934:0
  %5818 : __torch__.torch.nn.modules.linear.___torch_mangle_8280.Linear = prim::GetAttr[name="dense"](%3)
  %5819 : Float(17:393216, 512:768, 768:1) = aten::slice(%hidden_states, %5817, %5817, %5816, %5815), scope: __module.pooler # transformers/modeling_longformer.py:934:0
  %input.151 : Float(17:393216, 768:1) = aten::select(%5819, %5815, %5817), scope: __module.pooler # transformers/modeling_longformer.py:934:0
  %5821 : Tensor = prim::GetAttr[name="bias"](%5818)
  %5822 : Tensor = prim::GetAttr[name="weight"](%5818)
  %5823 : Float(768:1, 768:768) = aten::t(%5822), scope: __module.pooler/__module.pooler.dense # torch/nn/functional.py:1674:0
  %input : Float(17:768, 768:1) = aten::addmm(%5821, %input.151, %5823, %5815, %5815), scope: __module.pooler/__module.pooler.dense # torch/nn/functional.py:1674:0
  %5825 : Float(17:768, 768:1) = aten::tanh(%input), scope: __module.pooler/__module.pooler.activation # torch/nn/modules/activation.py:350:0
  %72 : Long() = aten::neg(%padding_len) # transformers/modeling_longformer.py:1275:0
  %73 : int = aten::Int(%72)
  %74 : int = prim::Constant[value=0]() # transformers/modeling_longformer.py:1275:0
  %75 : int = prim::Constant[value=0]() # transformers/modeling_longformer.py:1275:0
  %76 : int = prim::Constant[value=9223372036854775807]() # transformers/modeling_longformer.py:1275:0
  %77 : int = prim::Constant[value=1]() # transformers/modeling_longformer.py:1275:0
  %78 : Float(17:393216, 512:768, 768:1) = aten::slice(%hidden_states, %74, %75, %76, %77) # transformers/modeling_longformer.py:1275:0
  %79 : int = prim::Constant[value=1]() # transformers/modeling_longformer.py:1275:0
  %80 : int = prim::Constant[value=0]() # transformers/modeling_longformer.py:1275:0
  %81 : int = prim::Constant[value=1]() # transformers/modeling_longformer.py:1275:0
  %82 : Float(17:393216, 13:768, 768:1) = aten::slice(%78, %79, %80, %73, %81) # transformers/modeling_longformer.py:1275:0
  %83 : (Float(17:393216, 13:768, 768:1), Float(17:768, 768:1)) = prim::TupleConstruct(%82, %5825)
  return (%83)
