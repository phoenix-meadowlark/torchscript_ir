graph(%self.1 : __torch__.transformers.modeling_bert.___torch_mangle_6358.BertModel,
      %input_ids : Long(17:13, 13:1),
      %attention_mask.1 : Long(17:13, 13:1)):
  %3 : __torch__.transformers.modeling_bert.___torch_mangle_6357.BertPooler = prim::GetAttr[name="pooler"](%self.1)
  %4 : __torch__.transformers.modeling_bert.___torch_mangle_6354.BertEncoder = prim::GetAttr[name="encoder"](%self.1)
  %5 : __torch__.transformers.modeling_bert.___torch_mangle_6148.BertEmbeddings = prim::GetAttr[name="embeddings"](%self.1)
  %6 : int = prim::Constant[value=0]() # transformers/modeling_bert.py:795:0
  %7 : int = aten::size(%input_ids, %6) # transformers/modeling_bert.py:795:0
  %8 : Long() = prim::NumToTensor(%7)
  %9 : int = aten::Int(%8)
  %10 : int = prim::Constant[value=1]() # transformers/modeling_bert.py:795:0
  %11 : int = aten::size(%input_ids, %10) # transformers/modeling_bert.py:795:0
  %12 : Long() = prim::NumToTensor(%11)
  %13 : int = aten::Int(%12)
  %14 : int[] = prim::ListConstruct(%9, %13)
  %15 : int = prim::Constant[value=4]() # transformers/modeling_bert.py:806:0
  %16 : int = prim::Constant[value=0]() # transformers/modeling_bert.py:806:0
  %17 : Device = prim::Constant[value="cpu"]() # transformers/modeling_bert.py:806:0
  %18 : bool = prim::Constant[value=0]() # transformers/modeling_bert.py:806:0
  %input.2 : Long(17:13, 13:1) = aten::zeros(%14, %15, %16, %17, %18) # transformers/modeling_bert.py:806:0
  %20 : int = prim::Constant[value=0]() # transformers/modeling_utils.py:244:0
  %21 : int = prim::Constant[value=0]() # transformers/modeling_utils.py:244:0
  %22 : int = prim::Constant[value=9223372036854775807]() # transformers/modeling_utils.py:244:0
  %23 : int = prim::Constant[value=1]() # transformers/modeling_utils.py:244:0
  %24 : Long(17:13, 13:1) = aten::slice(%attention_mask.1, %20, %21, %22, %23) # transformers/modeling_utils.py:244:0
  %25 : int = prim::Constant[value=1]() # transformers/modeling_utils.py:244:0
  %26 : Long(17:13, 1:13, 13:1) = aten::unsqueeze(%24, %25) # transformers/modeling_utils.py:244:0
  %27 : int = prim::Constant[value=2]() # transformers/modeling_utils.py:244:0
  %28 : Long(17:13, 1:13, 1:13, 13:1) = aten::unsqueeze(%26, %27) # transformers/modeling_utils.py:244:0
  %29 : int = prim::Constant[value=3]() # transformers/modeling_utils.py:244:0
  %30 : int = prim::Constant[value=0]() # transformers/modeling_utils.py:244:0
  %31 : int = prim::Constant[value=9223372036854775807]() # transformers/modeling_utils.py:244:0
  %32 : int = prim::Constant[value=1]() # transformers/modeling_utils.py:244:0
  %extended_attention_mask : Long(17:13, 1:13, 1:13, 13:1) = aten::slice(%28, %29, %30, %31, %32) # transformers/modeling_utils.py:244:0
  %34 : int = prim::Constant[value=6]() # transformers/modeling_utils.py:257:0
  %35 : bool = prim::Constant[value=0]() # transformers/modeling_utils.py:257:0
  %36 : bool = prim::Constant[value=0]() # transformers/modeling_utils.py:257:0
  %37 : None = prim::Constant()
  %38 : Float(17:13, 1:13, 1:13, 13:1) = aten::to(%extended_attention_mask, %34, %35, %36, %37) # transformers/modeling_utils.py:257:0
  %39 : float = prim::Constant[value=1.]() # torch/tensor.py:396:0
  %40 : int = prim::Constant[value=1]() # torch/tensor.py:396:0
  %41 : Float(17:13, 1:13, 1:13, 13:1) = aten::rsub(%38, %39, %40) # torch/tensor.py:396:0
  %42 : Double() = prim::Constant[value={-10000}]() # transformers/modeling_utils.py:258:0
  %attention_mask : Float(17:13, 1:13, 1:13, 13:1) = aten::mul(%41, %42) # transformers/modeling_utils.py:258:0
  %48 : float = prim::Constant[value=0.10000000000000001](), scope: __module.embeddings/__module.embeddings.dropout # torch/nn/functional.py:973:0
  %49 : int = prim::Constant[value=768](), scope: __module.embeddings/__module.embeddings.LayerNorm # torch/nn/functional.py:2048:0
  %50 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.embeddings/__module.embeddings.LayerNorm # torch/nn/functional.py:2048:0
  %51 : bool = prim::Constant[value=1](), scope: __module.embeddings/__module.embeddings.LayerNorm # torch/nn/functional.py:2048:0
  %52 : int = prim::Constant[value=-1](), scope: __module.embeddings/__module.embeddings.position_embeddings # torch/nn/functional.py:1814:0
  %53 : bool = prim::Constant[value=0](), scope: __module.embeddings/__module.embeddings.word_embeddings # torch/nn/functional.py:1814:0
  %54 : int = prim::Constant[value=9223372036854775807](), scope: __module.embeddings # transformers/modeling_bert.py:191:0
  %55 : int = prim::Constant[value=0](), scope: __module.embeddings # transformers/modeling_bert.py:191:0
  %56 : int = prim::Constant[value=1](), scope: __module.embeddings # transformers/modeling_bert.py:184:0
  %57 : __torch__.torch.nn.modules.normalization.___torch_mangle_6146.LayerNorm = prim::GetAttr[name="LayerNorm"](%5)
  %58 : __torch__.torch.nn.modules.sparse.___torch_mangle_6145.Embedding = prim::GetAttr[name="token_type_embeddings"](%5)
  %59 : __torch__.torch.nn.modules.sparse.___torch_mangle_6144.Embedding = prim::GetAttr[name="position_embeddings"](%5)
  %60 : __torch__.torch.nn.modules.sparse.___torch_mangle_6143.Embedding = prim::GetAttr[name="word_embeddings"](%5)
  %61 : Tensor = prim::GetAttr[name="position_ids"](%5)
  %62 : int = aten::size(%input_ids, %56), scope: __module.embeddings # transformers/modeling_bert.py:184:0
  %63 : Long(1:512, 512:1) = aten::slice(%61, %55, %55, %54, %56), scope: __module.embeddings # transformers/modeling_bert.py:191:0
  %input.1 : Long(1:512, 13:1) = aten::slice(%63, %56, %55, %62, %56), scope: __module.embeddings # transformers/modeling_bert.py:191:0
  %65 : Tensor = prim::GetAttr[name="weight"](%60)
  %inputs_embeds : Float(17:9984, 13:768, 768:1) = aten::embedding(%65, %input_ids, %55, %53, %53), scope: __module.embeddings/__module.embeddings.word_embeddings # torch/nn/functional.py:1814:0
  %67 : Tensor = prim::GetAttr[name="weight"](%59)
  %position_embeddings : Float(1:9984, 13:768, 768:1) = aten::embedding(%67, %input.1, %52, %53, %53), scope: __module.embeddings/__module.embeddings.position_embeddings # torch/nn/functional.py:1814:0
  %69 : Tensor = prim::GetAttr[name="weight"](%58)
  %token_type_embeddings : Float(17:9984, 13:768, 768:1) = aten::embedding(%69, %input.2, %52, %53, %53), scope: __module.embeddings/__module.embeddings.token_type_embeddings # torch/nn/functional.py:1814:0
  %71 : Float(17:9984, 13:768, 768:1) = aten::add(%inputs_embeds, %position_embeddings, %56), scope: __module.embeddings # transformers/modeling_bert.py:201:0
  %input.3 : Float(17:9984, 13:768, 768:1) = aten::add(%71, %token_type_embeddings, %56), scope: __module.embeddings # transformers/modeling_bert.py:201:0
  %73 : Tensor = prim::GetAttr[name="bias"](%57)
  %74 : Tensor = prim::GetAttr[name="weight"](%57)
  %75 : int[] = prim::ListConstruct(%49), scope: __module.embeddings/__module.embeddings.LayerNorm
  %input.4 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.3, %75, %74, %73, %50, %51), scope: __module.embeddings/__module.embeddings.LayerNorm # torch/nn/functional.py:2048:0
  %input.5 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.4, %48, %53), scope: __module.embeddings/__module.embeddings.dropout # torch/nn/functional.py:973:0
  %78 : bool = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %79 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %80 : int = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # torch/nn/functional.py:1678:0
  %81 : int = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:227:0
  %82 : int = prim::Constant[value=12](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:228:0
  %83 : int = prim::Constant[value=64](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:228:0
  %84 : int = prim::Constant[value=2](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:229:0
  %85 : int = prim::Constant[value=3](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:229:0
  %86 : int = prim::Constant[value=-1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:258:0
  %87 : int = prim::Constant[value=-2](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:258:0
  %88 : Double() = prim::Constant[value={8}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:259:0
  %89 : None = prim::Constant(), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %90 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %91 : float = prim::Constant[value=0.10000000000000001](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %92 : int = prim::Constant[value=768](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:279:0
  %93 : __torch__.torch.nn.modules.container.___torch_mangle_6353.ModuleList = prim::GetAttr[name="layer"](%4)
  %94 : __torch__.transformers.modeling_bert.___torch_mangle_6352.BertLayer = prim::GetAttr[name="11"](%93)
  %95 : __torch__.torch.nn.modules.container.___torch_mangle_6353.ModuleList = prim::GetAttr[name="layer"](%4)
  %96 : __torch__.transformers.modeling_bert.___torch_mangle_6335.BertLayer = prim::GetAttr[name="10"](%95)
  %97 : __torch__.torch.nn.modules.container.___torch_mangle_6353.ModuleList = prim::GetAttr[name="layer"](%4)
  %98 : __torch__.transformers.modeling_bert.___torch_mangle_6318.BertLayer = prim::GetAttr[name="9"](%97)
  %99 : __torch__.torch.nn.modules.container.___torch_mangle_6353.ModuleList = prim::GetAttr[name="layer"](%4)
  %100 : __torch__.transformers.modeling_bert.___torch_mangle_6301.BertLayer = prim::GetAttr[name="8"](%99)
  %101 : __torch__.torch.nn.modules.container.___torch_mangle_6353.ModuleList = prim::GetAttr[name="layer"](%4)
  %102 : __torch__.transformers.modeling_bert.___torch_mangle_6284.BertLayer = prim::GetAttr[name="7"](%101)
  %103 : __torch__.torch.nn.modules.container.___torch_mangle_6353.ModuleList = prim::GetAttr[name="layer"](%4)
  %104 : __torch__.transformers.modeling_bert.___torch_mangle_6267.BertLayer = prim::GetAttr[name="6"](%103)
  %105 : __torch__.torch.nn.modules.container.___torch_mangle_6353.ModuleList = prim::GetAttr[name="layer"](%4)
  %106 : __torch__.transformers.modeling_bert.___torch_mangle_6250.BertLayer = prim::GetAttr[name="5"](%105)
  %107 : __torch__.torch.nn.modules.container.___torch_mangle_6353.ModuleList = prim::GetAttr[name="layer"](%4)
  %108 : __torch__.transformers.modeling_bert.___torch_mangle_6233.BertLayer = prim::GetAttr[name="4"](%107)
  %109 : __torch__.torch.nn.modules.container.___torch_mangle_6353.ModuleList = prim::GetAttr[name="layer"](%4)
  %110 : __torch__.transformers.modeling_bert.___torch_mangle_6216.BertLayer = prim::GetAttr[name="3"](%109)
  %111 : __torch__.torch.nn.modules.container.___torch_mangle_6353.ModuleList = prim::GetAttr[name="layer"](%4)
  %112 : __torch__.transformers.modeling_bert.___torch_mangle_6199.BertLayer = prim::GetAttr[name="2"](%111)
  %113 : __torch__.torch.nn.modules.container.___torch_mangle_6353.ModuleList = prim::GetAttr[name="layer"](%4)
  %114 : __torch__.transformers.modeling_bert.___torch_mangle_6182.BertLayer = prim::GetAttr[name="1"](%113)
  %115 : __torch__.torch.nn.modules.container.___torch_mangle_6353.ModuleList = prim::GetAttr[name="layer"](%4)
  %116 : __torch__.transformers.modeling_bert.___torch_mangle_6165.BertLayer = prim::GetAttr[name="0"](%115)
  %117 : __torch__.transformers.modeling_bert.___torch_mangle_6164.BertOutput = prim::GetAttr[name="output"](%116)
  %118 : __torch__.transformers.modeling_bert.___torch_mangle_6160.BertIntermediate = prim::GetAttr[name="intermediate"](%116)
  %119 : __torch__.transformers.modeling_bert.___torch_mangle_6158.BertAttention = prim::GetAttr[name="attention"](%116)
  %120 : __torch__.transformers.modeling_bert.___torch_mangle_6157.BertSelfOutput = prim::GetAttr[name="output"](%119)
  %121 : __torch__.transformers.modeling_bert.___torch_mangle_6153.BertSelfAttention = prim::GetAttr[name="self"](%119)
  %122 : __torch__.torch.nn.modules.linear.___torch_mangle_6151.Linear = prim::GetAttr[name="value"](%121)
  %123 : __torch__.torch.nn.modules.linear.___torch_mangle_6150.Linear = prim::GetAttr[name="key"](%121)
  %124 : __torch__.torch.nn.modules.linear.___torch_mangle_6149.Linear = prim::GetAttr[name="query"](%121)
  %125 : Tensor = prim::GetAttr[name="bias"](%124)
  %126 : Tensor = prim::GetAttr[name="weight"](%124)
  %127 : Float(768:1, 768:768) = aten::t(%126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %output.1 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.5, %127), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %x.1 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.1, %125, %80), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # torch/nn/functional.py:1678:0
  %130 : Tensor = prim::GetAttr[name="bias"](%123)
  %131 : Tensor = prim::GetAttr[name="weight"](%123)
  %132 : Float(768:1, 768:768) = aten::t(%131), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %output.2 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.5, %132), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %x.3 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.2, %130, %80), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # torch/nn/functional.py:1678:0
  %135 : Tensor = prim::GetAttr[name="bias"](%122)
  %136 : Tensor = prim::GetAttr[name="weight"](%122)
  %137 : Float(768:1, 768:768) = aten::t(%136), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %output.3 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.5, %137), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %x.5 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.3, %135, %80), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # torch/nn/functional.py:1678:0
  %140 : int = aten::size(%x.1, %81), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:227:0
  %141 : int = aten::size(%x.1, %80), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:227:0
  %142 : int[] = prim::ListConstruct(%140, %141, %82, %83), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %x.2 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.1, %142), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:228:0
  %144 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %query_layer.1 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.2, %144), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:229:0
  %146 : int = aten::size(%x.3, %81), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:227:0
  %147 : int = aten::size(%x.3, %80), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:227:0
  %148 : int[] = prim::ListConstruct(%146, %147, %82, %83), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %x.4 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.3, %148), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:228:0
  %150 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %key_layer.1 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.4, %150), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:229:0
  %152 : int = aten::size(%x.5, %81), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:227:0
  %153 : int = aten::size(%x.5, %80), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:227:0
  %154 : int[] = prim::ListConstruct(%152, %153, %82, %83), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %x.6 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.5, %154), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:228:0
  %156 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %value_layer.1 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.6, %156), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:229:0
  %158 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_layer.1, %86, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.1 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_layer.1, %158), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.2 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%attention_scores.1, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:259:0
  %input.6 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%attention_scores.2, %attention_mask, %80), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:262:0
  %input.7 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.6, %86, %89), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.1 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.7, %91, %90), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.1 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.1, %value_layer.1), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:275:0
  %165 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %166 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%context_layer.1, %165), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:277:0
  %context_layer.2 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%166, %81), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:277:0
  %168 : int = aten::size(%context_layer.2, %81), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:278:0
  %169 : int = aten::size(%context_layer.2, %80), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:278:0
  %170 : int[] = prim::ListConstruct(%168, %169, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %input.8 : Float(17:9984, 13:768, 768:1) = aten::view(%context_layer.2, %170), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_bert.py:279:0
  %172 : __torch__.torch.nn.modules.normalization.___torch_mangle_6155.LayerNorm = prim::GetAttr[name="LayerNorm"](%120)
  %173 : __torch__.torch.nn.modules.linear.___torch_mangle_6154.Linear = prim::GetAttr[name="dense"](%120)
  %174 : Tensor = prim::GetAttr[name="bias"](%173)
  %175 : Tensor = prim::GetAttr[name="weight"](%173)
  %176 : Float(768:1, 768:768) = aten::t(%175), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %output.4 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.8, %176), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %input.9 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.4, %174, %80), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.1 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.9, %91, %90), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dropout # torch/nn/functional.py:973:0
  %input.10 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.1, %input.5, %80), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output # transformers/modeling_bert.py:295:0
  %181 : Tensor = prim::GetAttr[name="bias"](%172)
  %182 : Tensor = prim::GetAttr[name="weight"](%172)
  %183 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm
  %input_tensor.1 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.10, %183, %182, %181, %79, %78), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %185 : __torch__.torch.nn.modules.linear.___torch_mangle_6159.Linear = prim::GetAttr[name="dense"](%118)
  %186 : Tensor = prim::GetAttr[name="bias"](%185)
  %187 : Tensor = prim::GetAttr[name="weight"](%185)
  %188 : Float(768:1, 3072:768) = aten::t(%187), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.5 : Float(17:39936, 13:3072, 3072:1) = aten::matmul(%input_tensor.1, %188), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.11 : Float(17:39936, 13:3072, 3072:1) = aten::add_(%output.5, %186, %80), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.12 : Float(17:39936, 13:3072, 3072:1) = aten::gelu(%input.11), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # torch/nn/functional.py:1369:0
  %192 : __torch__.torch.nn.modules.normalization.___torch_mangle_6162.LayerNorm = prim::GetAttr[name="LayerNorm"](%117)
  %193 : __torch__.torch.nn.modules.linear.___torch_mangle_6161.Linear = prim::GetAttr[name="dense"](%117)
  %194 : Tensor = prim::GetAttr[name="bias"](%193)
  %195 : Tensor = prim::GetAttr[name="weight"](%193)
  %196 : Float(3072:1, 768:3072) = aten::t(%195), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %output.6 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.12, %196), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %input.13 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.6, %194, %80), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.2 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.13, %91, %90), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dropout # torch/nn/functional.py:973:0
  %input.14 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.2, %input_tensor.1, %80), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output # transformers/modeling_bert.py:371:0
  %201 : Tensor = prim::GetAttr[name="bias"](%192)
  %202 : Tensor = prim::GetAttr[name="weight"](%192)
  %203 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.LayerNorm
  %input.15 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.14, %203, %202, %201, %79, %78), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.LayerNorm # torch/nn/functional.py:2048:0
  %205 : __torch__.transformers.modeling_bert.___torch_mangle_6181.BertOutput = prim::GetAttr[name="output"](%114)
  %206 : __torch__.transformers.modeling_bert.___torch_mangle_6177.BertIntermediate = prim::GetAttr[name="intermediate"](%114)
  %207 : __torch__.transformers.modeling_bert.___torch_mangle_6175.BertAttention = prim::GetAttr[name="attention"](%114)
  %208 : __torch__.transformers.modeling_bert.___torch_mangle_6174.BertSelfOutput = prim::GetAttr[name="output"](%207)
  %209 : __torch__.transformers.modeling_bert.___torch_mangle_6170.BertSelfAttention = prim::GetAttr[name="self"](%207)
  %210 : __torch__.torch.nn.modules.linear.___torch_mangle_6168.Linear = prim::GetAttr[name="value"](%209)
  %211 : __torch__.torch.nn.modules.linear.___torch_mangle_6167.Linear = prim::GetAttr[name="key"](%209)
  %212 : __torch__.torch.nn.modules.linear.___torch_mangle_6166.Linear = prim::GetAttr[name="query"](%209)
  %213 : Tensor = prim::GetAttr[name="bias"](%212)
  %214 : Tensor = prim::GetAttr[name="weight"](%212)
  %215 : Float(768:1, 768:768) = aten::t(%214), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %output.7 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.15, %215), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %x.7 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.7, %213, %80), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # torch/nn/functional.py:1678:0
  %218 : Tensor = prim::GetAttr[name="bias"](%211)
  %219 : Tensor = prim::GetAttr[name="weight"](%211)
  %220 : Float(768:1, 768:768) = aten::t(%219), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %output.8 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.15, %220), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %x.9 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.8, %218, %80), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # torch/nn/functional.py:1678:0
  %223 : Tensor = prim::GetAttr[name="bias"](%210)
  %224 : Tensor = prim::GetAttr[name="weight"](%210)
  %225 : Float(768:1, 768:768) = aten::t(%224), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %output.9 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.15, %225), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %x.11 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.9, %223, %80), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # torch/nn/functional.py:1678:0
  %228 : int = aten::size(%x.7, %81), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:227:0
  %229 : int = aten::size(%x.7, %80), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:227:0
  %230 : int[] = prim::ListConstruct(%228, %229, %82, %83), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %x.8 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.7, %230), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:228:0
  %232 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %query_layer.2 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.8, %232), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:229:0
  %234 : int = aten::size(%x.9, %81), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:227:0
  %235 : int = aten::size(%x.9, %80), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:227:0
  %236 : int[] = prim::ListConstruct(%234, %235, %82, %83), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %x.10 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.9, %236), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:228:0
  %238 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %key_layer.2 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.10, %238), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:229:0
  %240 : int = aten::size(%x.11, %81), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:227:0
  %241 : int = aten::size(%x.11, %80), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:227:0
  %242 : int[] = prim::ListConstruct(%240, %241, %82, %83), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %x.12 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.11, %242), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:228:0
  %244 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %value_layer.2 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.12, %244), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:229:0
  %246 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_layer.2, %86, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.3 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_layer.2, %246), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.4 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%attention_scores.3, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:259:0
  %input.16 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%attention_scores.4, %attention_mask, %80), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:262:0
  %input.17 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.16, %86, %89), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.2 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.17, %91, %90), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.3 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.2, %value_layer.2), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:275:0
  %253 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %254 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%context_layer.3, %253), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:277:0
  %context_layer.4 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%254, %81), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:277:0
  %256 : int = aten::size(%context_layer.4, %81), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:278:0
  %257 : int = aten::size(%context_layer.4, %80), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:278:0
  %258 : int[] = prim::ListConstruct(%256, %257, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %input.18 : Float(17:9984, 13:768, 768:1) = aten::view(%context_layer.4, %258), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_bert.py:279:0
  %260 : __torch__.torch.nn.modules.normalization.___torch_mangle_6172.LayerNorm = prim::GetAttr[name="LayerNorm"](%208)
  %261 : __torch__.torch.nn.modules.linear.___torch_mangle_6171.Linear = prim::GetAttr[name="dense"](%208)
  %262 : Tensor = prim::GetAttr[name="bias"](%261)
  %263 : Tensor = prim::GetAttr[name="weight"](%261)
  %264 : Float(768:1, 768:768) = aten::t(%263), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %output.10 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.18, %264), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %input.19 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.10, %262, %80), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.3 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.19, %91, %90), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dropout # torch/nn/functional.py:973:0
  %input.20 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.3, %input.15, %80), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output # transformers/modeling_bert.py:295:0
  %269 : Tensor = prim::GetAttr[name="bias"](%260)
  %270 : Tensor = prim::GetAttr[name="weight"](%260)
  %271 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.LayerNorm
  %input_tensor.2 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.20, %271, %270, %269, %79, %78), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %273 : __torch__.torch.nn.modules.linear.___torch_mangle_6176.Linear = prim::GetAttr[name="dense"](%206)
  %274 : Tensor = prim::GetAttr[name="bias"](%273)
  %275 : Tensor = prim::GetAttr[name="weight"](%273)
  %276 : Float(768:1, 3072:768) = aten::t(%275), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.11 : Float(17:39936, 13:3072, 3072:1) = aten::matmul(%input_tensor.2, %276), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.21 : Float(17:39936, 13:3072, 3072:1) = aten::add_(%output.11, %274, %80), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.22 : Float(17:39936, 13:3072, 3072:1) = aten::gelu(%input.21), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # torch/nn/functional.py:1369:0
  %280 : __torch__.torch.nn.modules.normalization.___torch_mangle_6179.LayerNorm = prim::GetAttr[name="LayerNorm"](%205)
  %281 : __torch__.torch.nn.modules.linear.___torch_mangle_6178.Linear = prim::GetAttr[name="dense"](%205)
  %282 : Tensor = prim::GetAttr[name="bias"](%281)
  %283 : Tensor = prim::GetAttr[name="weight"](%281)
  %284 : Float(3072:1, 768:3072) = aten::t(%283), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %output.12 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.22, %284), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %input.23 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.12, %282, %80), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.4 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.23, %91, %90), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dropout # torch/nn/functional.py:973:0
  %input.24 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.4, %input_tensor.2, %80), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output # transformers/modeling_bert.py:371:0
  %289 : Tensor = prim::GetAttr[name="bias"](%280)
  %290 : Tensor = prim::GetAttr[name="weight"](%280)
  %291 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.LayerNorm
  %input.25 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.24, %291, %290, %289, %79, %78), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.LayerNorm # torch/nn/functional.py:2048:0
  %293 : __torch__.transformers.modeling_bert.___torch_mangle_6198.BertOutput = prim::GetAttr[name="output"](%112)
  %294 : __torch__.transformers.modeling_bert.___torch_mangle_6194.BertIntermediate = prim::GetAttr[name="intermediate"](%112)
  %295 : __torch__.transformers.modeling_bert.___torch_mangle_6192.BertAttention = prim::GetAttr[name="attention"](%112)
  %296 : __torch__.transformers.modeling_bert.___torch_mangle_6191.BertSelfOutput = prim::GetAttr[name="output"](%295)
  %297 : __torch__.transformers.modeling_bert.___torch_mangle_6187.BertSelfAttention = prim::GetAttr[name="self"](%295)
  %298 : __torch__.torch.nn.modules.linear.___torch_mangle_6185.Linear = prim::GetAttr[name="value"](%297)
  %299 : __torch__.torch.nn.modules.linear.___torch_mangle_6184.Linear = prim::GetAttr[name="key"](%297)
  %300 : __torch__.torch.nn.modules.linear.___torch_mangle_6183.Linear = prim::GetAttr[name="query"](%297)
  %301 : Tensor = prim::GetAttr[name="bias"](%300)
  %302 : Tensor = prim::GetAttr[name="weight"](%300)
  %303 : Float(768:1, 768:768) = aten::t(%302), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %output.13 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.25, %303), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %x.13 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.13, %301, %80), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.query # torch/nn/functional.py:1678:0
  %306 : Tensor = prim::GetAttr[name="bias"](%299)
  %307 : Tensor = prim::GetAttr[name="weight"](%299)
  %308 : Float(768:1, 768:768) = aten::t(%307), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %output.14 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.25, %308), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %x.15 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.14, %306, %80), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.key # torch/nn/functional.py:1678:0
  %311 : Tensor = prim::GetAttr[name="bias"](%298)
  %312 : Tensor = prim::GetAttr[name="weight"](%298)
  %313 : Float(768:1, 768:768) = aten::t(%312), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %output.15 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.25, %313), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %x.17 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.15, %311, %80), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.value # torch/nn/functional.py:1678:0
  %316 : int = aten::size(%x.13, %81), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:227:0
  %317 : int = aten::size(%x.13, %80), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:227:0
  %318 : int[] = prim::ListConstruct(%316, %317, %82, %83), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %x.14 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.13, %318), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:228:0
  %320 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %query_layer.3 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.14, %320), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:229:0
  %322 : int = aten::size(%x.15, %81), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:227:0
  %323 : int = aten::size(%x.15, %80), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:227:0
  %324 : int[] = prim::ListConstruct(%322, %323, %82, %83), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %x.16 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.15, %324), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:228:0
  %326 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %key_layer.3 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.16, %326), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:229:0
  %328 : int = aten::size(%x.17, %81), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:227:0
  %329 : int = aten::size(%x.17, %80), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:227:0
  %330 : int[] = prim::ListConstruct(%328, %329, %82, %83), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %x.18 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.17, %330), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:228:0
  %332 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %value_layer.3 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.18, %332), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:229:0
  %334 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_layer.3, %86, %87), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.5 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_layer.3, %334), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.6 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%attention_scores.5, %88), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:259:0
  %input.26 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%attention_scores.6, %attention_mask, %80), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:262:0
  %input.27 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.26, %86, %89), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.3 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.27, %91, %90), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.5 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.3, %value_layer.3), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:275:0
  %341 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %342 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%context_layer.5, %341), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:277:0
  %context_layer.6 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%342, %81), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:277:0
  %344 : int = aten::size(%context_layer.6, %81), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:278:0
  %345 : int = aten::size(%context_layer.6, %80), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:278:0
  %346 : int[] = prim::ListConstruct(%344, %345, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %input.28 : Float(17:9984, 13:768, 768:1) = aten::view(%context_layer.6, %346), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_bert.py:279:0
  %348 : __torch__.torch.nn.modules.normalization.___torch_mangle_6189.LayerNorm = prim::GetAttr[name="LayerNorm"](%296)
  %349 : __torch__.torch.nn.modules.linear.___torch_mangle_6188.Linear = prim::GetAttr[name="dense"](%296)
  %350 : Tensor = prim::GetAttr[name="bias"](%349)
  %351 : Tensor = prim::GetAttr[name="weight"](%349)
  %352 : Float(768:1, 768:768) = aten::t(%351), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %output.16 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.28, %352), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %input.29 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.16, %350, %80), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.5 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.29, %91, %90), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.dropout # torch/nn/functional.py:973:0
  %input.30 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.5, %input.25, %80), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output # transformers/modeling_bert.py:295:0
  %357 : Tensor = prim::GetAttr[name="bias"](%348)
  %358 : Tensor = prim::GetAttr[name="weight"](%348)
  %359 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.LayerNorm
  %input_tensor.3 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.30, %359, %358, %357, %79, %78), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %361 : __torch__.torch.nn.modules.linear.___torch_mangle_6193.Linear = prim::GetAttr[name="dense"](%294)
  %362 : Tensor = prim::GetAttr[name="bias"](%361)
  %363 : Tensor = prim::GetAttr[name="weight"](%361)
  %364 : Float(768:1, 3072:768) = aten::t(%363), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.intermediate/__module.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.17 : Float(17:39936, 13:3072, 3072:1) = aten::matmul(%input_tensor.3, %364), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.intermediate/__module.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.31 : Float(17:39936, 13:3072, 3072:1) = aten::add_(%output.17, %362, %80), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.intermediate/__module.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.32 : Float(17:39936, 13:3072, 3072:1) = aten::gelu(%input.31), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.intermediate # torch/nn/functional.py:1369:0
  %368 : __torch__.torch.nn.modules.normalization.___torch_mangle_6196.LayerNorm = prim::GetAttr[name="LayerNorm"](%293)
  %369 : __torch__.torch.nn.modules.linear.___torch_mangle_6195.Linear = prim::GetAttr[name="dense"](%293)
  %370 : Tensor = prim::GetAttr[name="bias"](%369)
  %371 : Tensor = prim::GetAttr[name="weight"](%369)
  %372 : Float(3072:1, 768:3072) = aten::t(%371), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %output.18 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.32, %372), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %input.33 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.18, %370, %80), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.6 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.33, %91, %90), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.dropout # torch/nn/functional.py:973:0
  %input.34 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.6, %input_tensor.3, %80), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output # transformers/modeling_bert.py:371:0
  %377 : Tensor = prim::GetAttr[name="bias"](%368)
  %378 : Tensor = prim::GetAttr[name="weight"](%368)
  %379 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.LayerNorm
  %input.35 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.34, %379, %378, %377, %79, %78), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.LayerNorm # torch/nn/functional.py:2048:0
  %381 : __torch__.transformers.modeling_bert.___torch_mangle_6215.BertOutput = prim::GetAttr[name="output"](%110)
  %382 : __torch__.transformers.modeling_bert.___torch_mangle_6211.BertIntermediate = prim::GetAttr[name="intermediate"](%110)
  %383 : __torch__.transformers.modeling_bert.___torch_mangle_6209.BertAttention = prim::GetAttr[name="attention"](%110)
  %384 : __torch__.transformers.modeling_bert.___torch_mangle_6208.BertSelfOutput = prim::GetAttr[name="output"](%383)
  %385 : __torch__.transformers.modeling_bert.___torch_mangle_6204.BertSelfAttention = prim::GetAttr[name="self"](%383)
  %386 : __torch__.torch.nn.modules.linear.___torch_mangle_6202.Linear = prim::GetAttr[name="value"](%385)
  %387 : __torch__.torch.nn.modules.linear.___torch_mangle_6201.Linear = prim::GetAttr[name="key"](%385)
  %388 : __torch__.torch.nn.modules.linear.___torch_mangle_6200.Linear = prim::GetAttr[name="query"](%385)
  %389 : Tensor = prim::GetAttr[name="bias"](%388)
  %390 : Tensor = prim::GetAttr[name="weight"](%388)
  %391 : Float(768:1, 768:768) = aten::t(%390), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %output.19 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.35, %391), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %x.19 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.19, %389, %80), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.query # torch/nn/functional.py:1678:0
  %394 : Tensor = prim::GetAttr[name="bias"](%387)
  %395 : Tensor = prim::GetAttr[name="weight"](%387)
  %396 : Float(768:1, 768:768) = aten::t(%395), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %output.20 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.35, %396), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %x.21 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.20, %394, %80), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.key # torch/nn/functional.py:1678:0
  %399 : Tensor = prim::GetAttr[name="bias"](%386)
  %400 : Tensor = prim::GetAttr[name="weight"](%386)
  %401 : Float(768:1, 768:768) = aten::t(%400), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %output.21 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.35, %401), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %x.23 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.21, %399, %80), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.value # torch/nn/functional.py:1678:0
  %404 : int = aten::size(%x.19, %81), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:227:0
  %405 : int = aten::size(%x.19, %80), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:227:0
  %406 : int[] = prim::ListConstruct(%404, %405, %82, %83), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %x.20 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.19, %406), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:228:0
  %408 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %query_layer.4 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.20, %408), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:229:0
  %410 : int = aten::size(%x.21, %81), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:227:0
  %411 : int = aten::size(%x.21, %80), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:227:0
  %412 : int[] = prim::ListConstruct(%410, %411, %82, %83), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %x.22 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.21, %412), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:228:0
  %414 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %key_layer.4 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.22, %414), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:229:0
  %416 : int = aten::size(%x.23, %81), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:227:0
  %417 : int = aten::size(%x.23, %80), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:227:0
  %418 : int[] = prim::ListConstruct(%416, %417, %82, %83), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %x.24 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.23, %418), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:228:0
  %420 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %value_layer.4 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.24, %420), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:229:0
  %422 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_layer.4, %86, %87), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.7 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_layer.4, %422), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.8 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%attention_scores.7, %88), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:259:0
  %input.36 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%attention_scores.8, %attention_mask, %80), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:262:0
  %input.37 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.36, %86, %89), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.4 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.37, %91, %90), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.7 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.4, %value_layer.4), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:275:0
  %429 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %430 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%context_layer.7, %429), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:277:0
  %context_layer.8 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%430, %81), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:277:0
  %432 : int = aten::size(%context_layer.8, %81), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:278:0
  %433 : int = aten::size(%context_layer.8, %80), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:278:0
  %434 : int[] = prim::ListConstruct(%432, %433, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %input.38 : Float(17:9984, 13:768, 768:1) = aten::view(%context_layer.8, %434), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_bert.py:279:0
  %436 : __torch__.torch.nn.modules.normalization.___torch_mangle_6206.LayerNorm = prim::GetAttr[name="LayerNorm"](%384)
  %437 : __torch__.torch.nn.modules.linear.___torch_mangle_6205.Linear = prim::GetAttr[name="dense"](%384)
  %438 : Tensor = prim::GetAttr[name="bias"](%437)
  %439 : Tensor = prim::GetAttr[name="weight"](%437)
  %440 : Float(768:1, 768:768) = aten::t(%439), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %output.22 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.38, %440), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %input.39 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.22, %438, %80), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.7 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.39, %91, %90), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.dropout # torch/nn/functional.py:973:0
  %input.40 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.7, %input.35, %80), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output # transformers/modeling_bert.py:295:0
  %445 : Tensor = prim::GetAttr[name="bias"](%436)
  %446 : Tensor = prim::GetAttr[name="weight"](%436)
  %447 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.LayerNorm
  %input_tensor.4 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.40, %447, %446, %445, %79, %78), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %449 : __torch__.torch.nn.modules.linear.___torch_mangle_6210.Linear = prim::GetAttr[name="dense"](%382)
  %450 : Tensor = prim::GetAttr[name="bias"](%449)
  %451 : Tensor = prim::GetAttr[name="weight"](%449)
  %452 : Float(768:1, 3072:768) = aten::t(%451), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.intermediate/__module.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %output.23 : Float(17:39936, 13:3072, 3072:1) = aten::matmul(%input_tensor.4, %452), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.intermediate/__module.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %input.41 : Float(17:39936, 13:3072, 3072:1) = aten::add_(%output.23, %450, %80), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.intermediate/__module.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1678:0
  %input.42 : Float(17:39936, 13:3072, 3072:1) = aten::gelu(%input.41), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.intermediate # torch/nn/functional.py:1369:0
  %456 : __torch__.torch.nn.modules.normalization.___torch_mangle_6213.LayerNorm = prim::GetAttr[name="LayerNorm"](%381)
  %457 : __torch__.torch.nn.modules.linear.___torch_mangle_6212.Linear = prim::GetAttr[name="dense"](%381)
  %458 : Tensor = prim::GetAttr[name="bias"](%457)
  %459 : Tensor = prim::GetAttr[name="weight"](%457)
  %460 : Float(3072:1, 768:3072) = aten::t(%459), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %output.24 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.42, %460), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %input.43 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.24, %458, %80), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.8 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.43, %91, %90), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.dropout # torch/nn/functional.py:973:0
  %input.44 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.8, %input_tensor.4, %80), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output # transformers/modeling_bert.py:371:0
  %465 : Tensor = prim::GetAttr[name="bias"](%456)
  %466 : Tensor = prim::GetAttr[name="weight"](%456)
  %467 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.LayerNorm
  %input.45 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.44, %467, %466, %465, %79, %78), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.LayerNorm # torch/nn/functional.py:2048:0
  %469 : __torch__.transformers.modeling_bert.___torch_mangle_6232.BertOutput = prim::GetAttr[name="output"](%108)
  %470 : __torch__.transformers.modeling_bert.___torch_mangle_6228.BertIntermediate = prim::GetAttr[name="intermediate"](%108)
  %471 : __torch__.transformers.modeling_bert.___torch_mangle_6226.BertAttention = prim::GetAttr[name="attention"](%108)
  %472 : __torch__.transformers.modeling_bert.___torch_mangle_6225.BertSelfOutput = prim::GetAttr[name="output"](%471)
  %473 : __torch__.transformers.modeling_bert.___torch_mangle_6221.BertSelfAttention = prim::GetAttr[name="self"](%471)
  %474 : __torch__.torch.nn.modules.linear.___torch_mangle_6219.Linear = prim::GetAttr[name="value"](%473)
  %475 : __torch__.torch.nn.modules.linear.___torch_mangle_6218.Linear = prim::GetAttr[name="key"](%473)
  %476 : __torch__.torch.nn.modules.linear.___torch_mangle_6217.Linear = prim::GetAttr[name="query"](%473)
  %477 : Tensor = prim::GetAttr[name="bias"](%476)
  %478 : Tensor = prim::GetAttr[name="weight"](%476)
  %479 : Float(768:1, 768:768) = aten::t(%478), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %output.25 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.45, %479), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %x.25 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.25, %477, %80), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.query # torch/nn/functional.py:1678:0
  %482 : Tensor = prim::GetAttr[name="bias"](%475)
  %483 : Tensor = prim::GetAttr[name="weight"](%475)
  %484 : Float(768:1, 768:768) = aten::t(%483), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %output.26 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.45, %484), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %x.27 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.26, %482, %80), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.key # torch/nn/functional.py:1678:0
  %487 : Tensor = prim::GetAttr[name="bias"](%474)
  %488 : Tensor = prim::GetAttr[name="weight"](%474)
  %489 : Float(768:1, 768:768) = aten::t(%488), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %output.27 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.45, %489), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %x.29 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.27, %487, %80), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.value # torch/nn/functional.py:1678:0
  %492 : int = aten::size(%x.25, %81), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:227:0
  %493 : int = aten::size(%x.25, %80), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:227:0
  %494 : int[] = prim::ListConstruct(%492, %493, %82, %83), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %x.26 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.25, %494), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:228:0
  %496 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %query_layer.5 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.26, %496), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:229:0
  %498 : int = aten::size(%x.27, %81), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:227:0
  %499 : int = aten::size(%x.27, %80), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:227:0
  %500 : int[] = prim::ListConstruct(%498, %499, %82, %83), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %x.28 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.27, %500), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:228:0
  %502 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %key_layer.5 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.28, %502), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:229:0
  %504 : int = aten::size(%x.29, %81), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:227:0
  %505 : int = aten::size(%x.29, %80), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:227:0
  %506 : int[] = prim::ListConstruct(%504, %505, %82, %83), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %x.30 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.29, %506), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:228:0
  %508 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %value_layer.5 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.30, %508), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:229:0
  %510 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_layer.5, %86, %87), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.9 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_layer.5, %510), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.10 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%attention_scores.9, %88), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:259:0
  %input.46 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%attention_scores.10, %attention_mask, %80), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:262:0
  %input.47 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.46, %86, %89), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.5 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.47, %91, %90), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.9 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.5, %value_layer.5), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:275:0
  %517 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %518 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%context_layer.9, %517), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:277:0
  %context_layer.10 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%518, %81), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:277:0
  %520 : int = aten::size(%context_layer.10, %81), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:278:0
  %521 : int = aten::size(%context_layer.10, %80), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:278:0
  %522 : int[] = prim::ListConstruct(%520, %521, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %input.48 : Float(17:9984, 13:768, 768:1) = aten::view(%context_layer.10, %522), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_bert.py:279:0
  %524 : __torch__.torch.nn.modules.normalization.___torch_mangle_6223.LayerNorm = prim::GetAttr[name="LayerNorm"](%472)
  %525 : __torch__.torch.nn.modules.linear.___torch_mangle_6222.Linear = prim::GetAttr[name="dense"](%472)
  %526 : Tensor = prim::GetAttr[name="bias"](%525)
  %527 : Tensor = prim::GetAttr[name="weight"](%525)
  %528 : Float(768:1, 768:768) = aten::t(%527), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %output.28 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.48, %528), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %input.49 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.28, %526, %80), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.9 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.49, %91, %90), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.dropout # torch/nn/functional.py:973:0
  %input.50 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.9, %input.45, %80), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output # transformers/modeling_bert.py:295:0
  %533 : Tensor = prim::GetAttr[name="bias"](%524)
  %534 : Tensor = prim::GetAttr[name="weight"](%524)
  %535 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.LayerNorm
  %input_tensor.5 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.50, %535, %534, %533, %79, %78), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %537 : __torch__.torch.nn.modules.linear.___torch_mangle_6227.Linear = prim::GetAttr[name="dense"](%470)
  %538 : Tensor = prim::GetAttr[name="bias"](%537)
  %539 : Tensor = prim::GetAttr[name="weight"](%537)
  %540 : Float(768:1, 3072:768) = aten::t(%539), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.intermediate/__module.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %output.29 : Float(17:39936, 13:3072, 3072:1) = aten::matmul(%input_tensor.5, %540), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.intermediate/__module.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %input.51 : Float(17:39936, 13:3072, 3072:1) = aten::add_(%output.29, %538, %80), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.intermediate/__module.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1678:0
  %input.52 : Float(17:39936, 13:3072, 3072:1) = aten::gelu(%input.51), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.intermediate # torch/nn/functional.py:1369:0
  %544 : __torch__.torch.nn.modules.normalization.___torch_mangle_6230.LayerNorm = prim::GetAttr[name="LayerNorm"](%469)
  %545 : __torch__.torch.nn.modules.linear.___torch_mangle_6229.Linear = prim::GetAttr[name="dense"](%469)
  %546 : Tensor = prim::GetAttr[name="bias"](%545)
  %547 : Tensor = prim::GetAttr[name="weight"](%545)
  %548 : Float(3072:1, 768:3072) = aten::t(%547), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %output.30 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.52, %548), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %input.53 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.30, %546, %80), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.10 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.53, %91, %90), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.dropout # torch/nn/functional.py:973:0
  %input.54 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.10, %input_tensor.5, %80), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output # transformers/modeling_bert.py:371:0
  %553 : Tensor = prim::GetAttr[name="bias"](%544)
  %554 : Tensor = prim::GetAttr[name="weight"](%544)
  %555 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.LayerNorm
  %input.55 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.54, %555, %554, %553, %79, %78), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.LayerNorm # torch/nn/functional.py:2048:0
  %557 : __torch__.transformers.modeling_bert.___torch_mangle_6249.BertOutput = prim::GetAttr[name="output"](%106)
  %558 : __torch__.transformers.modeling_bert.___torch_mangle_6245.BertIntermediate = prim::GetAttr[name="intermediate"](%106)
  %559 : __torch__.transformers.modeling_bert.___torch_mangle_6243.BertAttention = prim::GetAttr[name="attention"](%106)
  %560 : __torch__.transformers.modeling_bert.___torch_mangle_6242.BertSelfOutput = prim::GetAttr[name="output"](%559)
  %561 : __torch__.transformers.modeling_bert.___torch_mangle_6238.BertSelfAttention = prim::GetAttr[name="self"](%559)
  %562 : __torch__.torch.nn.modules.linear.___torch_mangle_6236.Linear = prim::GetAttr[name="value"](%561)
  %563 : __torch__.torch.nn.modules.linear.___torch_mangle_6235.Linear = prim::GetAttr[name="key"](%561)
  %564 : __torch__.torch.nn.modules.linear.___torch_mangle_6234.Linear = prim::GetAttr[name="query"](%561)
  %565 : Tensor = prim::GetAttr[name="bias"](%564)
  %566 : Tensor = prim::GetAttr[name="weight"](%564)
  %567 : Float(768:1, 768:768) = aten::t(%566), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %output.31 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.55, %567), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %x.31 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.31, %565, %80), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.query # torch/nn/functional.py:1678:0
  %570 : Tensor = prim::GetAttr[name="bias"](%563)
  %571 : Tensor = prim::GetAttr[name="weight"](%563)
  %572 : Float(768:1, 768:768) = aten::t(%571), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %output.32 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.55, %572), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %x.33 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.32, %570, %80), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.key # torch/nn/functional.py:1678:0
  %575 : Tensor = prim::GetAttr[name="bias"](%562)
  %576 : Tensor = prim::GetAttr[name="weight"](%562)
  %577 : Float(768:1, 768:768) = aten::t(%576), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %output.33 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.55, %577), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %x.35 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.33, %575, %80), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.value # torch/nn/functional.py:1678:0
  %580 : int = aten::size(%x.31, %81), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:227:0
  %581 : int = aten::size(%x.31, %80), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:227:0
  %582 : int[] = prim::ListConstruct(%580, %581, %82, %83), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %x.32 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.31, %582), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:228:0
  %584 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %query_layer.6 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.32, %584), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:229:0
  %586 : int = aten::size(%x.33, %81), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:227:0
  %587 : int = aten::size(%x.33, %80), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:227:0
  %588 : int[] = prim::ListConstruct(%586, %587, %82, %83), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %x.34 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.33, %588), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:228:0
  %590 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %key_layer.6 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.34, %590), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:229:0
  %592 : int = aten::size(%x.35, %81), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:227:0
  %593 : int = aten::size(%x.35, %80), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:227:0
  %594 : int[] = prim::ListConstruct(%592, %593, %82, %83), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %x.36 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.35, %594), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:228:0
  %596 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %value_layer.6 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.36, %596), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:229:0
  %598 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_layer.6, %86, %87), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.11 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_layer.6, %598), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.12 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%attention_scores.11, %88), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:259:0
  %input.56 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%attention_scores.12, %attention_mask, %80), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:262:0
  %input.57 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.56, %86, %89), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.6 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.57, %91, %90), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.11 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.6, %value_layer.6), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:275:0
  %605 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %606 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%context_layer.11, %605), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:277:0
  %context_layer.12 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%606, %81), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:277:0
  %608 : int = aten::size(%context_layer.12, %81), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:278:0
  %609 : int = aten::size(%context_layer.12, %80), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:278:0
  %610 : int[] = prim::ListConstruct(%608, %609, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %input.58 : Float(17:9984, 13:768, 768:1) = aten::view(%context_layer.12, %610), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_bert.py:279:0
  %612 : __torch__.torch.nn.modules.normalization.___torch_mangle_6240.LayerNorm = prim::GetAttr[name="LayerNorm"](%560)
  %613 : __torch__.torch.nn.modules.linear.___torch_mangle_6239.Linear = prim::GetAttr[name="dense"](%560)
  %614 : Tensor = prim::GetAttr[name="bias"](%613)
  %615 : Tensor = prim::GetAttr[name="weight"](%613)
  %616 : Float(768:1, 768:768) = aten::t(%615), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %output.34 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.58, %616), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %input.59 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.34, %614, %80), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.11 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.59, %91, %90), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.dropout # torch/nn/functional.py:973:0
  %input.60 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.11, %input.55, %80), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output # transformers/modeling_bert.py:295:0
  %621 : Tensor = prim::GetAttr[name="bias"](%612)
  %622 : Tensor = prim::GetAttr[name="weight"](%612)
  %623 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.LayerNorm
  %input_tensor.6 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.60, %623, %622, %621, %79, %78), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %625 : __torch__.torch.nn.modules.linear.___torch_mangle_6244.Linear = prim::GetAttr[name="dense"](%558)
  %626 : Tensor = prim::GetAttr[name="bias"](%625)
  %627 : Tensor = prim::GetAttr[name="weight"](%625)
  %628 : Float(768:1, 3072:768) = aten::t(%627), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.intermediate/__module.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %output.35 : Float(17:39936, 13:3072, 3072:1) = aten::matmul(%input_tensor.6, %628), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.intermediate/__module.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %input.61 : Float(17:39936, 13:3072, 3072:1) = aten::add_(%output.35, %626, %80), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.intermediate/__module.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1678:0
  %input.62 : Float(17:39936, 13:3072, 3072:1) = aten::gelu(%input.61), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.intermediate # torch/nn/functional.py:1369:0
  %632 : __torch__.torch.nn.modules.normalization.___torch_mangle_6247.LayerNorm = prim::GetAttr[name="LayerNorm"](%557)
  %633 : __torch__.torch.nn.modules.linear.___torch_mangle_6246.Linear = prim::GetAttr[name="dense"](%557)
  %634 : Tensor = prim::GetAttr[name="bias"](%633)
  %635 : Tensor = prim::GetAttr[name="weight"](%633)
  %636 : Float(3072:1, 768:3072) = aten::t(%635), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %output.36 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.62, %636), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %input.63 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.36, %634, %80), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.12 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.63, %91, %90), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.dropout # torch/nn/functional.py:973:0
  %input.64 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.12, %input_tensor.6, %80), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output # transformers/modeling_bert.py:371:0
  %641 : Tensor = prim::GetAttr[name="bias"](%632)
  %642 : Tensor = prim::GetAttr[name="weight"](%632)
  %643 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.LayerNorm
  %input.65 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.64, %643, %642, %641, %79, %78), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.LayerNorm # torch/nn/functional.py:2048:0
  %645 : __torch__.transformers.modeling_bert.___torch_mangle_6266.BertOutput = prim::GetAttr[name="output"](%104)
  %646 : __torch__.transformers.modeling_bert.___torch_mangle_6262.BertIntermediate = prim::GetAttr[name="intermediate"](%104)
  %647 : __torch__.transformers.modeling_bert.___torch_mangle_6260.BertAttention = prim::GetAttr[name="attention"](%104)
  %648 : __torch__.transformers.modeling_bert.___torch_mangle_6259.BertSelfOutput = prim::GetAttr[name="output"](%647)
  %649 : __torch__.transformers.modeling_bert.___torch_mangle_6255.BertSelfAttention = prim::GetAttr[name="self"](%647)
  %650 : __torch__.torch.nn.modules.linear.___torch_mangle_6253.Linear = prim::GetAttr[name="value"](%649)
  %651 : __torch__.torch.nn.modules.linear.___torch_mangle_6252.Linear = prim::GetAttr[name="key"](%649)
  %652 : __torch__.torch.nn.modules.linear.___torch_mangle_6251.Linear = prim::GetAttr[name="query"](%649)
  %653 : Tensor = prim::GetAttr[name="bias"](%652)
  %654 : Tensor = prim::GetAttr[name="weight"](%652)
  %655 : Float(768:1, 768:768) = aten::t(%654), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %output.37 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.65, %655), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %x.37 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.37, %653, %80), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.query # torch/nn/functional.py:1678:0
  %658 : Tensor = prim::GetAttr[name="bias"](%651)
  %659 : Tensor = prim::GetAttr[name="weight"](%651)
  %660 : Float(768:1, 768:768) = aten::t(%659), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %output.38 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.65, %660), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %x.39 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.38, %658, %80), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.key # torch/nn/functional.py:1678:0
  %663 : Tensor = prim::GetAttr[name="bias"](%650)
  %664 : Tensor = prim::GetAttr[name="weight"](%650)
  %665 : Float(768:1, 768:768) = aten::t(%664), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %output.39 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.65, %665), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %x.41 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.39, %663, %80), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.value # torch/nn/functional.py:1678:0
  %668 : int = aten::size(%x.37, %81), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:227:0
  %669 : int = aten::size(%x.37, %80), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:227:0
  %670 : int[] = prim::ListConstruct(%668, %669, %82, %83), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %x.38 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.37, %670), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:228:0
  %672 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %query_layer.7 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.38, %672), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:229:0
  %674 : int = aten::size(%x.39, %81), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:227:0
  %675 : int = aten::size(%x.39, %80), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:227:0
  %676 : int[] = prim::ListConstruct(%674, %675, %82, %83), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %x.40 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.39, %676), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:228:0
  %678 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %key_layer.7 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.40, %678), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:229:0
  %680 : int = aten::size(%x.41, %81), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:227:0
  %681 : int = aten::size(%x.41, %80), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:227:0
  %682 : int[] = prim::ListConstruct(%680, %681, %82, %83), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %x.42 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.41, %682), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:228:0
  %684 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %value_layer.7 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.42, %684), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:229:0
  %686 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_layer.7, %86, %87), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.13 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_layer.7, %686), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.14 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%attention_scores.13, %88), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:259:0
  %input.66 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%attention_scores.14, %attention_mask, %80), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:262:0
  %input.67 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.66, %86, %89), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.7 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.67, %91, %90), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.13 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.7, %value_layer.7), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:275:0
  %693 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %694 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%context_layer.13, %693), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:277:0
  %context_layer.14 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%694, %81), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:277:0
  %696 : int = aten::size(%context_layer.14, %81), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:278:0
  %697 : int = aten::size(%context_layer.14, %80), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:278:0
  %698 : int[] = prim::ListConstruct(%696, %697, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %input.68 : Float(17:9984, 13:768, 768:1) = aten::view(%context_layer.14, %698), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_bert.py:279:0
  %700 : __torch__.torch.nn.modules.normalization.___torch_mangle_6257.LayerNorm = prim::GetAttr[name="LayerNorm"](%648)
  %701 : __torch__.torch.nn.modules.linear.___torch_mangle_6256.Linear = prim::GetAttr[name="dense"](%648)
  %702 : Tensor = prim::GetAttr[name="bias"](%701)
  %703 : Tensor = prim::GetAttr[name="weight"](%701)
  %704 : Float(768:1, 768:768) = aten::t(%703), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %output.40 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.68, %704), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %input.69 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.40, %702, %80), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.13 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.69, %91, %90), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.dropout # torch/nn/functional.py:973:0
  %input.70 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.13, %input.65, %80), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output # transformers/modeling_bert.py:295:0
  %709 : Tensor = prim::GetAttr[name="bias"](%700)
  %710 : Tensor = prim::GetAttr[name="weight"](%700)
  %711 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.LayerNorm
  %input_tensor.7 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.70, %711, %710, %709, %79, %78), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %713 : __torch__.torch.nn.modules.linear.___torch_mangle_6261.Linear = prim::GetAttr[name="dense"](%646)
  %714 : Tensor = prim::GetAttr[name="bias"](%713)
  %715 : Tensor = prim::GetAttr[name="weight"](%713)
  %716 : Float(768:1, 3072:768) = aten::t(%715), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.intermediate/__module.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %output.41 : Float(17:39936, 13:3072, 3072:1) = aten::matmul(%input_tensor.7, %716), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.intermediate/__module.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %input.71 : Float(17:39936, 13:3072, 3072:1) = aten::add_(%output.41, %714, %80), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.intermediate/__module.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1678:0
  %input.72 : Float(17:39936, 13:3072, 3072:1) = aten::gelu(%input.71), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.intermediate # torch/nn/functional.py:1369:0
  %720 : __torch__.torch.nn.modules.normalization.___torch_mangle_6264.LayerNorm = prim::GetAttr[name="LayerNorm"](%645)
  %721 : __torch__.torch.nn.modules.linear.___torch_mangle_6263.Linear = prim::GetAttr[name="dense"](%645)
  %722 : Tensor = prim::GetAttr[name="bias"](%721)
  %723 : Tensor = prim::GetAttr[name="weight"](%721)
  %724 : Float(3072:1, 768:3072) = aten::t(%723), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %output.42 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.72, %724), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %input.73 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.42, %722, %80), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.14 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.73, %91, %90), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.dropout # torch/nn/functional.py:973:0
  %input.74 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.14, %input_tensor.7, %80), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output # transformers/modeling_bert.py:371:0
  %729 : Tensor = prim::GetAttr[name="bias"](%720)
  %730 : Tensor = prim::GetAttr[name="weight"](%720)
  %731 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.LayerNorm
  %input.75 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.74, %731, %730, %729, %79, %78), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.LayerNorm # torch/nn/functional.py:2048:0
  %733 : __torch__.transformers.modeling_bert.___torch_mangle_6283.BertOutput = prim::GetAttr[name="output"](%102)
  %734 : __torch__.transformers.modeling_bert.___torch_mangle_6279.BertIntermediate = prim::GetAttr[name="intermediate"](%102)
  %735 : __torch__.transformers.modeling_bert.___torch_mangle_6277.BertAttention = prim::GetAttr[name="attention"](%102)
  %736 : __torch__.transformers.modeling_bert.___torch_mangle_6276.BertSelfOutput = prim::GetAttr[name="output"](%735)
  %737 : __torch__.transformers.modeling_bert.___torch_mangle_6272.BertSelfAttention = prim::GetAttr[name="self"](%735)
  %738 : __torch__.torch.nn.modules.linear.___torch_mangle_6270.Linear = prim::GetAttr[name="value"](%737)
  %739 : __torch__.torch.nn.modules.linear.___torch_mangle_6269.Linear = prim::GetAttr[name="key"](%737)
  %740 : __torch__.torch.nn.modules.linear.___torch_mangle_6268.Linear = prim::GetAttr[name="query"](%737)
  %741 : Tensor = prim::GetAttr[name="bias"](%740)
  %742 : Tensor = prim::GetAttr[name="weight"](%740)
  %743 : Float(768:1, 768:768) = aten::t(%742), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %output.43 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.75, %743), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %x.43 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.43, %741, %80), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.query # torch/nn/functional.py:1678:0
  %746 : Tensor = prim::GetAttr[name="bias"](%739)
  %747 : Tensor = prim::GetAttr[name="weight"](%739)
  %748 : Float(768:1, 768:768) = aten::t(%747), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %output.44 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.75, %748), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %x.45 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.44, %746, %80), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.key # torch/nn/functional.py:1678:0
  %751 : Tensor = prim::GetAttr[name="bias"](%738)
  %752 : Tensor = prim::GetAttr[name="weight"](%738)
  %753 : Float(768:1, 768:768) = aten::t(%752), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %output.45 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.75, %753), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %x.47 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.45, %751, %80), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.value # torch/nn/functional.py:1678:0
  %756 : int = aten::size(%x.43, %81), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:227:0
  %757 : int = aten::size(%x.43, %80), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:227:0
  %758 : int[] = prim::ListConstruct(%756, %757, %82, %83), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %x.44 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.43, %758), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:228:0
  %760 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %query_layer.8 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.44, %760), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:229:0
  %762 : int = aten::size(%x.45, %81), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:227:0
  %763 : int = aten::size(%x.45, %80), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:227:0
  %764 : int[] = prim::ListConstruct(%762, %763, %82, %83), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %x.46 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.45, %764), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:228:0
  %766 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %key_layer.8 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.46, %766), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:229:0
  %768 : int = aten::size(%x.47, %81), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:227:0
  %769 : int = aten::size(%x.47, %80), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:227:0
  %770 : int[] = prim::ListConstruct(%768, %769, %82, %83), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %x.48 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.47, %770), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:228:0
  %772 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %value_layer.8 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.48, %772), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:229:0
  %774 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_layer.8, %86, %87), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.15 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_layer.8, %774), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.16 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%attention_scores.15, %88), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:259:0
  %input.76 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%attention_scores.16, %attention_mask, %80), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:262:0
  %input.77 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.76, %86, %89), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.8 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.77, %91, %90), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.15 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.8, %value_layer.8), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:275:0
  %781 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %782 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%context_layer.15, %781), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:277:0
  %context_layer.16 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%782, %81), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:277:0
  %784 : int = aten::size(%context_layer.16, %81), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:278:0
  %785 : int = aten::size(%context_layer.16, %80), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:278:0
  %786 : int[] = prim::ListConstruct(%784, %785, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %input.78 : Float(17:9984, 13:768, 768:1) = aten::view(%context_layer.16, %786), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_bert.py:279:0
  %788 : __torch__.torch.nn.modules.normalization.___torch_mangle_6274.LayerNorm = prim::GetAttr[name="LayerNorm"](%736)
  %789 : __torch__.torch.nn.modules.linear.___torch_mangle_6273.Linear = prim::GetAttr[name="dense"](%736)
  %790 : Tensor = prim::GetAttr[name="bias"](%789)
  %791 : Tensor = prim::GetAttr[name="weight"](%789)
  %792 : Float(768:1, 768:768) = aten::t(%791), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %output.46 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.78, %792), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %input.79 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.46, %790, %80), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.15 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.79, %91, %90), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.dropout # torch/nn/functional.py:973:0
  %input.80 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.15, %input.75, %80), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output # transformers/modeling_bert.py:295:0
  %797 : Tensor = prim::GetAttr[name="bias"](%788)
  %798 : Tensor = prim::GetAttr[name="weight"](%788)
  %799 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.LayerNorm
  %input_tensor.8 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.80, %799, %798, %797, %79, %78), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %801 : __torch__.torch.nn.modules.linear.___torch_mangle_6278.Linear = prim::GetAttr[name="dense"](%734)
  %802 : Tensor = prim::GetAttr[name="bias"](%801)
  %803 : Tensor = prim::GetAttr[name="weight"](%801)
  %804 : Float(768:1, 3072:768) = aten::t(%803), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.intermediate/__module.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %output.47 : Float(17:39936, 13:3072, 3072:1) = aten::matmul(%input_tensor.8, %804), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.intermediate/__module.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %input.81 : Float(17:39936, 13:3072, 3072:1) = aten::add_(%output.47, %802, %80), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.intermediate/__module.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1678:0
  %input.82 : Float(17:39936, 13:3072, 3072:1) = aten::gelu(%input.81), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.intermediate # torch/nn/functional.py:1369:0
  %808 : __torch__.torch.nn.modules.normalization.___torch_mangle_6281.LayerNorm = prim::GetAttr[name="LayerNorm"](%733)
  %809 : __torch__.torch.nn.modules.linear.___torch_mangle_6280.Linear = prim::GetAttr[name="dense"](%733)
  %810 : Tensor = prim::GetAttr[name="bias"](%809)
  %811 : Tensor = prim::GetAttr[name="weight"](%809)
  %812 : Float(3072:1, 768:3072) = aten::t(%811), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %output.48 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.82, %812), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %input.83 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.48, %810, %80), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.16 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.83, %91, %90), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.dropout # torch/nn/functional.py:973:0
  %input.84 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.16, %input_tensor.8, %80), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output # transformers/modeling_bert.py:371:0
  %817 : Tensor = prim::GetAttr[name="bias"](%808)
  %818 : Tensor = prim::GetAttr[name="weight"](%808)
  %819 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.LayerNorm
  %input.85 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.84, %819, %818, %817, %79, %78), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.LayerNorm # torch/nn/functional.py:2048:0
  %821 : __torch__.transformers.modeling_bert.___torch_mangle_6300.BertOutput = prim::GetAttr[name="output"](%100)
  %822 : __torch__.transformers.modeling_bert.___torch_mangle_6296.BertIntermediate = prim::GetAttr[name="intermediate"](%100)
  %823 : __torch__.transformers.modeling_bert.___torch_mangle_6294.BertAttention = prim::GetAttr[name="attention"](%100)
  %824 : __torch__.transformers.modeling_bert.___torch_mangle_6293.BertSelfOutput = prim::GetAttr[name="output"](%823)
  %825 : __torch__.transformers.modeling_bert.___torch_mangle_6289.BertSelfAttention = prim::GetAttr[name="self"](%823)
  %826 : __torch__.torch.nn.modules.linear.___torch_mangle_6287.Linear = prim::GetAttr[name="value"](%825)
  %827 : __torch__.torch.nn.modules.linear.___torch_mangle_6286.Linear = prim::GetAttr[name="key"](%825)
  %828 : __torch__.torch.nn.modules.linear.___torch_mangle_6285.Linear = prim::GetAttr[name="query"](%825)
  %829 : Tensor = prim::GetAttr[name="bias"](%828)
  %830 : Tensor = prim::GetAttr[name="weight"](%828)
  %831 : Float(768:1, 768:768) = aten::t(%830), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %output.49 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.85, %831), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %x.49 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.49, %829, %80), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.query # torch/nn/functional.py:1678:0
  %834 : Tensor = prim::GetAttr[name="bias"](%827)
  %835 : Tensor = prim::GetAttr[name="weight"](%827)
  %836 : Float(768:1, 768:768) = aten::t(%835), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %output.50 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.85, %836), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %x.51 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.50, %834, %80), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.key # torch/nn/functional.py:1678:0
  %839 : Tensor = prim::GetAttr[name="bias"](%826)
  %840 : Tensor = prim::GetAttr[name="weight"](%826)
  %841 : Float(768:1, 768:768) = aten::t(%840), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %output.51 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.85, %841), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %x.53 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.51, %839, %80), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.value # torch/nn/functional.py:1678:0
  %844 : int = aten::size(%x.49, %81), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:227:0
  %845 : int = aten::size(%x.49, %80), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:227:0
  %846 : int[] = prim::ListConstruct(%844, %845, %82, %83), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %x.50 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.49, %846), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:228:0
  %848 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %query_layer.9 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.50, %848), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:229:0
  %850 : int = aten::size(%x.51, %81), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:227:0
  %851 : int = aten::size(%x.51, %80), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:227:0
  %852 : int[] = prim::ListConstruct(%850, %851, %82, %83), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %x.52 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.51, %852), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:228:0
  %854 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %key_layer.9 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.52, %854), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:229:0
  %856 : int = aten::size(%x.53, %81), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:227:0
  %857 : int = aten::size(%x.53, %80), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:227:0
  %858 : int[] = prim::ListConstruct(%856, %857, %82, %83), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %x.54 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.53, %858), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:228:0
  %860 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %value_layer.9 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.54, %860), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:229:0
  %862 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_layer.9, %86, %87), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.17 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_layer.9, %862), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.18 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%attention_scores.17, %88), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:259:0
  %input.86 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%attention_scores.18, %attention_mask, %80), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:262:0
  %input.87 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.86, %86, %89), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.9 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.87, %91, %90), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.17 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.9, %value_layer.9), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:275:0
  %869 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %870 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%context_layer.17, %869), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:277:0
  %context_layer.18 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%870, %81), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:277:0
  %872 : int = aten::size(%context_layer.18, %81), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:278:0
  %873 : int = aten::size(%context_layer.18, %80), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:278:0
  %874 : int[] = prim::ListConstruct(%872, %873, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %input.88 : Float(17:9984, 13:768, 768:1) = aten::view(%context_layer.18, %874), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_bert.py:279:0
  %876 : __torch__.torch.nn.modules.normalization.___torch_mangle_6291.LayerNorm = prim::GetAttr[name="LayerNorm"](%824)
  %877 : __torch__.torch.nn.modules.linear.___torch_mangle_6290.Linear = prim::GetAttr[name="dense"](%824)
  %878 : Tensor = prim::GetAttr[name="bias"](%877)
  %879 : Tensor = prim::GetAttr[name="weight"](%877)
  %880 : Float(768:1, 768:768) = aten::t(%879), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %output.52 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.88, %880), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %input.89 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.52, %878, %80), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.17 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.89, %91, %90), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.dropout # torch/nn/functional.py:973:0
  %input.90 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.17, %input.85, %80), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output # transformers/modeling_bert.py:295:0
  %885 : Tensor = prim::GetAttr[name="bias"](%876)
  %886 : Tensor = prim::GetAttr[name="weight"](%876)
  %887 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.LayerNorm
  %input_tensor.9 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.90, %887, %886, %885, %79, %78), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %889 : __torch__.torch.nn.modules.linear.___torch_mangle_6295.Linear = prim::GetAttr[name="dense"](%822)
  %890 : Tensor = prim::GetAttr[name="bias"](%889)
  %891 : Tensor = prim::GetAttr[name="weight"](%889)
  %892 : Float(768:1, 3072:768) = aten::t(%891), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.intermediate/__module.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %output.53 : Float(17:39936, 13:3072, 3072:1) = aten::matmul(%input_tensor.9, %892), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.intermediate/__module.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %input.91 : Float(17:39936, 13:3072, 3072:1) = aten::add_(%output.53, %890, %80), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.intermediate/__module.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1678:0
  %input.92 : Float(17:39936, 13:3072, 3072:1) = aten::gelu(%input.91), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.intermediate # torch/nn/functional.py:1369:0
  %896 : __torch__.torch.nn.modules.normalization.___torch_mangle_6298.LayerNorm = prim::GetAttr[name="LayerNorm"](%821)
  %897 : __torch__.torch.nn.modules.linear.___torch_mangle_6297.Linear = prim::GetAttr[name="dense"](%821)
  %898 : Tensor = prim::GetAttr[name="bias"](%897)
  %899 : Tensor = prim::GetAttr[name="weight"](%897)
  %900 : Float(3072:1, 768:3072) = aten::t(%899), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %output.54 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.92, %900), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %input.93 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.54, %898, %80), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.18 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.93, %91, %90), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.dropout # torch/nn/functional.py:973:0
  %input.94 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.18, %input_tensor.9, %80), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output # transformers/modeling_bert.py:371:0
  %905 : Tensor = prim::GetAttr[name="bias"](%896)
  %906 : Tensor = prim::GetAttr[name="weight"](%896)
  %907 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.LayerNorm
  %input.95 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.94, %907, %906, %905, %79, %78), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.LayerNorm # torch/nn/functional.py:2048:0
  %909 : __torch__.transformers.modeling_bert.___torch_mangle_6317.BertOutput = prim::GetAttr[name="output"](%98)
  %910 : __torch__.transformers.modeling_bert.___torch_mangle_6313.BertIntermediate = prim::GetAttr[name="intermediate"](%98)
  %911 : __torch__.transformers.modeling_bert.___torch_mangle_6311.BertAttention = prim::GetAttr[name="attention"](%98)
  %912 : __torch__.transformers.modeling_bert.___torch_mangle_6310.BertSelfOutput = prim::GetAttr[name="output"](%911)
  %913 : __torch__.transformers.modeling_bert.___torch_mangle_6306.BertSelfAttention = prim::GetAttr[name="self"](%911)
  %914 : __torch__.torch.nn.modules.linear.___torch_mangle_6304.Linear = prim::GetAttr[name="value"](%913)
  %915 : __torch__.torch.nn.modules.linear.___torch_mangle_6303.Linear = prim::GetAttr[name="key"](%913)
  %916 : __torch__.torch.nn.modules.linear.___torch_mangle_6302.Linear = prim::GetAttr[name="query"](%913)
  %917 : Tensor = prim::GetAttr[name="bias"](%916)
  %918 : Tensor = prim::GetAttr[name="weight"](%916)
  %919 : Float(768:1, 768:768) = aten::t(%918), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %output.55 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.95, %919), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %x.55 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.55, %917, %80), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.query # torch/nn/functional.py:1678:0
  %922 : Tensor = prim::GetAttr[name="bias"](%915)
  %923 : Tensor = prim::GetAttr[name="weight"](%915)
  %924 : Float(768:1, 768:768) = aten::t(%923), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %output.56 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.95, %924), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %x.57 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.56, %922, %80), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.key # torch/nn/functional.py:1678:0
  %927 : Tensor = prim::GetAttr[name="bias"](%914)
  %928 : Tensor = prim::GetAttr[name="weight"](%914)
  %929 : Float(768:1, 768:768) = aten::t(%928), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %output.57 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.95, %929), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %x.59 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.57, %927, %80), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.value # torch/nn/functional.py:1678:0
  %932 : int = aten::size(%x.55, %81), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:227:0
  %933 : int = aten::size(%x.55, %80), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:227:0
  %934 : int[] = prim::ListConstruct(%932, %933, %82, %83), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %x.56 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.55, %934), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:228:0
  %936 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %query_layer.10 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.56, %936), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:229:0
  %938 : int = aten::size(%x.57, %81), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:227:0
  %939 : int = aten::size(%x.57, %80), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:227:0
  %940 : int[] = prim::ListConstruct(%938, %939, %82, %83), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %x.58 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.57, %940), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:228:0
  %942 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %key_layer.10 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.58, %942), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:229:0
  %944 : int = aten::size(%x.59, %81), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:227:0
  %945 : int = aten::size(%x.59, %80), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:227:0
  %946 : int[] = prim::ListConstruct(%944, %945, %82, %83), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %x.60 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.59, %946), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:228:0
  %948 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %value_layer.10 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.60, %948), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:229:0
  %950 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_layer.10, %86, %87), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.19 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_layer.10, %950), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.20 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%attention_scores.19, %88), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:259:0
  %input.96 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%attention_scores.20, %attention_mask, %80), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:262:0
  %input.97 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.96, %86, %89), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.10 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.97, %91, %90), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.19 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.10, %value_layer.10), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:275:0
  %957 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %958 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%context_layer.19, %957), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:277:0
  %context_layer.20 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%958, %81), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:277:0
  %960 : int = aten::size(%context_layer.20, %81), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:278:0
  %961 : int = aten::size(%context_layer.20, %80), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:278:0
  %962 : int[] = prim::ListConstruct(%960, %961, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %input.98 : Float(17:9984, 13:768, 768:1) = aten::view(%context_layer.20, %962), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_bert.py:279:0
  %964 : __torch__.torch.nn.modules.normalization.___torch_mangle_6308.LayerNorm = prim::GetAttr[name="LayerNorm"](%912)
  %965 : __torch__.torch.nn.modules.linear.___torch_mangle_6307.Linear = prim::GetAttr[name="dense"](%912)
  %966 : Tensor = prim::GetAttr[name="bias"](%965)
  %967 : Tensor = prim::GetAttr[name="weight"](%965)
  %968 : Float(768:1, 768:768) = aten::t(%967), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %output.58 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.98, %968), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %input.99 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.58, %966, %80), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.19 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.99, %91, %90), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.dropout # torch/nn/functional.py:973:0
  %input.100 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.19, %input.95, %80), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output # transformers/modeling_bert.py:295:0
  %973 : Tensor = prim::GetAttr[name="bias"](%964)
  %974 : Tensor = prim::GetAttr[name="weight"](%964)
  %975 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.LayerNorm
  %input_tensor.10 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.100, %975, %974, %973, %79, %78), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %977 : __torch__.torch.nn.modules.linear.___torch_mangle_6312.Linear = prim::GetAttr[name="dense"](%910)
  %978 : Tensor = prim::GetAttr[name="bias"](%977)
  %979 : Tensor = prim::GetAttr[name="weight"](%977)
  %980 : Float(768:1, 3072:768) = aten::t(%979), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.intermediate/__module.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %output.59 : Float(17:39936, 13:3072, 3072:1) = aten::matmul(%input_tensor.10, %980), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.intermediate/__module.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %input.101 : Float(17:39936, 13:3072, 3072:1) = aten::add_(%output.59, %978, %80), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.intermediate/__module.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1678:0
  %input.102 : Float(17:39936, 13:3072, 3072:1) = aten::gelu(%input.101), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.intermediate # torch/nn/functional.py:1369:0
  %984 : __torch__.torch.nn.modules.normalization.___torch_mangle_6315.LayerNorm = prim::GetAttr[name="LayerNorm"](%909)
  %985 : __torch__.torch.nn.modules.linear.___torch_mangle_6314.Linear = prim::GetAttr[name="dense"](%909)
  %986 : Tensor = prim::GetAttr[name="bias"](%985)
  %987 : Tensor = prim::GetAttr[name="weight"](%985)
  %988 : Float(3072:1, 768:3072) = aten::t(%987), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %output.60 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.102, %988), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %input.103 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.60, %986, %80), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.20 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.103, %91, %90), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.dropout # torch/nn/functional.py:973:0
  %input.104 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.20, %input_tensor.10, %80), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output # transformers/modeling_bert.py:371:0
  %993 : Tensor = prim::GetAttr[name="bias"](%984)
  %994 : Tensor = prim::GetAttr[name="weight"](%984)
  %995 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.LayerNorm
  %input.105 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.104, %995, %994, %993, %79, %78), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.LayerNorm # torch/nn/functional.py:2048:0
  %997 : __torch__.transformers.modeling_bert.___torch_mangle_6334.BertOutput = prim::GetAttr[name="output"](%96)
  %998 : __torch__.transformers.modeling_bert.___torch_mangle_6330.BertIntermediate = prim::GetAttr[name="intermediate"](%96)
  %999 : __torch__.transformers.modeling_bert.___torch_mangle_6328.BertAttention = prim::GetAttr[name="attention"](%96)
  %1000 : __torch__.transformers.modeling_bert.___torch_mangle_6327.BertSelfOutput = prim::GetAttr[name="output"](%999)
  %1001 : __torch__.transformers.modeling_bert.___torch_mangle_6323.BertSelfAttention = prim::GetAttr[name="self"](%999)
  %1002 : __torch__.torch.nn.modules.linear.___torch_mangle_6321.Linear = prim::GetAttr[name="value"](%1001)
  %1003 : __torch__.torch.nn.modules.linear.___torch_mangle_6320.Linear = prim::GetAttr[name="key"](%1001)
  %1004 : __torch__.torch.nn.modules.linear.___torch_mangle_6319.Linear = prim::GetAttr[name="query"](%1001)
  %1005 : Tensor = prim::GetAttr[name="bias"](%1004)
  %1006 : Tensor = prim::GetAttr[name="weight"](%1004)
  %1007 : Float(768:1, 768:768) = aten::t(%1006), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %output.61 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.105, %1007), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %x.61 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.61, %1005, %80), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.query # torch/nn/functional.py:1678:0
  %1010 : Tensor = prim::GetAttr[name="bias"](%1003)
  %1011 : Tensor = prim::GetAttr[name="weight"](%1003)
  %1012 : Float(768:1, 768:768) = aten::t(%1011), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %output.62 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.105, %1012), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %x.63 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.62, %1010, %80), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.key # torch/nn/functional.py:1678:0
  %1015 : Tensor = prim::GetAttr[name="bias"](%1002)
  %1016 : Tensor = prim::GetAttr[name="weight"](%1002)
  %1017 : Float(768:1, 768:768) = aten::t(%1016), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %output.63 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.105, %1017), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %x.65 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.63, %1015, %80), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.value # torch/nn/functional.py:1678:0
  %1020 : int = aten::size(%x.61, %81), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:227:0
  %1021 : int = aten::size(%x.61, %80), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:227:0
  %1022 : int[] = prim::ListConstruct(%1020, %1021, %82, %83), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %x.62 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.61, %1022), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:228:0
  %1024 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %query_layer.11 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.62, %1024), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:229:0
  %1026 : int = aten::size(%x.63, %81), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:227:0
  %1027 : int = aten::size(%x.63, %80), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:227:0
  %1028 : int[] = prim::ListConstruct(%1026, %1027, %82, %83), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %x.64 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.63, %1028), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:228:0
  %1030 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %key_layer.11 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.64, %1030), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:229:0
  %1032 : int = aten::size(%x.65, %81), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:227:0
  %1033 : int = aten::size(%x.65, %80), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:227:0
  %1034 : int[] = prim::ListConstruct(%1032, %1033, %82, %83), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %x.66 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.65, %1034), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:228:0
  %1036 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %value_layer.11 : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.66, %1036), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:229:0
  %1038 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_layer.11, %86, %87), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.21 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_layer.11, %1038), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.22 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%attention_scores.21, %88), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:259:0
  %input.106 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%attention_scores.22, %attention_mask, %80), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:262:0
  %input.107 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.106, %86, %89), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.11 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.107, %91, %90), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.21 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.11, %value_layer.11), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:275:0
  %1045 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %1046 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%context_layer.21, %1045), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:277:0
  %context_layer.22 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%1046, %81), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:277:0
  %1048 : int = aten::size(%context_layer.22, %81), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:278:0
  %1049 : int = aten::size(%context_layer.22, %80), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:278:0
  %1050 : int[] = prim::ListConstruct(%1048, %1049, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %input.108 : Float(17:9984, 13:768, 768:1) = aten::view(%context_layer.22, %1050), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_bert.py:279:0
  %1052 : __torch__.torch.nn.modules.normalization.___torch_mangle_6325.LayerNorm = prim::GetAttr[name="LayerNorm"](%1000)
  %1053 : __torch__.torch.nn.modules.linear.___torch_mangle_6324.Linear = prim::GetAttr[name="dense"](%1000)
  %1054 : Tensor = prim::GetAttr[name="bias"](%1053)
  %1055 : Tensor = prim::GetAttr[name="weight"](%1053)
  %1056 : Float(768:1, 768:768) = aten::t(%1055), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %output.64 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.108, %1056), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %input.109 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.64, %1054, %80), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.21 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.109, %91, %90), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.dropout # torch/nn/functional.py:973:0
  %input.110 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.21, %input.105, %80), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output # transformers/modeling_bert.py:295:0
  %1061 : Tensor = prim::GetAttr[name="bias"](%1052)
  %1062 : Tensor = prim::GetAttr[name="weight"](%1052)
  %1063 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.LayerNorm
  %input_tensor.11 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.110, %1063, %1062, %1061, %79, %78), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %1065 : __torch__.torch.nn.modules.linear.___torch_mangle_6329.Linear = prim::GetAttr[name="dense"](%998)
  %1066 : Tensor = prim::GetAttr[name="bias"](%1065)
  %1067 : Tensor = prim::GetAttr[name="weight"](%1065)
  %1068 : Float(768:1, 3072:768) = aten::t(%1067), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.intermediate/__module.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %output.65 : Float(17:39936, 13:3072, 3072:1) = aten::matmul(%input_tensor.11, %1068), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.intermediate/__module.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %input.111 : Float(17:39936, 13:3072, 3072:1) = aten::add_(%output.65, %1066, %80), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.intermediate/__module.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1678:0
  %input.112 : Float(17:39936, 13:3072, 3072:1) = aten::gelu(%input.111), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.intermediate # torch/nn/functional.py:1369:0
  %1072 : __torch__.torch.nn.modules.normalization.___torch_mangle_6332.LayerNorm = prim::GetAttr[name="LayerNorm"](%997)
  %1073 : __torch__.torch.nn.modules.linear.___torch_mangle_6331.Linear = prim::GetAttr[name="dense"](%997)
  %1074 : Tensor = prim::GetAttr[name="bias"](%1073)
  %1075 : Tensor = prim::GetAttr[name="weight"](%1073)
  %1076 : Float(3072:1, 768:3072) = aten::t(%1075), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %output.66 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.112, %1076), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %input.113 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.66, %1074, %80), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.22 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.113, %91, %90), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.dropout # torch/nn/functional.py:973:0
  %input.114 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.22, %input_tensor.11, %80), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output # transformers/modeling_bert.py:371:0
  %1081 : Tensor = prim::GetAttr[name="bias"](%1072)
  %1082 : Tensor = prim::GetAttr[name="weight"](%1072)
  %1083 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.LayerNorm
  %input.115 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.114, %1083, %1082, %1081, %79, %78), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.LayerNorm # torch/nn/functional.py:2048:0
  %1085 : __torch__.transformers.modeling_bert.___torch_mangle_6351.BertOutput = prim::GetAttr[name="output"](%94)
  %1086 : __torch__.transformers.modeling_bert.___torch_mangle_6347.BertIntermediate = prim::GetAttr[name="intermediate"](%94)
  %1087 : __torch__.transformers.modeling_bert.___torch_mangle_6345.BertAttention = prim::GetAttr[name="attention"](%94)
  %1088 : __torch__.transformers.modeling_bert.___torch_mangle_6344.BertSelfOutput = prim::GetAttr[name="output"](%1087)
  %1089 : __torch__.transformers.modeling_bert.___torch_mangle_6340.BertSelfAttention = prim::GetAttr[name="self"](%1087)
  %1090 : __torch__.torch.nn.modules.linear.___torch_mangle_6338.Linear = prim::GetAttr[name="value"](%1089)
  %1091 : __torch__.torch.nn.modules.linear.___torch_mangle_6337.Linear = prim::GetAttr[name="key"](%1089)
  %1092 : __torch__.torch.nn.modules.linear.___torch_mangle_6336.Linear = prim::GetAttr[name="query"](%1089)
  %1093 : Tensor = prim::GetAttr[name="bias"](%1092)
  %1094 : Tensor = prim::GetAttr[name="weight"](%1092)
  %1095 : Float(768:1, 768:768) = aten::t(%1094), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %output.67 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.115, %1095), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %x.67 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.67, %1093, %80), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.query # torch/nn/functional.py:1678:0
  %1098 : Tensor = prim::GetAttr[name="bias"](%1091)
  %1099 : Tensor = prim::GetAttr[name="weight"](%1091)
  %1100 : Float(768:1, 768:768) = aten::t(%1099), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %output.68 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.115, %1100), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %x.69 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.68, %1098, %80), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.key # torch/nn/functional.py:1678:0
  %1103 : Tensor = prim::GetAttr[name="bias"](%1090)
  %1104 : Tensor = prim::GetAttr[name="weight"](%1090)
  %1105 : Float(768:1, 768:768) = aten::t(%1104), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %output.69 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.115, %1105), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %x.71 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.69, %1103, %80), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.value # torch/nn/functional.py:1678:0
  %1108 : int = aten::size(%x.67, %81), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:227:0
  %1109 : int = aten::size(%x.67, %80), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:227:0
  %1110 : int[] = prim::ListConstruct(%1108, %1109, %82, %83), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %x.68 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.67, %1110), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:228:0
  %1112 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %query_layer : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.68, %1112), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:229:0
  %1114 : int = aten::size(%x.69, %81), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:227:0
  %1115 : int = aten::size(%x.69, %80), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:227:0
  %1116 : int[] = prim::ListConstruct(%1114, %1115, %82, %83), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %x.70 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.69, %1116), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:228:0
  %1118 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %key_layer : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x.70, %1118), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:229:0
  %1120 : int = aten::size(%x.71, %81), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:227:0
  %1121 : int = aten::size(%x.71, %80), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:227:0
  %1122 : int[] = prim::ListConstruct(%1120, %1121, %82, %83), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %x : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%x.71, %1122), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:228:0
  %1124 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %value_layer : Float(17:9984, 12:64, 13:768, 64:1) = aten::permute(%x, %1124), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:229:0
  %1126 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_layer, %86, %87), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores.23 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_layer, %1126), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:258:0
  %attention_scores : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%attention_scores.23, %88), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:259:0
  %input.116 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%attention_scores, %attention_mask, %80), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:262:0
  %input.117 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.116, %86, %89), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/nn/functional.py:1498:0
  %attention_probs : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.117, %91, %90), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.23 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs, %value_layer), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:275:0
  %1133 : int[] = prim::ListConstruct(%81, %84, %80, %85), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %1134 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%context_layer.23, %1133), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:277:0
  %context_layer : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%1134, %81), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:277:0
  %1136 : int = aten::size(%context_layer, %81), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:278:0
  %1137 : int = aten::size(%context_layer, %80), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:278:0
  %1138 : int[] = prim::ListConstruct(%1136, %1137, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %input.118 : Float(17:9984, 13:768, 768:1) = aten::view(%context_layer, %1138), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_bert.py:279:0
  %1140 : __torch__.torch.nn.modules.normalization.___torch_mangle_6342.LayerNorm = prim::GetAttr[name="LayerNorm"](%1088)
  %1141 : __torch__.torch.nn.modules.linear.___torch_mangle_6341.Linear = prim::GetAttr[name="dense"](%1088)
  %1142 : Tensor = prim::GetAttr[name="bias"](%1141)
  %1143 : Tensor = prim::GetAttr[name="weight"](%1141)
  %1144 : Float(768:1, 768:768) = aten::t(%1143), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %output.70 : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.118, %1144), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %input.119 : Float(17:9984, 13:768, 768:1) = aten::add_(%output.70, %1142, %80), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.23 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.119, %91, %90), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.dropout # torch/nn/functional.py:973:0
  %input.120 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.23, %input.115, %80), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output # transformers/modeling_bert.py:295:0
  %1149 : Tensor = prim::GetAttr[name="bias"](%1140)
  %1150 : Tensor = prim::GetAttr[name="weight"](%1140)
  %1151 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.LayerNorm
  %input_tensor : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.120, %1151, %1150, %1149, %79, %78), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.LayerNorm # torch/nn/functional.py:2048:0
  %1153 : __torch__.torch.nn.modules.linear.___torch_mangle_6346.Linear = prim::GetAttr[name="dense"](%1086)
  %1154 : Tensor = prim::GetAttr[name="bias"](%1153)
  %1155 : Tensor = prim::GetAttr[name="weight"](%1153)
  %1156 : Float(768:1, 3072:768) = aten::t(%1155), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.intermediate/__module.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %output.71 : Float(17:39936, 13:3072, 3072:1) = aten::matmul(%input_tensor, %1156), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.intermediate/__module.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %input.121 : Float(17:39936, 13:3072, 3072:1) = aten::add_(%output.71, %1154, %80), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.intermediate/__module.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1678:0
  %input.122 : Float(17:39936, 13:3072, 3072:1) = aten::gelu(%input.121), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.intermediate # torch/nn/functional.py:1369:0
  %1160 : __torch__.torch.nn.modules.normalization.___torch_mangle_6349.LayerNorm = prim::GetAttr[name="LayerNorm"](%1085)
  %1161 : __torch__.torch.nn.modules.linear.___torch_mangle_6348.Linear = prim::GetAttr[name="dense"](%1085)
  %1162 : Tensor = prim::GetAttr[name="bias"](%1161)
  %1163 : Tensor = prim::GetAttr[name="weight"](%1161)
  %1164 : Float(3072:1, 768:3072) = aten::t(%1163), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %output : Float(17:9984, 13:768, 768:1) = aten::matmul(%input.122, %1164), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %input.123 : Float(17:9984, 13:768, 768:1) = aten::add_(%output, %1162, %80), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.dense # torch/nn/functional.py:1678:0
  %hidden_states.24 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.123, %91, %90), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.dropout # torch/nn/functional.py:973:0
  %input.124 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.24, %input_tensor, %80), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output # transformers/modeling_bert.py:371:0
  %1169 : Tensor = prim::GetAttr[name="bias"](%1160)
  %1170 : Tensor = prim::GetAttr[name="weight"](%1160)
  %1171 : int[] = prim::ListConstruct(%92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.LayerNorm
  %hidden_states : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.124, %1171, %1170, %1169, %79, %78), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.LayerNorm # torch/nn/functional.py:2048:0
  %1173 : int = prim::Constant[value=1](), scope: __module.pooler # transformers/modeling_bert.py:507:0
  %1174 : int = prim::Constant[value=9223372036854775807](), scope: __module.pooler # transformers/modeling_bert.py:507:0
  %1175 : int = prim::Constant[value=0](), scope: __module.pooler # transformers/modeling_bert.py:507:0
  %1176 : __torch__.torch.nn.modules.linear.___torch_mangle_6355.Linear = prim::GetAttr[name="dense"](%3)
  %1177 : Float(17:9984, 13:768, 768:1) = aten::slice(%hidden_states, %1175, %1175, %1174, %1173), scope: __module.pooler # transformers/modeling_bert.py:507:0
  %input.125 : Float(17:9984, 768:1) = aten::select(%1177, %1173, %1175), scope: __module.pooler # transformers/modeling_bert.py:507:0
  %1179 : Tensor = prim::GetAttr[name="bias"](%1176)
  %1180 : Tensor = prim::GetAttr[name="weight"](%1176)
  %1181 : Float(768:1, 768:768) = aten::t(%1180), scope: __module.pooler/__module.pooler.dense # torch/nn/functional.py:1674:0
  %input : Float(17:768, 768:1) = aten::addmm(%1179, %input.125, %1181, %1173, %1173), scope: __module.pooler/__module.pooler.dense # torch/nn/functional.py:1674:0
  %1183 : Float(17:768, 768:1) = aten::tanh(%input), scope: __module.pooler/__module.pooler.activation # torch/nn/modules/activation.py:350:0
  %47 : (Float(17:9984, 13:768, 768:1), Float(17:768, 768:1)) = prim::TupleConstruct(%hidden_states, %1183)
  return (%47)
